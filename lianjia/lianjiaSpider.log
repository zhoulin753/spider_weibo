2018-11-22 10:41:01 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 10:41:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 10:41:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 10:41:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:41:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:41:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:41:01 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 10:41:01 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:41:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:41:01 [old_house] INFO: Spider opened: old_house
2018-11-22 10:41:01 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 10:41:01 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 10:42:07 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:43:04 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:43:46 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:43:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3973614,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 43, 46, 237485),
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 22, 2, 41, 1, 719916)}
2018-11-22 10:43:46 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:57:41 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 10:57:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 10:57:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 10:57:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:57:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:57:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:57:43 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 10:57:43 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:57:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:57:43 [old_house] INFO: Spider opened: old_house
2018-11-22 10:57:43 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 10:57:43 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 10:58:46 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:59:48 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:00:32 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:00:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3979686,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 0, 32, 418178),
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 22, 2, 57, 43, 117724)}
2018-11-22 11:00:32 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:04:52 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 11:04:52 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 11:04:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 11:04:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:04:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:04:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:04:53 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 11:04:53 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:04:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:04:53 [old_house] INFO: Spider opened: old_house
2018-11-22 11:04:53 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 11:04:53 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 11:06:00 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:06:58 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:07:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:07:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3969414,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 7, 34, 333412),
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 22, 3, 4, 53, 399568)}
2018-11-22 11:07:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:17:24 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 11:17:24 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 11:17:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 11:17:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:17:24 [twisted] CRITICAL: Unhandled error in Deferred:
2018-11-22 11:17:24 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python36\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 941, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 941, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'lianjan'
2018-11-22 11:18:14 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 11:18:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 11:18:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 11:18:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:18:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:18:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:18:15 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 11:18:15 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:18:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:18:15 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/baoshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/xuhui/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/huangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/putuo/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/songjiang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jiading/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/yangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/changning/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jingan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/zhabei/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/fengxian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/shanghaizhoubian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/chongming/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jinshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/hongkou/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/qingpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:18:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 18,
 'downloader/exception_type_count/builtins.AssertionError': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 18, 15, 371281),
 'log_count/ERROR': 18,
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 22, 3, 18, 15, 119639)}
2018-11-22 11:18:15 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:19:19 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 11:19:19 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 11:19:19 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 11:19:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:19:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:19:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:19:19 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 11:19:19 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:19:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:19:19 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 11:19:19 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 11:19:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:20:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:20:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/baoshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:20:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:20:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/xuhui/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:20:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/putuo/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:21:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/yangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:21:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/changning/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:21:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:21:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/songjiang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:22:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jiading/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:22:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/huangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:22:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jingan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:22:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:22:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/zhabei/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:23:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/hongkou/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:23:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/qingpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:23:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:23:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/fengxian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:23:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jinshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:24:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/chongming/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:24:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/shanghaizhoubian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:24:15 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:24:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3995628,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 24, 15, 773411),
 'log_count/ERROR': 18,
 'log_count/INFO': 11,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 22, 3, 19, 19, 758348)}
2018-11-22 11:24:15 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:25:18 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 11:25:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 11:25:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 11:25:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:25:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:25:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:25:20 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 11:25:20 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:25:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:25:20 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 11:25:20 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 11:30:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:59:02 [py.warnings] WARNING: C:\Program Files\JetBrains\PyCharm 2018.1.4\helpers\pydev\_pydevd_bundle\pydevd_resolver.py:166: ScrapyDeprecationWarning: Attribute `_root` is deprecated, use `root` instead
  attr = getattr(var, n)

2018-11-22 11:59:02 [py.warnings] WARNING: C:\Program Files\JetBrains\PyCharm 2018.1.4\helpers\pydev\_pydevd_bundle\pydevd_resolver.py:71: ScrapyDeprecationWarning: Attribute `_root` is deprecated, use `root` instead
  return getattr(var, attribute)

2018-11-22 12:11:28 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 12:11:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 12:11:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 12:11:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 12:11:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 12:11:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 12:11:30 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 12:11:30 [scrapy.core.engine] INFO: Spider opened
2018-11-22 12:11:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 12:11:30 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 12:11:30 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 12:12:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 12:12:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 12:12:29 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 12:12:29 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 12:12:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 12:12:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 12:12:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 12:12:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 12:12:29 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 12:12:29 [scrapy.core.engine] INFO: Spider opened
2018-11-22 12:12:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 12:12:29 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 12:12:29 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 12:13:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 12:13:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 12:13:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/baoshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 12:13:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 12:13:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/xuhui/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 12:14:04 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 12:14:04 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 12:14:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 12:14:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 12:14:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 12:14:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 12:14:05 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 12:14:05 [scrapy.core.engine] INFO: Spider opened
2018-11-22 12:14:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 12:14:05 [old_house] INFO: Spider opened: old_house
2018-11-22 12:14:05 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 12:14:05 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 12:14:30 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 12:14:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 12:14:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 12:14:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 12:14:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 12:14:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 12:14:31 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 12:14:31 [scrapy.core.engine] INFO: Spider opened
2018-11-22 12:14:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 12:14:31 [old_house] INFO: Spider opened: old_house
2018-11-22 12:14:31 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 12:14:31 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 12:14:56 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 12:14:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 12:14:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 12:14:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 12:14:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 12:14:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 12:14:57 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 12:14:57 [scrapy.core.engine] INFO: Spider opened
2018-11-22 12:14:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 12:14:57 [old_house] INFO: Spider opened: old_house
2018-11-22 12:14:57 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 12:14:57 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 12:15:10 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 12:15:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 12:15:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 12:15:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 12:15:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 12:15:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 12:15:11 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 12:15:11 [scrapy.core.engine] INFO: Spider opened
2018-11-22 12:15:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 12:15:11 [old_house] INFO: Spider opened: old_house
2018-11-22 12:15:11 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 12:15:11 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 12:22:42 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 12:22:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 12:22:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 12:22:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 12:22:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 12:22:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 12:22:43 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 12:22:43 [scrapy.core.engine] INFO: Spider opened
2018-11-22 12:22:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 12:22:43 [old_house] INFO: Spider opened: old_house
2018-11-22 12:22:43 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 12:22:43 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 12:23:43 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 12:24:50 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 12:25:15 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 12:25:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3976888,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 4, 25, 15, 236770),
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 22, 4, 22, 43, 208959)}
2018-11-22 12:25:15 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:20:05 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 14:20:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 14:20:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 14:20:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:20:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:20:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:20:07 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 14:20:07 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:20:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:20:07 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 14:20:07 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 14:21:10 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:22:09 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:22:53 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 14:22:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3997504,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 6, 22, 53, 439477),
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 22, 6, 20, 7, 568085)}
2018-11-22 14:22:53 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:38:18 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 14:38:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 14:38:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 14:38:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:38:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:38:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:38:19 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 14:38:19 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:38:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:38:19 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 14:38:19 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 14:40:04 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 14:40:04 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 14:40:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 14:40:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:40:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:40:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:40:05 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 14:40:05 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:40:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:40:05 [old_house] INFO: Spider opened: old_house
2018-11-22 14:40:05 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 14:40:05 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 14:41:53 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 14:41:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 14:41:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 14:41:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:41:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:41:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:41:53 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 14:41:53 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:41:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:41:53 [old_house] INFO: Spider opened: old_house
2018-11-22 14:41:53 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 14:41:53 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 14:57:40 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 15:02:29 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 15:09:45 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 15:09:45 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 15:09:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 15:09:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 15:09:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 15:09:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 15:09:46 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 15:09:46 [scrapy.core.engine] INFO: Spider opened
2018-11-22 15:09:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 15:09:46 [old_house] INFO: Spider opened: old_house
2018-11-22 15:09:46 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 15:10:11 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 15:10:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 4006655,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 7, 10, 11, 622763),
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 22, 7, 9, 46, 398011)}
2018-11-22 15:10:11 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 15:41:06 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 15:41:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 15:41:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 15:41:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 15:41:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 15:41:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 15:41:07 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 15:41:07 [scrapy.core.engine] INFO: Spider opened
2018-11-22 15:41:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 15:41:07 [old_house] INFO: Spider opened: old_house
2018-11-22 15:41:07 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 15:41:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 15:41:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 4002289,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 7, 41, 34, 185366),
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 22, 7, 41, 7, 620412)}
2018-11-22 15:41:34 [scrapy.core.engine] INFO: Spider closed (finished)
