2018-11-22 10:41:01 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 10:41:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 10:41:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 10:41:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:41:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:41:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:41:01 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 10:41:01 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:41:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:41:01 [old_house] INFO: Spider opened: old_house
2018-11-22 10:41:01 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 10:41:01 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 10:42:07 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:43:04 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:43:46 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 10:43:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3973614,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 2, 43, 46, 237485),
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 22, 2, 41, 1, 719916)}
2018-11-22 10:43:46 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 10:57:41 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 10:57:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 10:57:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 10:57:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 10:57:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 10:57:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 10:57:43 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 10:57:43 [scrapy.core.engine] INFO: Spider opened
2018-11-22 10:57:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:57:43 [old_house] INFO: Spider opened: old_house
2018-11-22 10:57:43 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 10:57:43 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 10:58:46 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 10:59:48 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:00:32 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:00:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3979686,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 0, 32, 418178),
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 22, 2, 57, 43, 117724)}
2018-11-22 11:00:32 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:04:52 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 11:04:52 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 11:04:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 11:04:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:04:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:04:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:04:53 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 11:04:53 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:04:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:04:53 [old_house] INFO: Spider opened: old_house
2018-11-22 11:04:53 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 11:04:53 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 11:06:00 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:06:58 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:07:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:07:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3969414,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 7, 34, 333412),
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 22, 3, 4, 53, 399568)}
2018-11-22 11:07:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:17:24 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 11:17:24 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 11:17:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 11:17:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:17:24 [twisted] CRITICAL: Unhandled error in Deferred:
2018-11-22 11:17:24 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python36\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 941, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 941, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 953, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'lianjan'
2018-11-22 11:18:14 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 11:18:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 11:18:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 11:18:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:18:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:18:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:18:15 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 11:18:15 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:18:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:18:15 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/baoshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/xuhui/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/huangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/putuo/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/songjiang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jiading/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/yangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/changning/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jingan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/zhabei/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/fengxian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/shanghaizhoubian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/chongming/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jinshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/hongkou/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/qingpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware JavaScriptMiddleware.process_request must return None, Response or Request, got dict
2018-11-22 11:18:15 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:18:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 18,
 'downloader/exception_type_count/builtins.AssertionError': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 18, 15, 371281),
 'log_count/ERROR': 18,
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 22, 3, 18, 15, 119639)}
2018-11-22 11:18:15 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:19:19 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 11:19:19 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 11:19:19 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 11:19:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:19:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:19:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:19:19 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 11:19:19 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:19:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:19:19 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 11:19:19 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 11:19:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:20:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:20:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/baoshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:20:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:20:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/xuhui/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:20:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/putuo/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:21:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/yangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:21:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/changning/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:21:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:21:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/songjiang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:22:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jiading/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:22:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/huangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:22:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jingan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:22:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:22:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/zhabei/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:23:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/hongkou/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:23:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/qingpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:23:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:23:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/fengxian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:23:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jinshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:24:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/chongming/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:24:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/shanghaizhoubian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 11:24:15 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 11:24:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3995628,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 3, 24, 15, 773411),
 'log_count/ERROR': 18,
 'log_count/INFO': 11,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 22, 3, 19, 19, 758348)}
2018-11-22 11:24:15 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 11:25:18 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 11:25:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 11:25:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 11:25:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 11:25:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 11:25:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 11:25:20 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 11:25:20 [scrapy.core.engine] INFO: Spider opened
2018-11-22 11:25:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:25:20 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 11:25:20 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 11:30:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 11:59:02 [py.warnings] WARNING: C:\Program Files\JetBrains\PyCharm 2018.1.4\helpers\pydev\_pydevd_bundle\pydevd_resolver.py:166: ScrapyDeprecationWarning: Attribute `_root` is deprecated, use `root` instead
  attr = getattr(var, n)

2018-11-22 11:59:02 [py.warnings] WARNING: C:\Program Files\JetBrains\PyCharm 2018.1.4\helpers\pydev\_pydevd_bundle\pydevd_resolver.py:71: ScrapyDeprecationWarning: Attribute `_root` is deprecated, use `root` instead
  return getattr(var, attribute)

2018-11-22 12:11:28 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 12:11:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 12:11:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 12:11:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 12:11:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 12:11:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 12:11:30 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 12:11:30 [scrapy.core.engine] INFO: Spider opened
2018-11-22 12:11:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 12:11:30 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 12:11:30 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 12:12:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 12:12:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 12:12:29 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 12:12:29 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 12:12:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 12:12:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 12:12:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 12:12:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 12:12:29 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 12:12:29 [scrapy.core.engine] INFO: Spider opened
2018-11-22 12:12:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 12:12:29 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 12:12:29 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 12:13:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 12:13:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 12:13:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/baoshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 12:13:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 12:13:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/xuhui/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-22 12:14:04 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 12:14:04 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 12:14:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 12:14:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 12:14:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 12:14:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 12:14:05 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 12:14:05 [scrapy.core.engine] INFO: Spider opened
2018-11-22 12:14:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 12:14:05 [old_house] INFO: Spider opened: old_house
2018-11-22 12:14:05 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 12:14:05 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 12:14:30 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 12:14:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 12:14:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 12:14:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 12:14:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 12:14:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 12:14:31 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 12:14:31 [scrapy.core.engine] INFO: Spider opened
2018-11-22 12:14:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 12:14:31 [old_house] INFO: Spider opened: old_house
2018-11-22 12:14:31 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 12:14:31 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 12:14:56 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 12:14:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 12:14:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 12:14:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 12:14:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 12:14:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 12:14:57 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 12:14:57 [scrapy.core.engine] INFO: Spider opened
2018-11-22 12:14:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 12:14:57 [old_house] INFO: Spider opened: old_house
2018-11-22 12:14:57 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 12:14:57 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 12:15:10 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 12:15:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 12:15:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 12:15:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 12:15:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 12:15:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 12:15:11 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 12:15:11 [scrapy.core.engine] INFO: Spider opened
2018-11-22 12:15:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 12:15:11 [old_house] INFO: Spider opened: old_house
2018-11-22 12:15:11 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 12:15:11 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 12:22:42 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 12:22:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 12:22:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 12:22:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 12:22:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 12:22:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 12:22:43 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 12:22:43 [scrapy.core.engine] INFO: Spider opened
2018-11-22 12:22:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 12:22:43 [old_house] INFO: Spider opened: old_house
2018-11-22 12:22:43 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 12:22:43 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 12:23:43 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 12:24:50 [scrapy.extensions.logstats] INFO: Crawled 15 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 12:25:15 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 12:25:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3976888,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 4, 25, 15, 236770),
 'log_count/INFO': 10,
 'log_count/WARNING': 2,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 22, 4, 22, 43, 208959)}
2018-11-22 12:25:15 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:20:05 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 14:20:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 14:20:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 14:20:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:20:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:20:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:20:07 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 14:20:07 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:20:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:20:07 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 14:20:07 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 14:21:10 [scrapy.extensions.logstats] INFO: Crawled 6 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:22:09 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 7 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:22:53 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 14:22:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3997504,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 6, 22, 53, 439477),
 'log_count/INFO': 9,
 'log_count/WARNING': 2,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 22, 6, 20, 7, 568085)}
2018-11-22 14:22:53 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 14:38:18 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 14:38:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 14:38:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 14:38:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:38:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:38:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:38:19 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 14:38:19 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:38:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:38:19 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 14:38:19 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 14:40:04 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 14:40:04 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 14:40:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 14:40:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:40:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:40:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:40:05 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 14:40:05 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:40:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:40:05 [old_house] INFO: Spider opened: old_house
2018-11-22 14:40:05 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 14:40:05 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 14:41:53 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 14:41:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 14:41:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 14:41:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 14:41:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 14:41:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 14:41:53 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 14:41:53 [scrapy.core.engine] INFO: Spider opened
2018-11-22 14:41:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 14:41:53 [old_house] INFO: Spider opened: old_house
2018-11-22 14:41:53 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 14:41:53 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-22 14:57:40 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 15:02:29 [scrapy.extensions.logstats] INFO: Crawled 2 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 15:09:45 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 15:09:45 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 15:09:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 15:09:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 15:09:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 15:09:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 15:09:46 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 15:09:46 [scrapy.core.engine] INFO: Spider opened
2018-11-22 15:09:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 15:09:46 [old_house] INFO: Spider opened: old_house
2018-11-22 15:09:46 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 15:10:11 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 15:10:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 4006655,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 7, 10, 11, 622763),
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 22, 7, 9, 46, 398011)}
2018-11-22 15:10:11 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-22 15:41:06 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-22 15:41:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-22 15:41:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-22 15:41:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-22 15:41:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-22 15:41:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-22 15:41:07 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-22 15:41:07 [scrapy.core.engine] INFO: Spider opened
2018-11-22 15:41:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-22 15:41:07 [old_house] INFO: Spider opened: old_house
2018-11-22 15:41:07 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-22 15:41:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-22 15:41:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 4002289,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 22, 7, 41, 34, 185366),
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 22, 7, 41, 7, 620412)}
2018-11-22 15:41:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 17:16:47 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-23 17:16:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-23 17:16:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-23 17:16:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 17:16:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 17:16:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 17:16:49 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-23 17:16:49 [scrapy.core.engine] INFO: Spider opened
2018-11-23 17:16:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 17:16:49 [old_house] INFO: Spider opened: old_house
2018-11-23 17:16:49 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-23 17:17:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 17:17:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 4021641,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 9, 17, 17, 503438),
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 23, 9, 16, 49, 224215)}
2018-11-23 17:17:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 17:19:22 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-23 17:19:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-23 17:19:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-23 17:19:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 17:19:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 17:19:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 17:19:23 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-23 17:19:23 [scrapy.core.engine] INFO: Spider opened
2018-11-23 17:19:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 17:19:23 [old_house] INFO: Spider opened: old_house
2018-11-23 17:19:23 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-23 17:19:54 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 17:19:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 4015480,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 9, 19, 54, 889896),
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 23, 9, 19, 23, 73242)}
2018-11-23 17:19:54 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 17:20:35 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-23 17:20:35 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-23 17:20:35 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-23 17:20:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 17:20:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 17:20:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 17:20:35 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-23 17:20:35 [scrapy.core.engine] INFO: Spider opened
2018-11-23 17:20:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 17:20:35 [old_house] INFO: Spider opened: old_house
2018-11-23 17:20:35 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-23 17:21:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 17:21:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 4025072,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 9, 21, 4, 301631),
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 23, 9, 20, 35, 553134)}
2018-11-23 17:21:04 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 17:21:54 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-23 17:21:54 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-23 17:21:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-23 17:21:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 17:21:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 17:21:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 17:21:55 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-23 17:21:55 [scrapy.core.engine] INFO: Spider opened
2018-11-23 17:21:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 17:21:55 [old_house] INFO: Spider opened: old_house
2018-11-23 17:21:55 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-23 17:22:28 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 17:22:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3950261,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 9, 22, 28, 975230),
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'offsite/domains': 146,
 'offsite/filtered': 10184,
 'request_depth_max': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 23, 9, 21, 55, 37122)}
2018-11-23 17:22:28 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 17:23:05 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-23 17:23:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-23 17:23:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-23 17:23:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 17:23:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 17:23:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 17:23:05 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-23 17:23:05 [scrapy.core.engine] INFO: Spider opened
2018-11-23 17:23:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 17:23:05 [old_house] INFO: Spider opened: old_house
2018-11-23 17:23:05 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-23 17:23:37 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 17:23:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 4018928,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 9, 23, 37, 653481),
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 23, 9, 23, 5, 546674)}
2018-11-23 17:23:37 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 17:24:59 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-23 17:24:59 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-23 17:24:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-23 17:24:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 17:25:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 17:25:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 17:25:00 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-23 17:25:00 [scrapy.core.engine] INFO: Spider opened
2018-11-23 17:25:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 17:25:00 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-23 17:25:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:25:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:25:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/baoshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:25:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/xuhui/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:25:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/putuo/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:25:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/yangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:25:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/changning/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:25:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/songjiang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:25:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jiading/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:26:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/huangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:26:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 17:26:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jingan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:26:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/zhabei/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:26:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/hongkou/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:26:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/qingpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:26:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/fengxian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:26:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jinshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:26:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/chongming/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:26:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/shanghaizhoubian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:26:42 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 17:26:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 4024581,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 9, 26, 42, 612411),
 'log_count/ERROR': 18,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 23, 9, 25, 0, 419781)}
2018-11-23 17:26:42 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 17:30:21 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-23 17:30:21 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-23 17:30:21 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-23 17:30:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 17:30:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 17:30:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 17:30:22 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-23 17:30:22 [scrapy.core.engine] INFO: Spider opened
2018-11-23 17:30:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 17:30:22 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-23 17:30:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:30:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:30:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/baoshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:30:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/xuhui/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:30:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/putuo/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:30:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/yangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:30:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/changning/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:30:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/songjiang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:30:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jiading/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:30:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/huangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:30:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jingan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:30:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/zhabei/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:30:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/hongkou/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:30:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/qingpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:30:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/fengxian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:30:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jinshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:30:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/chongming/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:30:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/shanghaizhoubian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:30:54 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 17:30:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 4011771,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 9, 30, 54, 222074),
 'log_count/ERROR': 18,
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 23, 9, 30, 22, 747932)}
2018-11-23 17:30:54 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 17:35:44 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-23 17:35:44 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-23 17:35:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-23 17:35:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 17:35:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 17:35:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 17:35:44 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-23 17:35:44 [scrapy.core.engine] INFO: Spider opened
2018-11-23 17:35:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 17:35:44 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-23 17:35:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_request
    return Selector(request.url, body=body, encoding='utf-8', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\selector\unified.py", line 67, in __init__
    text = response.text
AttributeError: 'str' object has no attribute 'text'
2018-11-23 17:35:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_request
    return Selector(request.url, body=body, encoding='utf-8', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\selector\unified.py", line 67, in __init__
    text = response.text
AttributeError: 'str' object has no attribute 'text'
2018-11-23 17:35:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/baoshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_request
    return Selector(request.url, body=body, encoding='utf-8', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\selector\unified.py", line 67, in __init__
    text = response.text
AttributeError: 'str' object has no attribute 'text'
2018-11-23 17:35:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/xuhui/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_request
    return Selector(request.url, body=body, encoding='utf-8', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\selector\unified.py", line 67, in __init__
    text = response.text
AttributeError: 'str' object has no attribute 'text'
2018-11-23 17:35:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/putuo/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_request
    return Selector(request.url, body=body, encoding='utf-8', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\selector\unified.py", line 67, in __init__
    text = response.text
AttributeError: 'str' object has no attribute 'text'
2018-11-23 17:35:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/yangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_request
    return Selector(request.url, body=body, encoding='utf-8', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\selector\unified.py", line 67, in __init__
    text = response.text
AttributeError: 'str' object has no attribute 'text'
2018-11-23 17:35:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/changning/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_request
    return Selector(request.url, body=body, encoding='utf-8', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\selector\unified.py", line 67, in __init__
    text = response.text
AttributeError: 'str' object has no attribute 'text'
2018-11-23 17:35:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/songjiang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_request
    return Selector(request.url, body=body, encoding='utf-8', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\selector\unified.py", line 67, in __init__
    text = response.text
AttributeError: 'str' object has no attribute 'text'
2018-11-23 17:36:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jiading/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_request
    return Selector(request.url, body=body, encoding='utf-8', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\selector\unified.py", line 67, in __init__
    text = response.text
AttributeError: 'str' object has no attribute 'text'
2018-11-23 17:36:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/huangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_request
    return Selector(request.url, body=body, encoding='utf-8', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\selector\unified.py", line 67, in __init__
    text = response.text
AttributeError: 'str' object has no attribute 'text'
2018-11-23 17:36:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jingan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_request
    return Selector(request.url, body=body, encoding='utf-8', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\selector\unified.py", line 67, in __init__
    text = response.text
AttributeError: 'str' object has no attribute 'text'
2018-11-23 17:36:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/zhabei/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_request
    return Selector(request.url, body=body, encoding='utf-8', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\selector\unified.py", line 67, in __init__
    text = response.text
AttributeError: 'str' object has no attribute 'text'
2018-11-23 17:36:06 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/hongkou/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_request
    return Selector(request.url, body=body, encoding='utf-8', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\selector\unified.py", line 67, in __init__
    text = response.text
AttributeError: 'str' object has no attribute 'text'
2018-11-23 17:36:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/qingpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_request
    return Selector(request.url, body=body, encoding='utf-8', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\selector\unified.py", line 67, in __init__
    text = response.text
AttributeError: 'str' object has no attribute 'text'
2018-11-23 17:36:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/fengxian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_request
    return Selector(request.url, body=body, encoding='utf-8', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\selector\unified.py", line 67, in __init__
    text = response.text
AttributeError: 'str' object has no attribute 'text'
2018-11-23 17:36:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jinshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_request
    return Selector(request.url, body=body, encoding='utf-8', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\selector\unified.py", line 67, in __init__
    text = response.text
AttributeError: 'str' object has no attribute 'text'
2018-11-23 17:36:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/chongming/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_request
    return Selector(request.url, body=body, encoding='utf-8', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\selector\unified.py", line 67, in __init__
    text = response.text
AttributeError: 'str' object has no attribute 'text'
2018-11-23 17:36:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/shanghaizhoubian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_request
    return Selector(request.url, body=body, encoding='utf-8', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\selector\unified.py", line 67, in __init__
    text = response.text
AttributeError: 'str' object has no attribute 'text'
2018-11-23 17:36:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 17:36:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 18,
 'downloader/exception_type_count/builtins.AttributeError': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 9, 36, 13, 778297),
 'log_count/ERROR': 18,
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 23, 9, 35, 44, 670259)}
2018-11-23 17:36:13 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 17:36:32 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-23 17:36:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-23 17:36:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-23 17:36:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 17:36:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 17:36:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 17:36:32 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-23 17:36:32 [scrapy.core.engine] INFO: Spider opened
2018-11-23 17:36:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 17:36:32 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-23 17:37:53 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-23 17:37:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-23 17:37:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-23 17:37:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 17:37:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 17:37:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 17:37:53 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-23 17:37:53 [scrapy.core.engine] INFO: Spider opened
2018-11-23 17:37:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 17:37:53 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-23 17:37:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:37:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/baoshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/xuhui/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/putuo/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/yangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/changning/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/songjiang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jiading/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/huangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jingan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/zhabei/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/hongkou/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/qingpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/fengxian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jinshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/chongming/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/shanghaizhoubian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:24 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 17:38:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 4018275,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 9, 38, 24, 244173),
 'log_count/ERROR': 18,
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 23, 9, 37, 53, 594699)}
2018-11-23 17:38:24 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 17:38:37 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-23 17:38:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-23 17:38:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-23 17:38:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 17:38:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 17:38:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 17:38:38 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-23 17:38:38 [scrapy.core.engine] INFO: Spider opened
2018-11-23 17:38:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 17:38:38 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-23 17:38:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/baoshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/xuhui/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/putuo/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/yangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/changning/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/songjiang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jiading/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:38:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/huangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:39:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jingan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:39:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/zhabei/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:39:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/hongkou/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:39:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/qingpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:39:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/fengxian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:39:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jinshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:39:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/chongming/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:39:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/shanghaizhoubian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:39:10 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 17:39:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 4020017,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 9, 39, 10, 583727),
 'log_count/ERROR': 18,
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 23, 9, 38, 38, 121342)}
2018-11-23 17:39:10 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 17:40:55 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-23 17:40:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-23 17:40:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-23 17:40:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 17:40:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 17:40:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 17:40:55 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-23 17:40:55 [scrapy.core.engine] INFO: Spider opened
2018-11-23 17:40:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 17:40:55 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-23 17:41:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:41:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:41:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/baoshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:41:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/xuhui/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:41:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/putuo/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:41:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/yangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:41:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/changning/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:41:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/songjiang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:41:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jiading/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:41:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/huangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:41:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jingan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:41:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/zhabei/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:41:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/hongkou/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:41:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/qingpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:41:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/fengxian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:41:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jinshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:41:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/chongming/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:41:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/shanghaizhoubian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:41:30 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 17:41:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 4010655,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 9, 41, 30, 493069),
 'log_count/ERROR': 18,
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 23, 9, 40, 55, 633739)}
2018-11-23 17:41:30 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 17:45:03 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-23 17:45:03 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-23 17:45:03 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-23 17:45:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 17:45:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 17:45:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 17:45:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-23 17:45:04 [scrapy.core.engine] INFO: Spider opened
2018-11-23 17:45:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 17:45:04 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-23 17:45:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:45:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:45:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/baoshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:45:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/xuhui/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:45:33 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-23 17:45:33 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-23 17:45:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-23 17:45:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 17:45:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 17:45:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 17:45:33 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-23 17:45:33 [scrapy.core.engine] INFO: Spider opened
2018-11-23 17:45:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 17:45:33 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-23 17:45:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:45:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:45:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/baoshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:45:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/xuhui/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:45:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/putuo/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:45:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/yangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:46:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/changning/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:46:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/songjiang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:46:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jiading/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:46:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/huangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:46:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jingan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:46:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/zhabei/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:46:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/hongkou/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:46:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/qingpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:46:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/fengxian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:46:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jinshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:46:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/chongming/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:46:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/shanghaizhoubian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
TypeError: process_response() got an unexpected keyword argument 'request'
2018-11-23 17:46:24 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 17:46:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3949136,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 9, 46, 24, 337393),
 'log_count/ERROR': 18,
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 23, 9, 45, 33, 976717)}
2018-11-23 17:46:24 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 17:49:19 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-23 17:49:19 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-23 17:49:19 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-23 17:49:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 17:49:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 17:49:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 17:49:20 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-23 17:49:20 [scrapy.core.engine] INFO: Spider opened
2018-11-23 17:49:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 17:49:20 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-23 17:50:10 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 17:50:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 4017832,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 9, 50, 10, 117279),
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 23, 9, 49, 20, 936898)}
2018-11-23 17:50:10 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 17:53:42 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-23 17:53:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-23 17:53:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-23 17:53:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 17:53:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 17:53:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 17:53:43 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-23 17:53:43 [scrapy.core.engine] INFO: Spider opened
2018-11-23 17:53:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 17:53:43 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-23 17:54:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 17:54:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 4013660,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 9, 54, 21, 187678),
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 23, 9, 53, 43, 59620)}
2018-11-23 17:54:21 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 17:54:56 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-23 17:54:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-23 17:54:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-23 17:54:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 17:54:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 17:54:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 17:54:56 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-23 17:54:56 [scrapy.core.engine] INFO: Spider opened
2018-11-23 17:54:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 17:54:56 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-23 17:56:01 [scrapy.extensions.logstats] INFO: Crawled 8 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 17:56:49 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 17:56:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 4011499,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 9, 56, 49, 108401),
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'offsite/domains': 146,
 'offsite/filtered': 10897,
 'request_depth_max': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 23, 9, 54, 56, 653616)}
2018-11-23 17:56:49 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 17:57:41 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-23 17:57:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-23 17:57:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-23 17:57:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 17:57:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 17:57:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 17:57:42 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-23 17:57:42 [scrapy.core.engine] INFO: Spider opened
2018-11-23 17:57:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 17:57:42 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-23 17:58:40 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-23 17:58:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3948550,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 23, 9, 58, 40, 948072),
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 23, 9, 57, 42, 543229)}
2018-11-23 17:58:40 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-23 17:59:10 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-23 17:59:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-23 17:59:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-23 17:59:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-23 17:59:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-23 17:59:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-23 17:59:11 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-23 17:59:11 [scrapy.core.engine] INFO: Spider opened
2018-11-23 17:59:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-23 17:59:11 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-24 12:22:22 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-24 12:22:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-24 12:22:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-24 12:22:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-24 12:22:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-24 12:22:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-24 12:22:23 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-24 12:22:23 [scrapy.core.engine] INFO: Spider opened
2018-11-24 12:22:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-24 12:22:23 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-24 12:23:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-24 12:23:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 4007489,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 24, 4, 23, 4, 634336),
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 24, 4, 22, 23, 671244)}
2018-11-24 12:23:04 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-24 14:09:37 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-24 14:09:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-24 14:09:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-24 14:09:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-24 14:09:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-24 14:09:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-24 14:09:39 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-24 14:09:39 [scrapy.core.engine] INFO: Spider opened
2018-11-24 14:09:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-24 14:09:39 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-24 14:09:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 56, in process_response
    (six.get_method_self(method).__class__.__name__, type(response))
AssertionError: Middleware JavaScriptMiddleware.process_response must return Response or Request, got <class 'NoneType'>
2018-11-24 14:09:51 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 56, in process_response
    (six.get_method_self(method).__class__.__name__, type(response))
AssertionError: Middleware JavaScriptMiddleware.process_response must return Response or Request, got <class 'NoneType'>
2018-11-24 14:09:56 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/baoshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 56, in process_response
    (six.get_method_self(method).__class__.__name__, type(response))
AssertionError: Middleware JavaScriptMiddleware.process_response must return Response or Request, got <class 'NoneType'>
2018-11-24 14:10:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/xuhui/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 56, in process_response
    (six.get_method_self(method).__class__.__name__, type(response))
AssertionError: Middleware JavaScriptMiddleware.process_response must return Response or Request, got <class 'NoneType'>
2018-11-24 14:10:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/putuo/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 56, in process_response
    (six.get_method_self(method).__class__.__name__, type(response))
AssertionError: Middleware JavaScriptMiddleware.process_response must return Response or Request, got <class 'NoneType'>
2018-11-24 14:10:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/yangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 56, in process_response
    (six.get_method_self(method).__class__.__name__, type(response))
AssertionError: Middleware JavaScriptMiddleware.process_response must return Response or Request, got <class 'NoneType'>
2018-11-24 14:10:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/changning/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 56, in process_response
    (six.get_method_self(method).__class__.__name__, type(response))
AssertionError: Middleware JavaScriptMiddleware.process_response must return Response or Request, got <class 'NoneType'>
2018-11-24 14:10:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/songjiang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 56, in process_response
    (six.get_method_self(method).__class__.__name__, type(response))
AssertionError: Middleware JavaScriptMiddleware.process_response must return Response or Request, got <class 'NoneType'>
2018-11-24 14:10:37 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-24 14:10:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-24 14:10:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-24 14:10:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jiading/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 56, in process_response
    (six.get_method_self(method).__class__.__name__, type(response))
AssertionError: Middleware JavaScriptMiddleware.process_response must return Response or Request, got <class 'NoneType'>
2018-11-24 14:10:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-24 14:10:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-24 14:10:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-24 14:10:37 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-24 14:10:37 [scrapy.core.engine] INFO: Spider opened
2018-11-24 14:10:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-24 14:10:37 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-24 14:10:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/huangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 56, in process_response
    (six.get_method_self(method).__class__.__name__, type(response))
AssertionError: Middleware JavaScriptMiddleware.process_response must return Response or Request, got <class 'NoneType'>
2018-11-24 14:10:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-24 14:10:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jingan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 56, in process_response
    (six.get_method_self(method).__class__.__name__, type(response))
AssertionError: Middleware JavaScriptMiddleware.process_response must return Response or Request, got <class 'NoneType'>
2018-11-24 14:10:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/zhabei/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 56, in process_response
    (six.get_method_self(method).__class__.__name__, type(response))
AssertionError: Middleware JavaScriptMiddleware.process_response must return Response or Request, got <class 'NoneType'>
2018-11-24 14:10:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/hongkou/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 56, in process_response
    (six.get_method_self(method).__class__.__name__, type(response))
AssertionError: Middleware JavaScriptMiddleware.process_response must return Response or Request, got <class 'NoneType'>
2018-11-24 14:11:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/qingpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 56, in process_response
    (six.get_method_self(method).__class__.__name__, type(response))
AssertionError: Middleware JavaScriptMiddleware.process_response must return Response or Request, got <class 'NoneType'>
2018-11-24 14:11:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/fengxian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 56, in process_response
    (six.get_method_self(method).__class__.__name__, type(response))
AssertionError: Middleware JavaScriptMiddleware.process_response must return Response or Request, got <class 'NoneType'>
2018-11-24 14:11:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jinshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 56, in process_response
    (six.get_method_self(method).__class__.__name__, type(response))
AssertionError: Middleware JavaScriptMiddleware.process_response must return Response or Request, got <class 'NoneType'>
2018-11-24 14:11:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/chongming/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 56, in process_response
    (six.get_method_self(method).__class__.__name__, type(response))
AssertionError: Middleware JavaScriptMiddleware.process_response must return Response or Request, got <class 'NoneType'>
2018-11-24 14:11:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/shanghaizhoubian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 56, in process_response
    (six.get_method_self(method).__class__.__name__, type(response))
AssertionError: Middleware JavaScriptMiddleware.process_response must return Response or Request, got <class 'NoneType'>
2018-11-24 14:11:26 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-24 14:11:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3943503,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 24, 6, 11, 26, 587622),
 'log_count/ERROR': 18,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 24, 6, 9, 39, 120859)}
2018-11-24 14:11:26 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-24 14:11:41 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-24 14:11:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-24 14:11:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-24 14:11:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-24 14:11:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-24 14:11:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-24 14:11:41 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-24 14:11:41 [scrapy.core.engine] INFO: Spider opened
2018-11-24 14:11:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-24 14:11:41 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-24 14:12:23 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-24 14:12:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-24 14:12:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-24 14:12:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-24 14:12:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-24 14:12:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-24 14:12:23 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-24 14:12:23 [scrapy.core.engine] INFO: Spider opened
2018-11-24 14:12:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-24 14:12:23 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-24 14:12:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_response
    return response.content
AttributeError: 'HtmlResponse' object has no attribute 'content'
2018-11-24 14:12:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_response
    return response.content
AttributeError: 'HtmlResponse' object has no attribute 'content'
2018-11-24 14:12:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/baoshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_response
    return response.content
AttributeError: 'HtmlResponse' object has no attribute 'content'
2018-11-24 14:12:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/xuhui/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_response
    return response.content
AttributeError: 'HtmlResponse' object has no attribute 'content'
2018-11-24 14:13:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/putuo/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_response
    return response.content
AttributeError: 'HtmlResponse' object has no attribute 'content'
2018-11-24 14:13:02 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/yangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_response
    return response.content
AttributeError: 'HtmlResponse' object has no attribute 'content'
2018-11-24 14:13:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/changning/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_response
    return response.content
AttributeError: 'HtmlResponse' object has no attribute 'content'
2018-11-24 14:13:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/songjiang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_response
    return response.content
AttributeError: 'HtmlResponse' object has no attribute 'content'
2018-11-24 14:13:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jiading/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_response
    return response.content
AttributeError: 'HtmlResponse' object has no attribute 'content'
2018-11-24 14:13:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/huangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_response
    return response.content
AttributeError: 'HtmlResponse' object has no attribute 'content'
2018-11-24 14:13:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jingan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_response
    return response.content
AttributeError: 'HtmlResponse' object has no attribute 'content'
2018-11-24 14:13:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/zhabei/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_response
    return response.content
AttributeError: 'HtmlResponse' object has no attribute 'content'
2018-11-24 14:13:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-24 14:13:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/hongkou/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_response
    return response.content
AttributeError: 'HtmlResponse' object has no attribute 'content'
2018-11-24 14:13:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/qingpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_response
    return response.content
AttributeError: 'HtmlResponse' object has no attribute 'content'
2018-11-24 14:13:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/fengxian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_response
    return response.content
AttributeError: 'HtmlResponse' object has no attribute 'content'
2018-11-24 14:13:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jinshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_response
    return response.content
AttributeError: 'HtmlResponse' object has no attribute 'content'
2018-11-24 14:13:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/chongming/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_response
    return response.content
AttributeError: 'HtmlResponse' object has no attribute 'content'
2018-11-24 14:13:44 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/shanghaizhoubian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 32, in process_response
    return response.content
AttributeError: 'HtmlResponse' object has no attribute 'content'
2018-11-24 14:13:44 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-24 14:13:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3943493,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 24, 6, 13, 44, 210243),
 'log_count/ERROR': 18,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 24, 6, 12, 23, 787833)}
2018-11-24 14:13:44 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-24 14:14:17 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-24 14:14:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-24 14:14:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-24 14:14:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-24 14:14:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-24 14:14:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-24 14:14:17 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-24 14:14:17 [scrapy.core.engine] INFO: Spider opened
2018-11-24 14:14:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-24 14:14:17 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-24 14:17:34 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-24 14:17:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-24 14:17:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-24 14:17:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-24 14:17:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-24 14:17:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-24 14:17:34 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-24 14:17:34 [scrapy.core.engine] INFO: Spider opened
2018-11-24 14:17:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-24 14:17:34 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-24 14:18:37 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2018-11-24 14:19:50 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2018-11-24 14:20:40 [scrapy.extensions.logstats] INFO: Crawled 17 pages (at 6 pages/min), scraped 0 items (at 0 items/min)
2018-11-24 14:20:48 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-24 14:20:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3939939,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 24, 6, 20, 48, 583276),
 'log_count/INFO': 10,
 'log_count/WARNING': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 24, 6, 17, 34, 882655)}
2018-11-24 14:20:48 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-25 09:35:13 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-25 09:35:13 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-25 09:35:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-25 09:35:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-25 09:35:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-25 09:35:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-25 09:35:15 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-25 09:35:15 [scrapy.core.engine] INFO: Spider opened
2018-11-25 09:35:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-25 09:35:15 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-25 09:36:22 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-25 09:36:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-25 09:36:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-25 09:36:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-25 09:36:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-25 09:36:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-25 09:36:23 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-25 09:36:23 [scrapy.core.engine] INFO: Spider opened
2018-11-25 09:36:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-25 09:36:23 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-25 09:37:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-25 09:37:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 4013578,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 25, 1, 37, 14, 366485),
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'offsite/domains': 142,
 'offsite/filtered': 10852,
 'request_depth_max': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 25, 1, 36, 23, 203678)}
2018-11-25 09:37:14 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-25 09:38:49 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-25 09:38:49 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-25 09:38:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-25 09:38:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-25 09:38:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-25 09:38:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-25 09:38:50 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-25 09:38:50 [scrapy.core.engine] INFO: Spider opened
2018-11-25 09:38:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-25 09:38:51 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-25 09:39:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-25 09:39:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 4012204,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 25, 1, 39, 21, 272577),
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'offsite/domains': 142,
 'offsite/filtered': 10847,
 'request_depth_max': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 25, 1, 38, 51, 53046)}
2018-11-25 09:39:21 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-25 09:40:26 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-25 09:40:26 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-25 09:40:26 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-25 09:40:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-25 09:40:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-25 09:40:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-25 09:40:26 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-25 09:40:26 [scrapy.core.engine] INFO: Spider opened
2018-11-25 09:40:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-25 09:40:26 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-25 09:41:29 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-25 09:41:29 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-25 09:41:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-25 09:41:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-25 09:41:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-25 09:41:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-25 09:41:30 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-25 09:41:30 [scrapy.core.engine] INFO: Spider opened
2018-11-25 09:41:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-25 09:41:30 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-25 09:52:29 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2018-11-25 14:04:58 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-25 14:04:58 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-25 14:04:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-25 14:04:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-25 14:04:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-25 14:04:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-25 14:04:59 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-25 14:04:59 [scrapy.core.engine] INFO: Spider opened
2018-11-25 14:04:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-25 14:04:59 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-25 14:06:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-25 14:06:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1666-1667: ordinal not in range(128)
2018-11-25 14:06:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1668-1669: ordinal not in range(128)
2018-11-25 14:06:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/baoshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1668-1669: ordinal not in range(128)
2018-11-25 14:06:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/xuhui/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1664-1665: ordinal not in range(128)
2018-11-25 14:06:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/putuo/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1664-1665: ordinal not in range(128)
2018-11-25 14:06:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/yangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1666-1667: ordinal not in range(128)
2018-11-25 14:06:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/changning/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1672-1673: ordinal not in range(128)
2018-11-25 14:06:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/songjiang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1672-1673: ordinal not in range(128)
2018-11-25 14:06:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jiading/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1668-1669: ordinal not in range(128)
2018-11-25 14:06:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/huangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1668-1669: ordinal not in range(128)
2018-11-25 14:06:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jingan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1666-1667: ordinal not in range(128)
2018-11-25 14:06:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/zhabei/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1666-1667: ordinal not in range(128)
2018-11-25 14:06:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/hongkou/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1668-1669: ordinal not in range(128)
2018-11-25 14:06:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/qingpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1666-1667: ordinal not in range(128)
2018-11-25 14:06:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/fengxian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1670-1671: ordinal not in range(128)
2018-11-25 14:06:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jinshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1668-1669: ordinal not in range(128)
2018-11-25 14:06:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/chongming/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1672-1673: ordinal not in range(128)
2018-11-25 14:06:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/shanghaizhoubian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1686-1687: ordinal not in range(128)
2018-11-25 14:06:42 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-25 14:06:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 18,
 'downloader/exception_type_count/builtins.UnicodeEncodeError': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 25, 6, 6, 42, 696301),
 'log_count/ERROR': 18,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 25, 6, 4, 59, 745401)}
2018-11-25 14:06:42 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-25 14:21:18 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-25 14:21:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-25 14:21:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-25 14:21:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-25 14:21:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-25 14:21:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-25 14:21:20 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-25 14:21:20 [scrapy.core.engine] INFO: Spider opened
2018-11-25 14:21:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-25 14:21:20 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-25 14:21:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1666-1667: ordinal not in range(128)
2018-11-25 14:21:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1668-1669: ordinal not in range(128)
2018-11-25 14:21:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/baoshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1668-1669: ordinal not in range(128)
2018-11-25 14:21:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/xuhui/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1664-1665: ordinal not in range(128)
2018-11-25 14:21:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/putuo/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1664-1665: ordinal not in range(128)
2018-11-25 14:22:13 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-25 14:22:13 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-25 14:22:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-25 14:22:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-25 14:22:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-25 14:22:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-25 14:22:14 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-25 14:22:14 [scrapy.core.engine] INFO: Spider opened
2018-11-25 14:22:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-25 14:22:14 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-25 14:22:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1666-1667: ordinal not in range(128)
2018-11-25 14:22:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1668-1669: ordinal not in range(128)
2018-11-25 14:22:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/baoshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1668-1669: ordinal not in range(128)
2018-11-25 14:22:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/xuhui/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1664-1665: ordinal not in range(128)
2018-11-25 14:22:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/putuo/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1664-1665: ordinal not in range(128)
2018-11-25 14:22:34 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/yangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1666-1667: ordinal not in range(128)
2018-11-25 14:22:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/changning/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1672-1673: ordinal not in range(128)
2018-11-25 14:22:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/songjiang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1672-1673: ordinal not in range(128)
2018-11-25 14:22:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jiading/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1668-1669: ordinal not in range(128)
2018-11-25 14:22:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/huangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1668-1669: ordinal not in range(128)
2018-11-25 14:22:58 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-25 14:22:58 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-25 14:22:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-25 14:22:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-25 14:22:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-25 14:22:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-25 14:22:58 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-25 14:22:58 [scrapy.core.engine] INFO: Spider opened
2018-11-25 14:22:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-25 14:22:58 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-25 14:23:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1666-1667: ordinal not in range(128)
2018-11-25 14:23:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1668-1669: ordinal not in range(128)
2018-11-25 14:23:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/baoshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1668-1669: ordinal not in range(128)
2018-11-25 14:23:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/xuhui/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1664-1665: ordinal not in range(128)
2018-11-25 14:23:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/putuo/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1664-1665: ordinal not in range(128)
2018-11-25 14:23:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/yangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1666-1667: ordinal not in range(128)
2018-11-25 14:23:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/changning/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1672-1673: ordinal not in range(128)
2018-11-25 14:23:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/songjiang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1672-1673: ordinal not in range(128)
2018-11-25 14:23:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jiading/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1668-1669: ordinal not in range(128)
2018-11-25 14:23:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/huangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1668-1669: ordinal not in range(128)
2018-11-25 14:23:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jingan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1666-1667: ordinal not in range(128)
2018-11-25 14:23:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/zhabei/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1666-1667: ordinal not in range(128)
2018-11-25 14:23:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/hongkou/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1668-1669: ordinal not in range(128)
2018-11-25 14:23:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/qingpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1666-1667: ordinal not in range(128)
2018-11-25 14:23:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/fengxian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1670-1671: ordinal not in range(128)
2018-11-25 14:23:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jinshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1668-1669: ordinal not in range(128)
2018-11-25 14:23:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/chongming/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1672-1673: ordinal not in range(128)
2018-11-25 14:23:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/shanghaizhoubian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return HtmlResponse(spider.driver.current_url, body=body, encoding='ascii', request=request)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 31, in __init__
    super(TextResponse, self).__init__(*args, **kwargs)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\__init__.py", line 22, in __init__
    self._set_body(body)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\response\text.py", line 48, in _set_body
    self._body = body.encode(self._encoding)
UnicodeEncodeError: 'ascii' codec can't encode characters in position 1686-1687: ordinal not in range(128)
2018-11-25 14:23:42 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-25 14:23:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 18,
 'downloader/exception_type_count/builtins.UnicodeEncodeError': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 25, 6, 23, 42, 793367),
 'log_count/ERROR': 18,
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 25, 6, 22, 58, 770517)}
2018-11-25 14:23:42 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-25 14:24:04 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-25 14:24:04 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-25 14:24:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-25 14:24:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-25 14:24:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-25 14:24:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-25 14:24:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-25 14:24:04 [scrapy.core.engine] INFO: Spider opened
2018-11-25 14:24:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-25 14:24:04 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-25 14:26:06 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 0 items (at 0 items/min)
2018-11-25 14:27:41 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-25 14:27:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-25 14:27:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-25 14:27:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-25 14:27:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-25 14:27:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-25 14:27:41 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-25 14:27:41 [scrapy.core.engine] INFO: Spider opened
2018-11-25 14:27:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-25 14:27:41 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-25 14:33:09 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-25 14:33:09 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-25 14:33:09 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-25 14:33:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-25 14:33:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-25 14:33:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-25 14:33:10 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-25 14:33:10 [scrapy.core.engine] INFO: Spider opened
2018-11-25 14:33:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-25 14:33:10 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-25 14:33:49 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-25 14:33:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3942084,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 25, 6, 33, 49, 763732),
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'offsite/domains': 139,
 'offsite/filtered': 10119,
 'request_depth_max': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 25, 6, 33, 10, 340324)}
2018-11-25 14:33:49 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-25 14:37:59 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-25 14:37:59 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-25 14:37:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-25 14:37:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-25 14:38:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-25 14:38:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-25 14:38:00 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-25 14:38:00 [scrapy.core.engine] INFO: Spider opened
2018-11-25 14:38:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-25 14:38:00 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-25 14:38:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return Request(spider.driver.current_url, body=body, encoding='utf-8', request=request)
TypeError: __init__() got an unexpected keyword argument 'request'
2018-11-25 14:38:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return Request(spider.driver.current_url, body=body, encoding='utf-8', request=request)
TypeError: __init__() got an unexpected keyword argument 'request'
2018-11-25 14:38:08 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/baoshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return Request(spider.driver.current_url, body=body, encoding='utf-8', request=request)
TypeError: __init__() got an unexpected keyword argument 'request'
2018-11-25 14:38:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/xuhui/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return Request(spider.driver.current_url, body=body, encoding='utf-8', request=request)
TypeError: __init__() got an unexpected keyword argument 'request'
2018-11-25 14:38:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/putuo/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return Request(spider.driver.current_url, body=body, encoding='utf-8', request=request)
TypeError: __init__() got an unexpected keyword argument 'request'
2018-11-25 14:38:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/yangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return Request(spider.driver.current_url, body=body, encoding='utf-8', request=request)
TypeError: __init__() got an unexpected keyword argument 'request'
2018-11-25 14:38:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/changning/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return Request(spider.driver.current_url, body=body, encoding='utf-8', request=request)
TypeError: __init__() got an unexpected keyword argument 'request'
2018-11-25 14:38:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/songjiang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return Request(spider.driver.current_url, body=body, encoding='utf-8', request=request)
TypeError: __init__() got an unexpected keyword argument 'request'
2018-11-25 14:38:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jiading/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return Request(spider.driver.current_url, body=body, encoding='utf-8', request=request)
TypeError: __init__() got an unexpected keyword argument 'request'
2018-11-25 14:38:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/huangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return Request(spider.driver.current_url, body=body, encoding='utf-8', request=request)
TypeError: __init__() got an unexpected keyword argument 'request'
2018-11-25 14:38:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jingan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return Request(spider.driver.current_url, body=body, encoding='utf-8', request=request)
TypeError: __init__() got an unexpected keyword argument 'request'
2018-11-25 14:38:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/zhabei/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return Request(spider.driver.current_url, body=body, encoding='utf-8', request=request)
TypeError: __init__() got an unexpected keyword argument 'request'
2018-11-25 14:38:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/hongkou/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return Request(spider.driver.current_url, body=body, encoding='utf-8', request=request)
TypeError: __init__() got an unexpected keyword argument 'request'
2018-11-25 14:38:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/qingpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return Request(spider.driver.current_url, body=body, encoding='utf-8', request=request)
TypeError: __init__() got an unexpected keyword argument 'request'
2018-11-25 14:38:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/fengxian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return Request(spider.driver.current_url, body=body, encoding='utf-8', request=request)
TypeError: __init__() got an unexpected keyword argument 'request'
2018-11-25 14:38:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jinshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return Request(spider.driver.current_url, body=body, encoding='utf-8', request=request)
TypeError: __init__() got an unexpected keyword argument 'request'
2018-11-25 14:38:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/chongming/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return Request(spider.driver.current_url, body=body, encoding='utf-8', request=request)
TypeError: __init__() got an unexpected keyword argument 'request'
2018-11-25 14:38:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/shanghaizhoubian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\middleware\middlwares.py", line 27, in process_request
    return Request(spider.driver.current_url, body=body, encoding='utf-8', request=request)
TypeError: __init__() got an unexpected keyword argument 'request'
2018-11-25 14:38:33 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-25 14:38:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 18,
 'downloader/exception_type_count/builtins.TypeError': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 25, 6, 38, 33, 27792),
 'log_count/ERROR': 18,
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 25, 6, 38, 0, 429144)}
2018-11-25 14:38:33 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-25 14:44:03 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-25 14:44:03 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-25 14:44:03 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-25 14:44:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-25 14:44:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-25 14:44:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-25 14:44:04 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-25 14:44:04 [scrapy.core.engine] INFO: Spider opened
2018-11-25 14:44:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-25 14:44:04 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-25 14:46:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-25 14:47:09 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-25 14:47:09 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-25 14:47:09 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-25 14:47:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-25 14:47:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-25 14:47:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-25 14:47:10 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-25 14:47:10 [scrapy.core.engine] INFO: Spider opened
2018-11-25 14:47:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-25 14:47:10 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-25 14:47:50 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-25 14:47:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 4010968,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 25, 6, 47, 50, 542456),
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'offsite/domains': 139,
 'offsite/filtered': 10846,
 'request_depth_max': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 25, 6, 47, 10, 908456)}
2018-11-25 14:47:50 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-25 14:57:29 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-25 14:57:29 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-25 14:57:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-25 14:57:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-25 14:57:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-25 14:57:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-25 14:57:30 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-25 14:57:30 [scrapy.core.engine] INFO: Spider opened
2018-11-25 14:57:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-25 14:57:30 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-25 14:58:01 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-25 14:58:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 4004578,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 25, 6, 58, 1, 670533),
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'offsite/domains': 1,
 'offsite/filtered': 18,
 'request_depth_max': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 25, 6, 57, 30, 439996)}
2018-11-25 14:58:01 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 10:19:29 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 10:19:29 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 10:19:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 10:19:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 10:19:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['lianjia.middleware.middlwares.JavaScriptMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 10:19:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 10:19:30 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 10:19:30 [scrapy.core.engine] INFO: Spider opened
2018-11-28 10:19:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 10:19:31 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-28 10:19:56 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 10:19:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 4006109,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 2, 19, 56, 32549),
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'offsite/domains': 1,
 'offsite/filtered': 18,
 'request_depth_max': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 28, 2, 19, 31, 121635)}
2018-11-28 10:19:56 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 10:23:48 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 10:23:48 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 10:23:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 10:23:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 10:23:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 10:23:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 10:23:49 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 10:23:49 [scrapy.core.engine] INFO: Spider opened
2018-11-28 10:23:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 10:23:49 [old_house] INFO: Spider opened: old_house
2018-11-28 10:23:49 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-28 10:24:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 10:24:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3941097,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 2, 24, 14, 297727),
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'offsite/domains': 1,
 'offsite/filtered': 18,
 'request_depth_max': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 28, 2, 23, 49, 273864)}
2018-11-28 10:24:14 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 10:34:29 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 10:34:29 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 10:34:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 10:34:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 10:34:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 10:34:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 10:34:30 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 10:34:30 [scrapy.core.engine] INFO: Spider opened
2018-11-28 10:34:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 10:34:30 [old_house] INFO: Spider opened: old_house
2018-11-28 10:34:30 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py:59: URLWarning: allowed_domains accepts only domains, not URLs. Ignoring URL entry https://sh.lianjia.com/ershoufang/ in allowed_domains.
  warnings.warn("allowed_domains accepts only domains, not URLs. Ignoring URL entry %s in allowed_domains." % domain, URLWarning)

2018-11-28 10:34:53 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 10:34:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3937866,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 2, 34, 53, 757731),
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'offsite/domains': 1,
 'offsite/filtered': 215,
 'request_depth_max': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 28, 2, 34, 30, 202272)}
2018-11-28 10:34:53 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 10:36:30 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 10:36:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 10:36:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 10:36:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 10:36:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 10:36:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 10:36:31 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 10:36:31 [scrapy.core.engine] INFO: Spider opened
2018-11-28 10:36:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 10:36:31 [old_house] INFO: Spider opened: old_house
2018-11-28 10:38:16 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 10:38:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 10:38:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 10:38:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 10:38:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 10:38:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 10:38:16 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 10:38:16 [scrapy.core.engine] INFO: Spider opened
2018-11-28 10:38:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 10:38:16 [old_house] INFO: Spider opened: old_house
2018-11-28 10:38:43 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 10:38:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3947134,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 2, 38, 43, 229917),
 'log_count/INFO': 8,
 'offsite/domains': 1,
 'offsite/filtered': 215,
 'request_depth_max': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 28, 2, 38, 16, 780645)}
2018-11-28 10:38:43 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 10:39:01 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 10:39:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 10:39:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 10:39:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 10:39:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 10:39:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 10:39:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 10:39:02 [scrapy.core.engine] INFO: Spider opened
2018-11-28 10:39:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 10:39:02 [old_house] INFO: Spider opened: old_house
2018-11-28 10:39:28 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 10:39:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 3944313,
 'downloader/response_count': 18,
 'downloader/response_status_count/200': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 2, 39, 28, 616232),
 'log_count/INFO': 8,
 'offsite/domains': 1,
 'offsite/filtered': 215,
 'request_depth_max': 1,
 'response_received_count': 18,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 28, 2, 39, 2, 253041)}
2018-11-28 10:39:28 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 10:45:32 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 10:45:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 10:45:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 10:45:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 10:45:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 10:45:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 10:45:33 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 10:45:33 [scrapy.core.engine] INFO: Spider opened
2018-11-28 10:45:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 10:45:34 [old_house] INFO: Spider opened: old_house
2018-11-28 10:47:37 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 10:47:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 10:47:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 10:47:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 10:47:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 10:47:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 10:47:38 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 10:47:38 [scrapy.core.engine] INFO: Spider opened
2018-11-28 10:47:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 10:47:38 [old_house] INFO: Spider opened: old_house
2018-11-28 10:53:00 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 10:53:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 10:53:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 10:53:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 10:53:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 10:53:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 10:53:00 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 10:53:00 [scrapy.core.engine] INFO: Spider opened
2018-11-28 10:53:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 10:53:00 [old_house] INFO: Spider opened: old_house
2018-11-28 10:53:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/beicai/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:53:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/waigaoqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:53:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tangqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:53:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tangzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:53:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shuyuanzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:53:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shibo/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:53:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/sanlin/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:53:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nanmatou/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 10:53:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nichengzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:53:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lianyang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:53:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lingangxincheng/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:53:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/laogangzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:53:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lujiazui/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:53:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kangqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:53:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinyang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:53:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huinan/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:53:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:53:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hangtou/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:53:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huamu/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:53:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/dahua/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:53:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhoupu/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changqiao/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:10 [scrapy.extensions.logstats] INFO: Crawled 48 pages (at 48 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 10:54:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kangjian/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jianguoxilu/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hengshanlu/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhiwuyuan/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xietulu/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xujiahui/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xuhuibinjiang/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tianlin/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wantiguan/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shanghainanzhan/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/longhua/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huajing/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huadongligong/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caohejing/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhangmiao/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yanghang/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yuepu/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tonghe/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shangda/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/songnan/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/songbao/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/luodian/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/luojing/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaojing/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gucun/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gongkang/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gongfu/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/dachangzhen/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhuqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhangjiang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yangjing/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yuanshen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yangdong/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yuqiao1/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinchang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xuanqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/weifang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wanxiangzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhuanqiao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinzhuang5/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wujing/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/qibao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/pujiang1/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/meilong/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:54:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/maqiao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/laominhang/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:13 [scrapy.extensions.logstats] INFO: Crawled 89 pages (at 41 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 10:55:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/longbai/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinhongqiao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinganxincheng/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinhui/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huacao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hanghua/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chuansha/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/datuanzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chunshen/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/geqing/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaohang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gumei/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaodong/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/biyun/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caolu/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changshoulu/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenru/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhongyuanliangwancheng/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenguang/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wanli/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wuning/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/ganquanyichuan/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/taopu/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/guangxin/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changzheng/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changfeng1/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caoyang/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/anshan/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/beixinjing/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhongyuan1/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhoujiazuilu/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinjiangwancheng/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kongjianglu/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wujiaochang/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:55:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huangxinggongyuan/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chedun/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:21 [scrapy.extensions.logstats] INFO: Crawled 137 pages (at 48 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 10:56:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/anting/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jiadingxincheng/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jiadinglaocheng/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huating/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/fengzhuang/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinbang/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 10:56:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yexie/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xiaokunshan/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinqiao/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/songjianglaocheng/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/sijing/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/songjiangdaxuecheng/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/sheshan/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/songjiangxincheng/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shenminbieshu/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xuxing/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinchenglu1/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/waigang/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/malu/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nanxiang/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jiangqiao/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/juyuanxinqu/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shihudang/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 10:56:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/maogang/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 10:56:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jiuting/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhongshangongyuan/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenninglu/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xianxia/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinhualu/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xijiao/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tianshan/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hongqiao1/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gubei/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:56:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/dongwaitan/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:12 [scrapy.extensions.logstats] INFO: Crawled 170 pages (at 33 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 10:57:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/dapuqiao/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xintiandi/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yuyuan/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wuliqiao/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shibobinjiang/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/renminguangchang/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/penglaigongyuan/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nanjingdonglu/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/laoximen/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huaihaizhonglu/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huangpubinjiang/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/dongjiadu/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caojiadu/> (referer: https://sh.lianjia.com/ershoufang/jingan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nanjingxilu/> (referer: https://sh.lianjia.com/ershoufang/jingan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jiangninglu/> (referer: https://sh.lianjia.com/ershoufang/jingan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jingansi/> (referer: https://sh.lianjia.com/ershoufang/jingan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/buyecheng/> (referer: https://sh.lianjia.com/ershoufang/zhabei/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/beiwaitan/> (referer: https://sh.lianjia.com/ershoufang/hongkou/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhabeigongyuan/> (referer: https://sh.lianjia.com/ershoufang/zhabei/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yangcheng/> (referer: https://sh.lianjia.com/ershoufang/zhabei/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/fengxianjinhui/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhujiajiao/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhaoxiang/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xianghuaqiao/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yingpu/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xujing/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xiayang/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/liantang1/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinze/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huaxin/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chonggu/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/sichuanbeilu/> (referer: https://sh.lianjia.com/ershoufang/hongkou/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/quyang/> (referer: https://sh.lianjia.com/ershoufang/hongkou/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/linpinglu/> (referer: https://sh.lianjia.com/ershoufang/hongkou/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/baihe/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhuanghang/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhelin/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xidu/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/situan/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/qingcun/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nanqiao/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/haiwan/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:57:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/fengcheng/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/liangcheng/> (referer: https://sh.lianjia.com/ershoufang/hongkou/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:06 [scrapy.extensions.logstats] INFO: Crawled 205 pages (at 35 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 10:58:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/luxungongyuan/> (referer: https://sh.lianjia.com/ershoufang/hongkou/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jiangwanzhen/> (referer: https://sh.lianjia.com/ershoufang/hongkou/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yonghe/> (referer: https://sh.lianjia.com/ershoufang/zhabei/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xizangbeilu/> (referer: https://sh.lianjia.com/ershoufang/zhabei/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/pengpu/> (referer: https://sh.lianjia.com/ershoufang/zhabei/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/daning/> (referer: https://sh.lianjia.com/ershoufang/zhabei/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caojing/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/baozhen/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 10:58:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhujing/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhangyan/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tinglin/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shanyang/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shihua/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/langxia/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/luxiang/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinshan1/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/fengjing/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hengshadao/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 10:58:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chongmingqita/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chongmingxincheng/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chenjiazhen/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changxingdao21211/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changshushi/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 10:58:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wuxishi/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 10:58:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/taicang212/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 10:58:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/suzhou/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shanghaizhoubian2/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 10:58:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/qidong1/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nantong/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 10:58:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kunshan1/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jiaxing/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/haimen/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 81, in _parse_response
    cb_res = callback(response, **cb_kwargs) or ()
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 49, in parse_item
    print(json.dumps(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage'])
TypeError: string indices must be integers
2018-11-28 10:58:46 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 10:58:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 49567721,
 'downloader/response_count': 232,
 'downloader/response_status_count/200': 232,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 2, 58, 46, 308029),
 'log_count/ERROR': 214,
 'log_count/INFO': 13,
 'request_depth_max': 1,
 'response_received_count': 232,
 'scheduler/dequeued': 232,
 'scheduler/dequeued/memory': 232,
 'scheduler/enqueued': 232,
 'scheduler/enqueued/memory': 232,
 'spider_exceptions/IndexError': 11,
 'spider_exceptions/TypeError': 203,
 'start_time': datetime.datetime(2018, 11, 28, 2, 53, 0, 743157)}
2018-11-28 10:58:46 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 11:03:35 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 11:03:35 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 11:03:35 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 11:03:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 11:03:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 11:03:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 11:03:36 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 11:03:36 [scrapy.core.engine] INFO: Spider opened
2018-11-28 11:03:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 11:03:36 [old_house] INFO: Spider opened: old_house
2018-11-28 12:49:30 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 12:49:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 12:49:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 12:49:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 12:49:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 12:49:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 12:49:32 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 12:49:32 [scrapy.core.engine] INFO: Spider opened
2018-11-28 12:49:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 12:49:32 [old_house] INFO: Spider opened: old_house
2018-11-28 12:50:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/beicai/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/minhang/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/weifang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wanxiangzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/waigaoqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tangzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tangqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shuyuanzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shibo/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/sanlin/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nanmatou/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nichengzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lianyang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lingangxincheng/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/laogangzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lujiazui/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kangqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinyang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huinan/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/dahua/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhuanqiao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:50 [scrapy.extensions.logstats] INFO: Crawled 49 pages (at 49 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 12:50:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changqiao/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhiwuyuan/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xietulu/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xujiahui/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xuhuibinjiang/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wantiguan/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tianlin/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shanghainanzhan/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/longhua/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kangjian/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jianguoxilu/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hengshanlu/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huajing/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caohejing/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huadongligong/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhangmiao/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yanghang/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yuepu/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tonghe/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shangda/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 12:50:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/songnan/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:02:25 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 13:02:25 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 13:02:25 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 13:02:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 13:02:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 13:02:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 13:02:25 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 13:02:25 [scrapy.core.engine] INFO: Spider opened
2018-11-28 13:02:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 13:02:25 [old_house] INFO: Spider opened: old_house
2018-11-28 13:02:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/putuo/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware LianjiaDownloaderMiddleware.process_request must return None, Response or Request, got generator
2018-11-28 13:02:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/changning/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware LianjiaDownloaderMiddleware.process_request must return None, Response or Request, got generator
2018-11-28 13:02:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/yangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware LianjiaDownloaderMiddleware.process_request must return None, Response or Request, got generator
2018-11-28 13:02:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/pudong/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware LianjiaDownloaderMiddleware.process_request must return None, Response or Request, got generator
2018-11-28 13:02:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/baoshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware LianjiaDownloaderMiddleware.process_request must return None, Response or Request, got generator
2018-11-28 13:02:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/minhang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware LianjiaDownloaderMiddleware.process_request must return None, Response or Request, got generator
2018-11-28 13:02:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/xuhui/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware LianjiaDownloaderMiddleware.process_request must return None, Response or Request, got generator
2018-11-28 13:02:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/huangpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware LianjiaDownloaderMiddleware.process_request must return None, Response or Request, got generator
2018-11-28 13:02:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/songjiang/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware LianjiaDownloaderMiddleware.process_request must return None, Response or Request, got generator
2018-11-28 13:02:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jiading/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware LianjiaDownloaderMiddleware.process_request must return None, Response or Request, got generator
2018-11-28 13:02:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jingan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware LianjiaDownloaderMiddleware.process_request must return None, Response or Request, got generator
2018-11-28 13:02:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/zhabei/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware LianjiaDownloaderMiddleware.process_request must return None, Response or Request, got generator
2018-11-28 13:02:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/shanghaizhoubian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware LianjiaDownloaderMiddleware.process_request must return None, Response or Request, got generator
2018-11-28 13:02:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/hongkou/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware LianjiaDownloaderMiddleware.process_request must return None, Response or Request, got generator
2018-11-28 13:02:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/qingpu/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware LianjiaDownloaderMiddleware.process_request must return None, Response or Request, got generator
2018-11-28 13:02:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/fengxian/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware LianjiaDownloaderMiddleware.process_request must return None, Response or Request, got generator
2018-11-28 13:02:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/chongming/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware LianjiaDownloaderMiddleware.process_request must return None, Response or Request, got generator
2018-11-28 13:02:26 [scrapy.core.scraper] ERROR: Error downloading <GET https://sh.lianjia.com/ershoufang/jinshan/>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 40, in process_request
    (six.get_method_self(method).__class__.__name__, response.__class__.__name__)
AssertionError: Middleware LianjiaDownloaderMiddleware.process_request must return None, Response or Request, got generator
2018-11-28 13:02:26 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 13:02:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 18,
 'downloader/exception_type_count/builtins.AssertionError': 18,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 5, 2, 26, 174586),
 'log_count/ERROR': 18,
 'log_count/INFO': 8,
 'scheduler/dequeued': 18,
 'scheduler/dequeued/memory': 18,
 'scheduler/enqueued': 18,
 'scheduler/enqueued/memory': 18,
 'start_time': datetime.datetime(2018, 11, 28, 5, 2, 25, 906368)}
2018-11-28 13:02:26 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 13:03:11 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 13:03:11 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 13:03:11 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 13:03:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 13:03:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 13:03:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 13:03:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 13:03:12 [scrapy.core.engine] INFO: Spider opened
2018-11-28 13:03:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 13:03:12 [old_house] INFO: Spider opened: old_house
2018-11-28 13:03:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/beicai/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chunshen/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xuanqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinchang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/weifang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wanxiangzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/waigaoqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tangzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tangqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shuyuanzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shibo/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/sanlin/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nanmatou/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nichengzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lianyang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lingangxincheng/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/laogangzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lujiazui/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:03:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kangqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:04:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/dahua/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:04:27 [scrapy.extensions.logstats] INFO: Crawled 47 pages (at 47 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 13:04:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yanghang/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:04:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhangmiao/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:04:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhiwuyuan/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:04:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xietulu/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:04:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xujiahui/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:04:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xuhuibinjiang/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:04:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wantiguan/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:04:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tianlin/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:04:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shanghainanzhan/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:04:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/longhua/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:04:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kangjian/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:04:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jianguoxilu/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:04:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hengshanlu/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:04:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huajing/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:04:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huadongligong/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:04:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caohejing/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:04:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yuepu/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:04:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tonghe/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:04:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shangda/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:04:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/songnan/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:04:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/songbao/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:04:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/luodian/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/luojing/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaojing/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gucun/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gongkang/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gongfu/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/dachangzhen/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changqiao/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinzhuang5/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhuanqiao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wujing/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/qibao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/meilong/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/pujiang1/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/maqiao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/laominhang/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/longbai/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinhongqiao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinganxincheng/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinhui/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huacao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hanghua/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gumei/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhoupu/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhuqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:35 [scrapy.extensions.logstats] INFO: Crawled 89 pages (at 42 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 13:05:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhangjiang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yangjing/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yuanshen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yangdong/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yuqiao1/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinyang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huinan/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hangtou/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huamu/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaodong/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaohang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/geqing/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/datuanzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chuansha/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caolu/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:05:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/biyun/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    yield Request(response.url+'pg'+str(self.url_page)+'/', callback='parse_item')
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 31, in __init__
    raise TypeError('callback must be a callable, got %s' % type(callback).__name__)
TypeError: callback must be a callable, got str
2018-11-28 13:11:36 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 13:11:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 13:11:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 13:11:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 13:11:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 13:11:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 13:11:38 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 13:11:38 [scrapy.core.engine] INFO: Spider opened
2018-11-28 13:11:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 13:11:38 [old_house] INFO: Spider opened: old_house
2018-11-28 13:13:02 [scrapy.extensions.logstats] INFO: Crawled 49 pages (at 49 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 13:14:44 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 13:14:44 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 13:14:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 13:14:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 13:14:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 13:14:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 13:14:45 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 13:14:45 [scrapy.core.engine] INFO: Spider opened
2018-11-28 13:14:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 13:14:45 [old_house] INFO: Spider opened: old_house
2018-11-28 13:15:46 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 13:15:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 13:15:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 13:15:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 13:15:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 13:15:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 13:15:47 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 13:15:47 [scrapy.core.engine] INFO: Spider opened
2018-11-28 13:15:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 13:15:47 [old_house] INFO: Spider opened: old_house
2018-11-28 13:17:59 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 13:17:59 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 13:17:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 13:17:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 13:18:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 13:18:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 13:18:00 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 13:18:00 [scrapy.core.engine] INFO: Spider opened
2018-11-28 13:18:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 13:18:00 [old_house] INFO: Spider opened: old_house
2018-11-28 13:19:15 [scrapy.extensions.logstats] INFO: Crawled 50 pages (at 50 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 13:19:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/longhua/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 51, in parse_item
    page=self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 60, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 13:20:00 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 13:20:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 13:20:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 13:20:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 13:20:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 13:20:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 13:20:00 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 13:20:00 [scrapy.core.engine] INFO: Spider opened
2018-11-28 13:20:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 13:20:00 [old_house] INFO: Spider opened: old_house
2018-11-28 15:03:50 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 15:03:50 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 15:03:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 15:03:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 15:03:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 15:03:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 15:03:52 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 15:03:52 [scrapy.core.engine] INFO: Spider opened
2018-11-28 15:03:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 15:03:52 [old_house] INFO: Spider opened: old_house
2018-11-28 15:04:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chuansha/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 52, in parse_item
    page=self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 66, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 15:05:14 [scrapy.extensions.logstats] INFO: Crawled 45 pages (at 45 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 15:05:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhongyuanliangwancheng/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 52, in parse_item
    page=self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 66, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 15:06:07 [scrapy.extensions.logstats] INFO: Crawled 72 pages (at 27 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 15:07:04 [scrapy.extensions.logstats] INFO: Crawled 102 pages (at 30 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 15:08:04 [scrapy.extensions.logstats] INFO: Crawled 126 pages (at 24 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 15:08:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinbang/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 52, in parse_item
    page=self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 66, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 15:09:01 [scrapy.extensions.logstats] INFO: Crawled 154 pages (at 28 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 15:09:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shihudang/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 52, in parse_item
    page=self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 66, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 15:09:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/maogang/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 52, in parse_item
    page=self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 66, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 15:10:06 [scrapy.extensions.logstats] INFO: Crawled 187 pages (at 33 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 15:10:54 [scrapy.extensions.logstats] INFO: Crawled 213 pages (at 26 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 15:10:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hengshadao/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 52, in parse_item
    page=self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 66, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 15:11:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/baozhen/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 52, in parse_item
    page=self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 66, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 15:11:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changshushi/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 52, in parse_item
    page=self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 66, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 15:11:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wuxishi/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 52, in parse_item
    page=self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 66, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 15:11:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/taicang212/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 52, in parse_item
    page=self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 66, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 15:11:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shanghaizhoubian2/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 52, in parse_item
    page=self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 66, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 15:11:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nantong/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 52, in parse_item
    page=self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 66, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 15:11:27 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 15:11:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 49829580,
 'downloader/response_count': 231,
 'downloader/response_status_count/200': 231,
 'dupefilter/filtered': 3254,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 7, 11, 27, 644223),
 'log_count/ERROR': 12,
 'log_count/INFO': 15,
 'request_depth_max': 2,
 'response_received_count': 231,
 'scheduler/dequeued': 231,
 'scheduler/dequeued/memory': 231,
 'scheduler/enqueued': 231,
 'scheduler/enqueued/memory': 231,
 'spider_exceptions/IndexError': 12,
 'start_time': datetime.datetime(2018, 11, 28, 7, 3, 52, 335540)}
2018-11-28 15:11:27 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 15:21:21 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 15:21:21 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 15:21:21 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 15:21:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 15:21:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 15:21:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 15:21:22 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 15:21:22 [scrapy.core.engine] INFO: Spider opened
2018-11-28 15:21:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 15:21:22 [old_house] INFO: Spider opened: old_house
2018-11-28 15:25:40 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 15:25:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 15:25:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 15:25:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 15:25:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 15:25:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 15:25:42 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 15:25:42 [scrapy.core.engine] INFO: Spider opened
2018-11-28 15:25:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 15:25:42 [old_house] INFO: Spider opened: old_house
2018-11-28 15:26:29 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 15:26:29 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 15:26:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 15:26:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 15:26:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 15:26:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 15:26:30 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 15:26:30 [scrapy.core.engine] INFO: Spider opened
2018-11-28 15:26:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 15:26:30 [old_house] INFO: Spider opened: old_house
2018-11-28 15:44:28 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 15:44:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 15:44:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 15:44:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 15:44:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 15:44:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 15:44:29 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 15:44:29 [scrapy.core.engine] INFO: Spider opened
2018-11-28 15:44:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 15:44:29 [old_house] INFO: Spider opened: old_house
2018-11-28 15:45:51 [scrapy.extensions.logstats] INFO: Crawled 49 pages (at 49 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 15:46:31 [scrapy.extensions.logstats] INFO: Crawled 73 pages (at 24 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 15:47:36 [scrapy.extensions.logstats] INFO: Crawled 113 pages (at 40 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 15:48:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinbang/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 73, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 15:48:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shihudang/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 73, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 15:48:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/maogang/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 73, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 15:48:42 [scrapy.extensions.logstats] INFO: Crawled 149 pages (at 36 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 15:49:32 [scrapy.extensions.logstats] INFO: Crawled 176 pages (at 27 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 15:50:46 [scrapy.extensions.logstats] INFO: Crawled 218 pages (at 42 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 15:51:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/baozhen/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 73, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 15:51:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hengshadao/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 73, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 15:51:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changshushi/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 73, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 15:51:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wuxishi/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 73, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 15:51:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/taicang212/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 73, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 15:51:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shanghaizhoubian2/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 73, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 15:51:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nantong/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 73, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 15:51:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 15:51:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 49796785,
 'downloader/response_count': 233,
 'downloader/response_status_count/200': 233,
 'dupefilter/filtered': 3324,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 7, 51, 13, 366861),
 'log_count/ERROR': 10,
 'log_count/INFO': 14,
 'request_depth_max': 3,
 'response_received_count': 233,
 'scheduler/dequeued': 233,
 'scheduler/dequeued/memory': 233,
 'scheduler/enqueued': 233,
 'scheduler/enqueued/memory': 233,
 'spider_exceptions/IndexError': 10,
 'start_time': datetime.datetime(2018, 11, 28, 7, 44, 29, 692486)}
2018-11-28 15:51:13 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 16:45:49 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 16:45:49 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 16:45:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 16:45:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 16:45:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 16:45:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 16:45:51 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 16:45:51 [scrapy.core.engine] INFO: Spider opened
2018-11-28 16:45:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 16:45:51 [old_house] INFO: Spider opened: old_house
2018-11-28 16:46:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/beicai/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'beicai'
2018-11-28 16:46:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chunshen/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 74, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 16:46:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lianyang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'lianyang'
2018-11-28 16:46:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lingangxincheng/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'lingangxincheng'
2018-11-28 16:46:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/laogangzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'laogangzhen'
2018-11-28 16:46:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lujiazui/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'lujiazui'
2018-11-28 16:46:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kangqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'kangqiao'
2018-11-28 16:46:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinyang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'jinyang'
2018-11-28 16:46:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'jinqiao'
2018-11-28 16:46:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huinan/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'huinan'
2018-11-28 16:46:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hangtou/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'hangtou'
2018-11-28 16:46:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaodong/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'gaodong'
2018-11-28 16:46:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huamu/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'huamu'
2018-11-28 16:46:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaohang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'gaohang'
2018-11-28 16:46:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/geqing/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'geqing'
2018-11-28 16:46:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/datuanzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'datuanzhen'
2018-11-28 16:46:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chuansha/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 74, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 16:46:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caolu/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'caolu'
2018-11-28 16:46:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/biyun/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'biyun'
2018-11-28 16:46:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/dahua/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'dahua'
2018-11-28 16:46:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhuanqiao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhuanqiao'
2018-11-28 16:47:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinzhuang5/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xinzhuang5'
2018-11-28 16:47:26 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 16:47:26 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 16:47:26 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 16:47:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 16:47:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 16:47:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 16:47:27 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 16:47:27 [scrapy.core.engine] INFO: Spider opened
2018-11-28 16:47:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 16:47:27 [old_house] INFO: Spider opened: old_house
2018-11-28 16:48:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/beicai/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'beicai'
2018-11-28 16:48:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chunshen/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'chunshen'
2018-11-28 16:48:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yuqiao1/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'yuqiao1'
2018-11-28 16:48:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinchang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xinchang'
2018-11-28 16:48:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xuanqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xuanqiao'
2018-11-28 16:48:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/weifang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'weifang'
2018-11-28 16:48:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wanxiangzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'wanxiangzhen'
2018-11-28 16:48:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/waigaoqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'waigaoqiao'
2018-11-28 16:48:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tangzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'tangzhen'
2018-11-28 16:48:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shuyuanzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'shuyuanzhen'
2018-11-28 16:48:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tangqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'tangqiao'
2018-11-28 16:48:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shibo/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'shibo'
2018-11-28 16:48:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/sanlin/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'sanlin'
2018-11-28 16:48:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nanmatou/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'nanmatou'
2018-11-28 16:48:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nichengzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'nichengzhen'
2018-11-28 16:48:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lianyang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'lianyang'
2018-11-28 16:48:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lingangxincheng/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'lingangxincheng'
2018-11-28 16:48:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/laogangzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'laogangzhen'
2018-11-28 16:48:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lujiazui/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'lujiazui'
2018-11-28 16:48:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/dahua/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'dahua'
2018-11-28 16:48:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhangmiao/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhangmiao'
2018-11-28 16:48:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yanghang/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'yanghang'
2018-11-28 16:48:41 [scrapy.extensions.logstats] INFO: Crawled 48 pages (at 48 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 16:48:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhiwuyuan/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhiwuyuan'
2018-11-28 16:48:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xietulu/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xietulu'
2018-11-28 16:48:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xujiahui/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xujiahui'
2018-11-28 16:48:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xuhuibinjiang/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xuhuibinjiang'
2018-11-28 16:48:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wantiguan/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'wantiguan'
2018-11-28 16:48:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tianlin/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'tianlin'
2018-11-28 16:48:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shanghainanzhan/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 16:48:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kangjian/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'kangjian'
2018-11-28 16:48:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/longhua/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'longhua'
2018-11-28 16:48:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xuhui/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xuhui'
2018-11-28 16:48:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hengshanlu/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'hengshanlu'
2018-11-28 16:48:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huajing/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'huajing'
2018-11-28 16:48:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huadongligong/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'huadongligong'
2018-11-28 16:48:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caohejing/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'caohejing'
2018-11-28 16:48:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yuepu/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 16:48:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tonghe/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'tonghe'
2018-11-28 16:48:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shangda/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'shangda'
2018-11-28 16:48:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/songnan/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'songnan'
2018-11-28 16:48:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/songbao/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'songbao'
2018-11-28 16:48:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/luodian/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'luodian'
2018-11-28 16:48:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/luojing/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'luojing'
2018-11-28 16:48:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaojing/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'gaojing'
2018-11-28 16:49:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gucun/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'gucun'
2018-11-28 16:49:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gongkang/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'gongkang'
2018-11-28 16:49:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gongfu/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'gongfu'
2018-11-28 16:49:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/dachangzhen/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'dachangzhen'
2018-11-28 16:49:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changqiao/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'changqiao'
2018-11-28 16:49:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhuanqiao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhuanqiao'
2018-11-28 16:49:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinzhuang5/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xinzhuang5'
2018-11-28 16:49:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wujing/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'wujing'
2018-11-28 16:49:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/qibao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'qibao'
2018-11-28 16:49:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/pujiang1/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'pujiang1'
2018-11-28 16:49:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/meilong/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'meilong'
2018-11-28 16:49:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/maqiao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'maqiao'
2018-11-28 16:49:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/laominhang/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'laominhang'
2018-11-28 16:49:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/longbai/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'longbai'
2018-11-28 16:49:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinhongqiao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'jinhongqiao'
2018-11-28 16:49:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/minhang/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'minhang'
2018-11-28 16:49:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinhui/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'jinhui'
2018-11-28 16:49:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huacao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'huacao'
2018-11-28 16:49:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hanghua/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'hanghua'
2018-11-28 16:49:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gumei/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'gumei'
2018-11-28 16:49:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhoupu/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhoupu'
2018-11-28 16:49:30 [scrapy.extensions.logstats] INFO: Crawled 73 pages (at 25 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 16:49:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhuqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhuqiao'
2018-11-28 16:49:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhangjiang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhangjiang'
2018-11-28 16:50:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yangjing/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'yangjing'
2018-11-28 16:50:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yuanshen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'yuanshen'
2018-11-28 16:50:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yangdong/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'yangdong'
2018-11-28 16:50:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kangqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'kangqiao'
2018-11-28 16:50:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinyang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'jinyang'
2018-11-28 16:50:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'jinqiao'
2018-11-28 16:50:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huinan/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'huinan'
2018-11-28 16:50:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hangtou/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'hangtou'
2018-11-28 16:50:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huamu/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'huamu'
2018-11-28 16:50:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaodong/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'gaodong'
2018-11-28 16:50:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaohang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'gaohang'
2018-11-28 16:50:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/geqing/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'geqing'
2018-11-28 16:50:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/datuanzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'datuanzhen'
2018-11-28 16:50:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chuansha/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'chuansha'
2018-11-28 16:50:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caolu/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'caolu'
2018-11-28 16:50:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/biyun/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'biyun'
2018-11-28 16:51:07 [scrapy.extensions.logstats] INFO: Crawled 112 pages (at 39 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 16:51:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changshoulu/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'changshoulu'
2018-11-28 16:51:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenru/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhenru'
2018-11-28 16:51:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhongyuanliangwancheng/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhongyuanliangwancheng'
2018-11-28 16:51:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenguang/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhenguang'
2018-11-28 16:51:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wanli/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'wanli'
2018-11-28 16:51:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wuning/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'wuning'
2018-11-28 16:51:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/taopu/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'taopu'
2018-11-28 16:51:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/ganquanyichuan/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'ganquanyichuan'
2018-11-28 16:51:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/guangxin/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'guangxin'
2018-11-28 16:51:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changzheng/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'changzheng'
2018-11-28 16:51:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caoyang/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'caoyang'
2018-11-28 16:51:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changfeng1/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'changfeng1'
2018-11-28 16:51:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/anshan/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'anshan'
2018-11-28 16:51:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhongyuan1/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhongyuan1'
2018-11-28 16:51:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhoujiazuilu/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhoujiazuilu'
2018-11-28 16:51:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinjiangwancheng/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xinjiangwancheng'
2018-11-28 16:51:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wujiaochang/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'wujiaochang'
2018-11-28 16:51:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kongjianglu/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'kongjianglu'
2018-11-28 16:51:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huangxinggongyuan/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'huangxinggongyuan'
2018-11-28 16:51:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/dongwaitan/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'dongwaitan'
2018-11-28 16:51:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chedun/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'chedun'
2018-11-28 16:52:05 [scrapy.extensions.logstats] INFO: Crawled 137 pages (at 25 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 16:52:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/anting/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'anting'
2018-11-28 16:52:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yexie/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'yexie'
2018-11-28 16:52:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xuxing/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xuxing'
2018-11-28 16:52:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinchenglu1/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xinchenglu1'
2018-11-28 16:52:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/waigang/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'waigang'
2018-11-28 16:52:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nanxiang/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'nanxiang'
2018-11-28 16:52:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/malu/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'malu'
2018-11-28 16:52:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jiangqiao/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'jiangqiao'
2018-11-28 16:52:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/juyuanxinqu/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'juyuanxinqu'
2018-11-28 16:52:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jiadingxincheng/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'jiadingxincheng'
2018-11-28 16:52:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jiadinglaocheng/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'jiadinglaocheng'
2018-11-28 16:52:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huating/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'huating'
2018-11-28 16:52:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/fengzhuang/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'fengzhuang'
2018-11-28 16:52:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinbang/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 16:52:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xiaokunshan/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xiaokunshan'
2018-11-28 16:52:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinqiao/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xinqiao'
2018-11-28 16:52:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/songjianglaocheng/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'songjianglaocheng'
2018-11-28 16:52:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/sijing/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'sijing'
2018-11-28 16:52:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/songjiangdaxuecheng/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'songjiangdaxuecheng'
2018-11-28 16:52:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/sheshan/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'sheshan'
2018-11-28 16:52:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/songjiangxincheng/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'songjiangxincheng'
2018-11-28 16:52:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shenminbieshu/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'shenminbieshu'
2018-11-28 16:52:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shihudang/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 16:52:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/maogang/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 16:52:36 [scrapy.extensions.logstats] INFO: Crawled 149 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 16:52:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jiuting/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'jiuting'
2018-11-28 16:52:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhongshangongyuan/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhongshangongyuan'
2018-11-28 16:52:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenninglu/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhenninglu'
2018-11-28 16:52:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xianxia/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xianxia'
2018-11-28 16:52:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinhualu/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xinhualu'
2018-11-28 16:52:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xijiao/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xijiao'
2018-11-28 16:52:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tianshan/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'tianshan'
2018-11-28 16:52:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hongqiao1/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'hongqiao1'
2018-11-28 16:52:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gubei/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'gubei'
2018-11-28 16:52:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/beixinjing/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'beixinjing'
2018-11-28 16:53:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/dapuqiao/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'dapuqiao'
2018-11-28 16:53:42 [scrapy.extensions.logstats] INFO: Crawled 171 pages (at 22 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 16:53:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/penglaigongyuan/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'penglaigongyuan'
2018-11-28 16:53:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nanjingdonglu/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'nanjingdonglu'
2018-11-28 16:53:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/laoximen/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'laoximen'
2018-11-28 16:53:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huaihaizhonglu/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'huaihaizhonglu'
2018-11-28 16:53:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huangpubinjiang/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'huangpubinjiang'
2018-11-28 16:53:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/dongjiadu/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'dongjiadu'
2018-11-28 16:53:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caojiadu/> (referer: https://sh.lianjia.com/ershoufang/jingan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'caojiadu'
2018-11-28 16:53:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shibobinjiang/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'shibobinjiang'
2018-11-28 16:53:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/renminguangchang/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'renminguangchang'
2018-11-28 16:53:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nanjingxilu/> (referer: https://sh.lianjia.com/ershoufang/jingan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'nanjingxilu'
2018-11-28 16:53:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jiangninglu/> (referer: https://sh.lianjia.com/ershoufang/jingan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'jiangninglu'
2018-11-28 16:53:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jingansi/> (referer: https://sh.lianjia.com/ershoufang/jingan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'jingansi'
2018-11-28 16:53:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/buyecheng/> (referer: https://sh.lianjia.com/ershoufang/zhabei/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'buyecheng'
2018-11-28 16:54:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yuyuan/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'yuyuan'
2018-11-28 16:54:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xintiandi/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xintiandi'
2018-11-28 16:54:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wuliqiao/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'wuliqiao'
2018-11-28 16:54:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/beiwaitan/> (referer: https://sh.lianjia.com/ershoufang/hongkou/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'beiwaitan'
2018-11-28 16:54:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/baihe/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'baihe'
2018-11-28 16:54:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/sichuanbeilu/> (referer: https://sh.lianjia.com/ershoufang/hongkou/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'sichuanbeilu'
2018-11-28 16:54:51 [scrapy.extensions.logstats] INFO: Crawled 195 pages (at 24 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 16:54:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhujiajiao/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhujiajiao'
2018-11-28 16:54:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhaoxiang/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhaoxiang'
2018-11-28 16:54:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yingpu/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'yingpu'
2018-11-28 16:54:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xianghuaqiao/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xianghuaqiao'
2018-11-28 16:54:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xujing/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xujing'
2018-11-28 16:54:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xiayang/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xiayang'
2018-11-28 16:54:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/liantang1/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'liantang1'
2018-11-28 16:54:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinze/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'jinze'
2018-11-28 16:54:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huaxin/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'huaxin'
2018-11-28 16:54:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xidu/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xidu'
2018-11-28 16:54:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/situan/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'situan'
2018-11-28 16:54:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/qingcun/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'qingcun'
2018-11-28 16:54:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nanqiao/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'nanqiao'
2018-11-28 16:54:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/fengxian/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'fengxian'
2018-11-28 16:54:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/fengcheng/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'fengcheng'
2018-11-28 16:54:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chonggu/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'chonggu'
2018-11-28 16:55:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhuanghang/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhuanghang'
2018-11-28 16:55:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhelin/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhelin'
2018-11-28 16:55:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/fengxianjinhui/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'fengxianjinhui'
2018-11-28 16:55:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/quyang/> (referer: https://sh.lianjia.com/ershoufang/hongkou/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'quyang'
2018-11-28 16:55:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/linpinglu/> (referer: https://sh.lianjia.com/ershoufang/hongkou/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'linpinglu'
2018-11-28 16:55:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/liangcheng/> (referer: https://sh.lianjia.com/ershoufang/hongkou/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'liangcheng'
2018-11-28 16:55:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/luxungongyuan/> (referer: https://sh.lianjia.com/ershoufang/hongkou/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'luxungongyuan'
2018-11-28 16:55:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jiangwanzhen/> (referer: https://sh.lianjia.com/ershoufang/hongkou/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'jiangwanzhen'
2018-11-28 16:55:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhabeigongyuan/> (referer: https://sh.lianjia.com/ershoufang/zhabei/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhabeigongyuan'
2018-11-28 16:55:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yangcheng/> (referer: https://sh.lianjia.com/ershoufang/zhabei/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'yangcheng'
2018-11-28 16:55:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yonghe/> (referer: https://sh.lianjia.com/ershoufang/zhabei/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'yonghe'
2018-11-28 16:55:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xizangbeilu/> (referer: https://sh.lianjia.com/ershoufang/zhabei/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xizangbeilu'
2018-11-28 16:55:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/pengpu/> (referer: https://sh.lianjia.com/ershoufang/zhabei/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'pengpu'
2018-11-28 16:55:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/daning/> (referer: https://sh.lianjia.com/ershoufang/zhabei/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'daning'
2018-11-28 16:55:45 [scrapy.extensions.logstats] INFO: Crawled 223 pages (at 28 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 16:55:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caojing/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'caojing'
2018-11-28 16:56:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/baozhen/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 16:56:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhujing/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhujing'
2018-11-28 16:56:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhangyan/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhangyan'
2018-11-28 16:56:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tinglin/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'tinglin'
2018-11-28 16:56:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shanyang/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'shanyang'
2018-11-28 16:56:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shihua/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'shihua'
2018-11-28 16:56:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/langxia/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'langxia'
2018-11-28 16:56:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/luxiang/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'luxiang'
2018-11-28 16:56:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinshan1/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'jinshan1'
2018-11-28 16:56:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/fengjing/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'fengjing'
2018-11-28 16:56:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hengshadao/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 16:56:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chongmingqita/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'chongmingqita'
2018-11-28 16:56:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chongmingxincheng/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'chongmingxincheng'
2018-11-28 16:56:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chenjiazhen/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'chenjiazhen'
2018-11-28 16:56:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changxingdao21211/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'changxingdao21211'
2018-11-28 16:56:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changshushi/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 16:56:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wuxishi/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 16:56:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/taicang212/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 16:56:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/suzhou/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'suzhou'
2018-11-28 16:56:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shanghaizhoubian2/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 16:56:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/qidong1/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'qidong1'
2018-11-28 16:56:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nantong/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 16:56:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kunshan1/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'kunshan1'
2018-11-28 16:56:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jiaxing/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'jiaxing'
2018-11-28 16:56:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/haimen/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'haimen'
2018-11-28 16:56:01 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 16:56:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 50065562,
 'downloader/response_count': 232,
 'downloader/response_status_count/200': 232,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 8, 56, 1, 670069),
 'log_count/ERROR': 214,
 'log_count/INFO': 16,
 'request_depth_max': 1,
 'response_received_count': 232,
 'scheduler/dequeued': 232,
 'scheduler/dequeued/memory': 232,
 'scheduler/enqueued': 232,
 'scheduler/enqueued/memory': 232,
 'spider_exceptions/IndexError': 12,
 'spider_exceptions/KeyError': 202,
 'start_time': datetime.datetime(2018, 11, 28, 8, 47, 27, 363822)}
2018-11-28 16:56:01 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 16:57:39 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 16:57:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 16:57:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 16:57:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 16:57:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 16:57:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 16:57:44 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 16:57:44 [scrapy.core.engine] INFO: Spider opened
2018-11-28 16:57:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 16:57:44 [old_house] INFO: Spider opened: old_house
2018-11-28 16:58:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/beicai/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'beicai'
2018-11-28 16:58:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chunshen/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'chunshen'
2018-11-28 16:58:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kangqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'kangqiao'
2018-11-28 16:58:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinyang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 16:58:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'jinqiao'
2018-11-28 16:58:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huinan/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'huinan'
2018-11-28 16:58:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hangtou/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'hangtou'
2018-11-28 16:58:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huamu/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'huamu'
2018-11-28 16:58:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaodong/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'gaodong'
2018-11-28 16:58:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaohang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'gaohang'
2018-11-28 16:58:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/geqing/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'geqing'
2018-11-28 16:58:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/datuanzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'datuanzhen'
2018-11-28 16:58:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chuansha/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'chuansha'
2018-11-28 16:58:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/biyun/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'biyun'
2018-11-28 16:58:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caolu/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'caolu'
2018-11-28 17:02:51 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 17:02:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 17:02:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 17:02:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 17:02:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 17:02:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 17:02:53 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 17:02:53 [scrapy.core.engine] INFO: Spider opened
2018-11-28 17:02:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:02:53 [old_house] INFO: Spider opened: old_house
2018-11-28 17:03:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/beicai/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'beicai'
2018-11-28 17:03:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chunshen/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'chunshen'
2018-11-28 17:03:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lujiazui/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'lujiazui'
2018-11-28 17:03:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kangqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'kangqiao'
2018-11-28 17:03:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinyang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:03:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'jinqiao'
2018-11-28 17:03:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huinan/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'huinan'
2018-11-28 17:03:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hangtou/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'hangtou'
2018-11-28 17:03:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huamu/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'huamu'
2018-11-28 17:03:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaodong/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'gaodong'
2018-11-28 17:03:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaohang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'gaohang'
2018-11-28 17:03:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/geqing/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'geqing'
2018-11-28 17:03:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/datuanzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'datuanzhen'
2018-11-28 17:03:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chuansha/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'chuansha'
2018-11-28 17:03:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caolu/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'caolu'
2018-11-28 17:03:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/biyun/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'biyun'
2018-11-28 17:03:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhuanqiao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhuanqiao'
2018-11-28 17:03:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinzhuang5/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xinzhuang5'
2018-11-28 17:03:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wujing/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'wujing'
2018-11-28 17:04:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changqiao/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'changqiao'
2018-11-28 17:04:41 [scrapy.extensions.logstats] INFO: Crawled 47 pages (at 47 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:04:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changshoulu/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'changshoulu'
2018-11-28 17:04:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenru/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhenru'
2018-11-28 17:04:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhongyuanliangwancheng/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhongyuanliangwancheng'
2018-11-28 17:04:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenguang/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhenguang'
2018-11-28 17:04:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wanli/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'wanli'
2018-11-28 17:04:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wuning/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'wuning'
2018-11-28 17:04:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/taopu/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'taopu'
2018-11-28 17:04:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/ganquanyichuan/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'ganquanyichuan'
2018-11-28 17:04:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/guangxin/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'guangxin'
2018-11-28 17:04:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changzheng/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'changzheng'
2018-11-28 17:04:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caoyang/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'caoyang'
2018-11-28 17:04:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changfeng1/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'changfeng1'
2018-11-28 17:04:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhiwuyuan/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhiwuyuan'
2018-11-28 17:04:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xietulu/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xietulu'
2018-11-28 17:04:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xujiahui/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xujiahui'
2018-11-28 17:04:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xuhuibinjiang/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xuhuibinjiang'
2018-11-28 17:04:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wantiguan/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'wantiguan'
2018-11-28 17:04:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tianlin/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'tianlin'
2018-11-28 17:04:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shanghainanzhan/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'shanghainanzhan'
2018-11-28 17:04:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/longhua/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'longhua'
2018-11-28 17:04:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kangjian/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'kangjian'
2018-11-28 17:04:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jianguoxilu/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'jianguoxilu'
2018-11-28 17:05:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hengshanlu/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'hengshanlu'
2018-11-28 17:05:26 [scrapy.extensions.logstats] INFO: Crawled 70 pages (at 23 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:05:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhangmiao/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhangmiao'
2018-11-28 17:05:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yanghang/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'yanghang'
2018-11-28 17:05:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/baoshan/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'baoshan'
2018-11-28 17:05:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tonghe/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'tonghe'
2018-11-28 17:05:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huajing/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'huajing'
2018-11-28 17:05:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caohejing/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'caohejing'
2018-11-28 17:05:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huadongligong/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'huadongligong'
2018-11-28 17:05:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shangda/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'shangda'
2018-11-28 17:05:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/songnan/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'songnan'
2018-11-28 17:05:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/songbao/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'songbao'
2018-11-28 17:05:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/luodian/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'luodian'
2018-11-28 17:05:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/luojing/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'luojing'
2018-11-28 17:05:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaojing/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'gaojing'
2018-11-28 17:05:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gucun/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'gucun'
2018-11-28 17:05:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gongfu/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'gongfu'
2018-11-28 17:05:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gongkang/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'gongkang'
2018-11-28 17:05:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/dachangzhen/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'dachangzhen'
2018-11-28 17:05:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/qibao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'qibao'
2018-11-28 17:05:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/pujiang1/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'pujiang1'
2018-11-28 17:05:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/meilong/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'meilong'
2018-11-28 17:05:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/laominhang/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'laominhang'
2018-11-28 17:05:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/longbai/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'longbai'
2018-11-28 17:06:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinhongqiao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'jinhongqiao'
2018-11-28 17:06:21 [scrapy.extensions.logstats] INFO: Crawled 93 pages (at 23 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:06:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/minhang/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'minhang'
2018-11-28 17:06:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinhui/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'jinhui'
2018-11-28 17:06:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huacao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'huacao'
2018-11-28 17:06:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hanghua/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'hanghua'
2018-11-28 17:06:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gumei/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'gumei'
2018-11-28 17:06:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhoupu/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhoupu'
2018-11-28 17:06:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhuqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhuqiao'
2018-11-28 17:06:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhangjiang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'zhangjiang'
2018-11-28 17:06:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yangjing/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'yangjing'
2018-11-28 17:06:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yuanshen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'yuanshen'
2018-11-28 17:06:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yangdong/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'yangdong'
2018-11-28 17:06:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yuqiao1/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'yuqiao1'
2018-11-28 17:06:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinchang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xinchang'
2018-11-28 17:06:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/weifang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'weifang'
2018-11-28 17:06:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xuanqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'xuanqiao'
2018-11-28 17:06:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wanxiangzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'wanxiangzhen'
2018-11-28 17:06:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/waigaoqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'waigaoqiao'
2018-11-28 17:06:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tangzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'tangzhen'
2018-11-28 17:06:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tangqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'tangqiao'
2018-11-28 17:06:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shuyuanzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'shuyuanzhen'
2018-11-28 17:06:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shibo/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'shibo'
2018-11-28 17:06:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/sanlin/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'sanlin'
2018-11-28 17:06:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nanmatou/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'nanmatou'
2018-11-28 17:06:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nichengzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'nichengzhen'
2018-11-28 17:06:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lianyang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'lianyang'
2018-11-28 17:06:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lingangxincheng/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'lingangxincheng'
2018-11-28 17:06:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/laogangzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'laogangzhen'
2018-11-28 17:06:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/dahua/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while self.page_dict[response.url.split('/')[4]] >= new_page:
KeyError: 'dahua'
2018-11-28 17:09:26 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 17:09:26 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 17:09:26 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 17:09:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 17:09:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 17:09:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 17:09:29 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 17:09:29 [scrapy.core.engine] INFO: Spider opened
2018-11-28 17:09:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:09:29 [old_house] INFO: Spider opened: old_house
2018-11-28 17:10:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/beicai/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'beicai'
2018-11-28 17:10:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chunshen/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'chunshen'
2018-11-28 17:10:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nichengzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'nichengzhen'
2018-11-28 17:10:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lianyang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'lianyang'
2018-11-28 17:10:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lingangxincheng/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'lingangxincheng'
2018-11-28 17:10:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/laogangzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'laogangzhen'
2018-11-28 17:10:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lujiazui/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'lujiazui'
2018-11-28 17:10:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kangqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'kangqiao'
2018-11-28 17:10:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinyang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'jinyang'
2018-11-28 17:10:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'jinqiao'
2018-11-28 17:10:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huinan/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'huinan'
2018-11-28 17:10:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hangtou/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'hangtou'
2018-11-28 17:10:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huamu/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'huamu'
2018-11-28 17:10:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaodong/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'gaodong'
2018-11-28 17:10:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaohang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'gaohang'
2018-11-28 17:10:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/geqing/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'geqing'
2018-11-28 17:10:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/datuanzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'datuanzhen'
2018-11-28 17:10:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chuansha/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:10:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caolu/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'caolu'
2018-11-28 17:10:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/biyun/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'biyun'
2018-11-28 17:10:58 [scrapy.extensions.logstats] INFO: Crawled 45 pages (at 45 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:11:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changqiao/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'changqiao'
2018-11-28 17:11:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhangmiao/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'zhangmiao'
2018-11-28 17:11:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yanghang/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'yanghang'
2018-11-28 17:11:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhiwuyuan/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'zhiwuyuan'
2018-11-28 17:11:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xietulu/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'xietulu'
2018-11-28 17:11:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xujiahui/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'xujiahui'
2018-11-28 17:11:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wantiguan/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'wantiguan'
2018-11-28 17:11:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tianlin/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'tianlin'
2018-11-28 17:11:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shanghainanzhan/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'shanghainanzhan'
2018-11-28 17:11:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xuhui/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'xuhui'
2018-11-28 17:11:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kangjian/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'kangjian'
2018-11-28 17:11:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jianguoxilu/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'jianguoxilu'
2018-11-28 17:11:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hengshanlu/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'hengshanlu'
2018-11-28 17:11:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huajing/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'huajing'
2018-11-28 17:11:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huadongligong/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'huadongligong'
2018-11-28 17:11:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yuepu/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'yuepu'
2018-11-28 17:11:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caohejing/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'caohejing'
2018-11-28 17:11:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tonghe/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'tonghe'
2018-11-28 17:11:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shangda/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'shangda'
2018-11-28 17:11:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/songnan/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'songnan'
2018-11-28 17:11:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/luodian/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'luodian'
2018-11-28 17:11:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/luojing/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'luojing'
2018-11-28 17:11:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaojing/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'gaojing'
2018-11-28 17:11:42 [scrapy.extensions.logstats] INFO: Crawled 69 pages (at 24 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:11:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gucun/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'gucun'
2018-11-28 17:11:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gongkang/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'gongkang'
2018-11-28 17:11:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gongfu/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'gongfu'
2018-11-28 17:11:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/baoshan/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'baoshan'
2018-11-28 17:11:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhoupu/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'zhoupu'
2018-11-28 17:11:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhuqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'zhuqiao'
2018-11-28 17:11:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/pudong/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'pudong'
2018-11-28 17:11:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/dahua/> (referer: https://sh.lianjia.com/ershoufang/baoshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'dahua'
2018-11-28 17:11:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhuanqiao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'zhuanqiao'
2018-11-28 17:11:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinzhuang5/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'xinzhuang5'
2018-11-28 17:11:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wujing/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'wujing'
2018-11-28 17:11:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/qibao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'qibao'
2018-11-28 17:11:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/pujiang1/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'pujiang1'
2018-11-28 17:11:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/meilong/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'meilong'
2018-11-28 17:11:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/maqiao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:11:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/laominhang/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'laominhang'
2018-11-28 17:11:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/longbai/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'longbai'
2018-11-28 17:11:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinhongqiao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'jinhongqiao'
2018-11-28 17:11:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/minhang/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'minhang'
2018-11-28 17:11:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinhui/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'jinhui'
2018-11-28 17:11:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huacao/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'huacao'
2018-11-28 17:12:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hanghua/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'hanghua'
2018-11-28 17:12:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gumei/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'gumei'
2018-11-28 17:12:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yangjing/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'yangjing'
2018-11-28 17:12:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yuanshen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'yuanshen'
2018-11-28 17:12:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yangdong/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'yangdong'
2018-11-28 17:12:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinchang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'xinchang'
2018-11-28 17:12:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yuqiao1/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'yuqiao1'
2018-11-28 17:12:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xuanqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'xuanqiao'
2018-11-28 17:12:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/weifang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'weifang'
2018-11-28 17:12:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wanxiangzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'wanxiangzhen'
2018-11-28 17:12:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/waigaoqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'waigaoqiao'
2018-11-28 17:12:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tangzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'tangzhen'
2018-11-28 17:12:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tangqiao/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'tangqiao'
2018-11-28 17:12:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shuyuanzhen/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'shuyuanzhen'
2018-11-28 17:12:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shibo/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'shibo'
2018-11-28 17:12:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/sanlin/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'sanlin'
2018-11-28 17:12:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nanmatou/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:12:57 [scrapy.extensions.logstats] INFO: Crawled 110 pages (at 41 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:12:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changshoulu/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'changshoulu'
2018-11-28 17:13:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenru/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'zhenru'
2018-11-28 17:13:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhongyuanliangwancheng/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'zhongyuanliangwancheng'
2018-11-28 17:13:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenguang/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'zhenguang'
2018-11-28 17:13:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wanli/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'wanli'
2018-11-28 17:13:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wuning/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'wuning'
2018-11-28 17:13:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/taopu/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'taopu'
2018-11-28 17:13:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/ganquanyichuan/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'ganquanyichuan'
2018-11-28 17:13:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/guangxin/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'guangxin'
2018-11-28 17:13:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changzheng/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'changzheng'
2018-11-28 17:13:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caoyang/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'caoyang'
2018-11-28 17:13:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changfeng1/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'changfeng1'
2018-11-28 17:13:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/anshan/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'anshan'
2018-11-28 17:13:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/beixinjing/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'beixinjing'
2018-11-28 17:13:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhongyuan1/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'zhongyuan1'
2018-11-28 17:13:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhoujiazuilu/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'zhoujiazuilu'
2018-11-28 17:13:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinjiangwancheng/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'xinjiangwancheng'
2018-11-28 17:13:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wujiaochang/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'wujiaochang'
2018-11-28 17:13:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kongjianglu/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'kongjianglu'
2018-11-28 17:13:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huangxinggongyuan/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'huangxinggongyuan'
2018-11-28 17:13:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chedun/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'chedun'
2018-11-28 17:13:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/anting/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'anting'
2018-11-28 17:13:44 [scrapy.extensions.logstats] INFO: Crawled 134 pages (at 24 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinchenglu1/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'xinchenglu1'
2018-11-28 17:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/waigang/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'waigang'
2018-11-28 17:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nanxiang/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'nanxiang'
2018-11-28 17:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/malu/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'malu'
2018-11-28 17:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jiangqiao/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'jiangqiao'
2018-11-28 17:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/juyuanxinqu/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'juyuanxinqu'
2018-11-28 17:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jiading/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'jiading'
2018-11-28 17:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jiadinglaocheng/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'jiadinglaocheng'
2018-11-28 17:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huating/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'huating'
2018-11-28 17:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/fengzhuang/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'fengzhuang'
2018-11-28 17:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yexie/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'yexie'
2018-11-28 17:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinbang/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xiaokunshan/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'xiaokunshan'
2018-11-28 17:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinqiao/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'xinqiao'
2018-11-28 17:13:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xuxing/> (referer: https://sh.lianjia.com/ershoufang/jiading/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'xuxing'
2018-11-28 17:13:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/songjianglaocheng/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'songjianglaocheng'
2018-11-28 17:13:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/sijing/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'sijing'
2018-11-28 17:13:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/songjiangdaxuecheng/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'songjiangdaxuecheng'
2018-11-28 17:13:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/sheshan/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'sheshan'
2018-11-28 17:13:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/songjiangxincheng/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'songjiangxincheng'
2018-11-28 17:13:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shenminbieshu/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'shenminbieshu'
2018-11-28 17:13:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shihudang/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:13:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/maogang/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:14:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jiuting/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'jiuting'
2018-11-28 17:14:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhongshangongyuan/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'zhongshangongyuan'
2018-11-28 17:14:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenninglu/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'zhenninglu'
2018-11-28 17:14:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xianxia/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'xianxia'
2018-11-28 17:14:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinhualu/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'xinhualu'
2018-11-28 17:14:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xijiao/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'xijiao'
2018-11-28 17:14:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tianshan/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'tianshan'
2018-11-28 17:14:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hongqiao1/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'hongqiao1'
2018-11-28 17:14:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gubei/> (referer: https://sh.lianjia.com/ershoufang/changning/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'gubei'
2018-11-28 17:14:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/dongwaitan/> (referer: https://sh.lianjia.com/ershoufang/yangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'dongwaitan'
2018-11-28 17:14:45 [scrapy.extensions.logstats] INFO: Crawled 168 pages (at 34 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:14:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/dapuqiao/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'dapuqiao'
2018-11-28 17:14:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caojiadu/> (referer: https://sh.lianjia.com/ershoufang/jingan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'caojiadu'
2018-11-28 17:14:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yuyuan/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'yuyuan'
2018-11-28 17:14:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wuliqiao/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'wuliqiao'
2018-11-28 17:14:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xintiandi/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'xintiandi'
2018-11-28 17:14:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shibobinjiang/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'shibobinjiang'
2018-11-28 17:14:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/renminguangchang/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'renminguangchang'
2018-11-28 17:14:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/penglaigongyuan/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'penglaigongyuan'
2018-11-28 17:14:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nanjingdonglu/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'nanjingdonglu'
2018-11-28 17:14:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/laoximen/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'laoximen'
2018-11-28 17:14:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huaihaizhonglu/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'huaihaizhonglu'
2018-11-28 17:14:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huangpubinjiang/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'huangpubinjiang'
2018-11-28 17:14:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/dongjiadu/> (referer: https://sh.lianjia.com/ershoufang/huangpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'dongjiadu'
2018-11-28 17:14:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nanjingxilu/> (referer: https://sh.lianjia.com/ershoufang/jingan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'nanjingxilu'
2018-11-28 17:14:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jiangninglu/> (referer: https://sh.lianjia.com/ershoufang/jingan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'jiangninglu'
2018-11-28 17:14:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jingansi/> (referer: https://sh.lianjia.com/ershoufang/jingan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'jingansi'
2018-11-28 17:14:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhabei/> (referer: https://sh.lianjia.com/ershoufang/zhabei/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'zhabei'
2018-11-28 17:15:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/beiwaitan/> (referer: https://sh.lianjia.com/ershoufang/hongkou/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'beiwaitan'
2018-11-28 17:15:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhabeigongyuan/> (referer: https://sh.lianjia.com/ershoufang/zhabei/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'zhabeigongyuan'
2018-11-28 17:15:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yangcheng/> (referer: https://sh.lianjia.com/ershoufang/zhabei/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'yangcheng'
2018-11-28 17:15:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/baihe/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'baihe'
2018-11-28 17:15:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/fengxianjinhui/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'fengxianjinhui'
2018-11-28 17:15:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhujiajiao/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'zhujiajiao'
2018-11-28 17:15:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhaoxiang/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'zhaoxiang'
2018-11-28 17:15:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yingpu/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'yingpu'
2018-11-28 17:15:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xianghuaqiao/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'xianghuaqiao'
2018-11-28 17:15:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xujing/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'xujing'
2018-11-28 17:15:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xiayang/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'xiayang'
2018-11-28 17:15:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/liantang1/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'liantang1'
2018-11-28 17:15:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinze/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'jinze'
2018-11-28 17:15:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huaxin/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'huaxin'
2018-11-28 17:15:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chonggu/> (referer: https://sh.lianjia.com/ershoufang/qingpu/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'chonggu'
2018-11-28 17:15:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/sichuanbeilu/> (referer: https://sh.lianjia.com/ershoufang/hongkou/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'sichuanbeilu'
2018-11-28 17:15:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/quyang/> (referer: https://sh.lianjia.com/ershoufang/hongkou/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'quyang'
2018-11-28 17:15:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/linpinglu/> (referer: https://sh.lianjia.com/ershoufang/hongkou/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'linpinglu'
2018-11-28 17:15:36 [scrapy.extensions.logstats] INFO: Crawled 196 pages (at 28 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:15:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhuanghang/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'zhuanghang'
2018-11-28 17:15:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhelin/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'zhelin'
2018-11-28 17:15:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xidu/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'xidu'
2018-11-28 17:15:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/situan/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'situan'
2018-11-28 17:15:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/qingcun/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'qingcun'
2018-11-28 17:15:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nanqiao/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'nanqiao'
2018-11-28 17:15:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/haiwan/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'haiwan'
2018-11-28 17:15:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/fengcheng/> (referer: https://sh.lianjia.com/ershoufang/fengxian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'fengcheng'
2018-11-28 17:15:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/liangcheng/> (referer: https://sh.lianjia.com/ershoufang/hongkou/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'liangcheng'
2018-11-28 17:15:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/luxungongyuan/> (referer: https://sh.lianjia.com/ershoufang/hongkou/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'luxungongyuan'
2018-11-28 17:15:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jiangwanzhen/> (referer: https://sh.lianjia.com/ershoufang/hongkou/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'jiangwanzhen'
2018-11-28 17:15:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/yonghe/> (referer: https://sh.lianjia.com/ershoufang/zhabei/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'yonghe'
2018-11-28 17:15:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xizangbeilu/> (referer: https://sh.lianjia.com/ershoufang/zhabei/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'xizangbeilu'
2018-11-28 17:15:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/pengpu/> (referer: https://sh.lianjia.com/ershoufang/zhabei/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'pengpu'
2018-11-28 17:15:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/daning/> (referer: https://sh.lianjia.com/ershoufang/zhabei/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'daning'
2018-11-28 17:16:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caojing/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'caojing'
2018-11-28 17:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/baozhen/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhujing/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'zhujing'
2018-11-28 17:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhangyan/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'zhangyan'
2018-11-28 17:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tinglin/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'tinglin'
2018-11-28 17:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shihua/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'shihua'
2018-11-28 17:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shanyang/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'shanyang'
2018-11-28 17:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/langxia/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'langxia'
2018-11-28 17:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/luxiang/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'luxiang'
2018-11-28 17:16:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinshan1/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'jinshan1'
2018-11-28 17:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/fengjing/> (referer: https://sh.lianjia.com/ershoufang/jinshan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'fengjing'
2018-11-28 17:16:37 [scrapy.extensions.logstats] INFO: Crawled 230 pages (at 34 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hengshadao/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chongmingqita/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'chongmingqita'
2018-11-28 17:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chongmingxincheng/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'chongmingxincheng'
2018-11-28 17:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chenjiazhen/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'chenjiazhen'
2018-11-28 17:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changxingdao21211/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'changxingdao21211'
2018-11-28 17:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changshushi/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wuxishi/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/taicang212/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/suzhou/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'suzhou'
2018-11-28 17:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shanghaizhoubian2/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/qidong1/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'qidong1'
2018-11-28 17:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kunshan1/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'kunshan1'
2018-11-28 17:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nantong/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 75, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jiaxing/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'jiaxing'
2018-11-28 17:16:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/haimen/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 56, in parse_item
    while add_url[response.url.split('/')[4]] >= new_page:
KeyError: 'haimen'
2018-11-28 17:16:37 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 17:16:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 49384680,
 'downloader/response_count': 230,
 'downloader/response_status_count/200': 230,
 'dupefilter/filtered': 3,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 9, 16, 37, 328716),
 'log_count/ERROR': 212,
 'log_count/INFO': 15,
 'request_depth_max': 1,
 'response_received_count': 230,
 'scheduler/dequeued': 230,
 'scheduler/dequeued/memory': 230,
 'scheduler/enqueued': 230,
 'scheduler/enqueued/memory': 230,
 'spider_exceptions/IndexError': 13,
 'spider_exceptions/KeyError': 199,
 'start_time': datetime.datetime(2018, 11, 28, 9, 9, 29, 106125)}
2018-11-28 17:16:37 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 17:19:45 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 17:19:45 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 17:19:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 17:19:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 17:19:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 17:19:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 17:19:47 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 17:19:47 [scrapy.core.engine] INFO: Spider opened
2018-11-28 17:19:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:19:47 [old_house] INFO: Spider opened: old_house
2018-11-28 17:20:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chunshen/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 79, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:21:10 [scrapy.extensions.logstats] INFO: Crawled 46 pages (at 46 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:21:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jianguoxilu/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 79, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:21:53 [scrapy.extensions.logstats] INFO: Crawled 69 pages (at 23 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:22:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/weifang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 79, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:22:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/laominhang/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 79, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:22:49 [scrapy.extensions.logstats] INFO: Crawled 102 pages (at 33 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:23:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinbang/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 79, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:24:23 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 17:24:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 17:24:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 17:24:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 17:24:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 17:24:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 17:24:25 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 17:24:25 [scrapy.core.engine] INFO: Spider opened
2018-11-28 17:24:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:24:25 [old_house] INFO: Spider opened: old_house
2018-11-28 17:25:42 [scrapy.extensions.logstats] INFO: Crawled 48 pages (at 48 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:25:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/longhua/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 79, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:26:30 [scrapy.extensions.logstats] INFO: Crawled 75 pages (at 27 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:27:34 [scrapy.extensions.logstats] INFO: Crawled 113 pages (at 38 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:28:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xinbang/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 79, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:28:34 [scrapy.extensions.logstats] INFO: Crawled 138 pages (at 25 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:28:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shihudang/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 79, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:28:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/maogang/> (referer: https://sh.lianjia.com/ershoufang/songjiang/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 79, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:29:32 [scrapy.extensions.logstats] INFO: Crawled 170 pages (at 32 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:30:30 [scrapy.extensions.logstats] INFO: Crawled 204 pages (at 34 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:31:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/baozhen/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 79, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:31:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hengshadao/> (referer: https://sh.lianjia.com/ershoufang/chongming/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 79, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:31:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changshushi/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 79, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:31:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wuxishi/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 79, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:31:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/taicang212/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 79, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:31:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shanghaizhoubian2/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 79, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:31:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/nantong/> (referer: https://sh.lianjia.com/ershoufang/shanghaizhoubian/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 79, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:31:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-28 17:31:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 49438613,
 'downloader/response_count': 232,
 'downloader/response_status_count/200': 232,
 'dupefilter/filtered': 3288,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 28, 9, 31, 16, 990136),
 'log_count/ERROR': 11,
 'log_count/INFO': 14,
 'request_depth_max': 2,
 'response_received_count': 232,
 'scheduler/dequeued': 232,
 'scheduler/dequeued/memory': 232,
 'scheduler/enqueued': 232,
 'scheduler/enqueued/memory': 232,
 'spider_exceptions/IndexError': 11,
 'start_time': datetime.datetime(2018, 11, 28, 9, 24, 25, 299935)}
2018-11-28 17:31:16 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-28 17:33:36 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 17:33:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 17:33:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 17:33:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 17:33:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 17:33:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 17:33:38 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 17:33:38 [scrapy.core.engine] INFO: Spider opened
2018-11-28 17:33:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:33:38 [old_house] INFO: Spider opened: old_house
2018-11-28 17:34:54 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 26 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:35:42 [scrapy.extensions.logstats] INFO: Crawled 52 pages (at 26 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:36:20 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 17:36:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 17:36:20 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 17:36:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 17:36:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 17:36:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 17:36:23 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 17:36:23 [scrapy.core.engine] INFO: Spider opened
2018-11-28 17:36:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:36:23 [old_house] INFO: Spider opened: old_house
2018-11-28 17:49:56 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 17:49:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 17:49:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 17:49:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 17:49:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 17:49:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 17:49:58 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 17:49:58 [scrapy.core.engine] INFO: Spider opened
2018-11-28 17:49:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:49:58 [old_house] INFO: Spider opened: old_house
2018-11-28 17:50:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/weifang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spiders\crawl.py", line 83, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 54, in parse_item
    page = self.get_page(response)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 79, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 17:51:29 [scrapy.extensions.logstats] INFO: Crawled 56 pages (at 56 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 17:52:04 [scrapy.extensions.logstats] INFO: Crawled 80 pages (at 24 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 18:02:07 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 18:02:07 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 18:02:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 18:02:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 18:02:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 18:02:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 18:02:09 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 18:02:09 [scrapy.core.engine] INFO: Spider opened
2018-11-28 18:02:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 18:02:09 [old_house] INFO: Spider opened: old_house
2018-11-28 18:03:25 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 18:03:25 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-28 18:03:25 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 18:03:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 18:03:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 18:03:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 18:03:26 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 18:03:26 [scrapy.core.engine] INFO: Spider opened
2018-11-28 18:03:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 18:03:26 [old_house] INFO: Spider opened: old_house
2018-11-28 18:04:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huinan/pg1/> (referer: https://sh.lianjia.com/ershoufang/huinan/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 59, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 95, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 18:04:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinqiao/pg1/> (referer: https://sh.lianjia.com/ershoufang/jinqiao/)
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 59, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\admin\PycharmProjects\spider-dome\lianjia\lianjia\spiders\old_house.py", line 95, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 22:17:55 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 22:17:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-11-28 22:17:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 22:17:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 22:17:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 22:17:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 22:17:56 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 22:17:56 [scrapy.core.engine] INFO: Spider opened
2018-11-28 22:17:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 22:17:56 [old_house] INFO: Spider opened: old_house
2018-11-28 22:20:33 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 22:20:33 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-11-28 22:20:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 22:20:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 22:20:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 22:20:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 22:20:34 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 22:20:34 [scrapy.core.engine] INFO: Spider opened
2018-11-28 22:20:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 22:20:34 [old_house] INFO: Spider opened: old_house
2018-11-28 22:25:46 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 22:25:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-11-28 22:25:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 22:25:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 22:25:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 22:25:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 22:25:46 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 22:25:46 [scrapy.core.engine] INFO: Spider opened
2018-11-28 22:25:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 22:25:46 [old_house] INFO: Spider opened: old_house
2018-11-28 22:26:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chunshen/pg1/> (referer: https://sh.lianjia.com/ershoufang/chunshen/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 89, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 22:26:48 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 27 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 22:26:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/dahua/pg1/> (referer: https://sh.lianjia.com/ershoufang/dahua/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 89, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 22:37:33 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 22:37:33 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-11-28 22:37:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 22:37:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 22:37:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 22:37:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 22:37:34 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 22:37:34 [scrapy.core.engine] INFO: Spider opened
2018-11-28 22:37:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 22:37:34 [old_house] INFO: Spider opened: old_house
2018-11-28 22:39:11 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 22:39:11 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-11-28 22:39:11 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 22:39:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 22:39:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 22:39:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 22:39:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 22:39:12 [scrapy.core.engine] INFO: Spider opened
2018-11-28 22:39:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 22:39:12 [old_house] INFO: Spider opened: old_house
2018-11-28 22:40:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinyang/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 55, in parse_item
    page = self.get_page(response)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 78, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Python 3.6\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 22:40:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/laominhang/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 55, in parse_item
    page = self.get_page(response)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 78, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Python 3.6\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 22:40:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/maqiao/pg1/> (referer: https://sh.lianjia.com/ershoufang/maqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 90, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 22:40:14 [scrapy.extensions.logstats] INFO: Crawled 30 pages (at 30 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 22:40:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/maqiao/pg4/> (referer: https://sh.lianjia.com/ershoufang/maqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 90, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 22:40:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/maqiao/pg3/> (referer: https://sh.lianjia.com/ershoufang/maqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 90, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 22:40:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinhongqiao/pg2/> (referer: https://sh.lianjia.com/ershoufang/jinhongqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 90, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 22:40:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinhongqiao/pg8/> (referer: https://sh.lianjia.com/ershoufang/jinhongqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 90, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 22:40:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinhongqiao/pg9/> (referer: https://sh.lianjia.com/ershoufang/jinhongqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 90, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 22:40:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinhongqiao/pg7/> (referer: https://sh.lianjia.com/ershoufang/jinhongqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 90, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 22:40:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinhongqiao/pg6/> (referer: https://sh.lianjia.com/ershoufang/jinhongqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 90, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 22:40:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinhongqiao/pg5/> (referer: https://sh.lianjia.com/ershoufang/jinhongqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 90, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 22:41:43 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 22:41:43 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-11-28 22:41:43 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 22:41:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 22:41:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 22:41:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 22:41:44 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 22:41:44 [scrapy.core.engine] INFO: Spider opened
2018-11-28 22:41:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 22:41:44 [old_house] INFO: Spider opened: old_house
2018-11-28 22:43:08 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 24 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 22:43:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhiwuyuan/pg1/> (referer: https://sh.lianjia.com/ershoufang/zhiwuyuan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 90, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 22:43:54 [scrapy.extensions.logstats] INFO: Crawled 48 pages (at 24 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 22:43:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhiwuyuan/pg3/> (referer: https://sh.lianjia.com/ershoufang/zhiwuyuan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 90, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 22:43:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhiwuyuan/pg4/> (referer: https://sh.lianjia.com/ershoufang/zhiwuyuan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 90, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 22:43:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhiwuyuan/pg5/> (referer: https://sh.lianjia.com/ershoufang/zhiwuyuan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 90, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 22:43:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhiwuyuan/pg2/> (referer: https://sh.lianjia.com/ershoufang/zhiwuyuan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 90, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 22:44:54 [scrapy.extensions.logstats] INFO: Crawled 79 pages (at 31 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 22:46:04 [scrapy.extensions.logstats] INFO: Crawled 119 pages (at 40 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 22:46:54 [scrapy.extensions.logstats] INFO: Crawled 148 pages (at 29 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 22:48:06 [scrapy.extensions.logstats] INFO: Crawled 185 pages (at 37 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 22:49:34 [scrapy.extensions.logstats] INFO: Crawled 199 pages (at 14 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 22:50:11 [scrapy.extensions.logstats] INFO: Crawled 214 pages (at 15 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 22:51:07 [scrapy.extensions.logstats] INFO: Crawled 243 pages (at 29 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 22:51:28 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 22:51:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-11-28 22:51:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 22:51:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 22:51:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 22:51:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 22:51:28 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 22:51:28 [scrapy.core.engine] INFO: Spider opened
2018-11-28 22:51:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 22:51:28 [old_house] INFO: Spider opened: old_house
2018-11-28 22:53:23 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 22:53:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-11-28 22:53:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 22:53:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 22:53:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 22:53:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 22:53:24 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 22:53:24 [scrapy.core.engine] INFO: Spider opened
2018-11-28 22:53:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 22:53:24 [old_house] INFO: Spider opened: old_house
2018-11-28 22:54:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chunshen/> (referer: https://sh.lianjia.com/ershoufang/minhang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 55, in parse_item
    page = self.get_page(response)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 80, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Python 3.6\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 22:54:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hangtou/pg1/> (referer: https://sh.lianjia.com/ershoufang/hangtou/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 22:54:24 [scrapy.extensions.logstats] INFO: Crawled 28 pages (at 28 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 22:56:08 [scrapy.extensions.logstats] INFO: Crawled 77 pages (at 49 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 22:56:47 [scrapy.extensions.logstats] INFO: Crawled 101 pages (at 24 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 22:57:38 [scrapy.extensions.logstats] INFO: Crawled 131 pages (at 30 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:03:42 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 23:03:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-11-28 23:03:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 23:03:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 23:03:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 23:03:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 23:03:42 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 23:03:42 [scrapy.core.engine] INFO: Spider opened
2018-11-28 23:03:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:03:42 [old_house] INFO: Spider opened: old_house
2018-11-28 23:04:48 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 23 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:05:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/beicai/pg9/> (referer: https://sh.lianjia.com/ershoufang/beicai/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:06:12 [scrapy.extensions.logstats] INFO: Crawled 55 pages (at 32 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:07:06 [scrapy.extensions.logstats] INFO: Crawled 67 pages (at 12 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:07:50 [scrapy.extensions.logstats] INFO: Crawled 88 pages (at 21 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:09:08 [scrapy.extensions.logstats] INFO: Crawled 126 pages (at 38 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:09:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huamu/pg6/> (referer: https://sh.lianjia.com/ershoufang/huamu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:09:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huamu/pg5/> (referer: https://sh.lianjia.com/ershoufang/huamu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:09:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huamu/pg3/> (referer: https://sh.lianjia.com/ershoufang/huamu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:09:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huamu/pg4/> (referer: https://sh.lianjia.com/ershoufang/huamu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:10:01 [scrapy.extensions.logstats] INFO: Crawled 153 pages (at 27 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:10:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huinan/pg8/> (referer: https://sh.lianjia.com/ershoufang/huinan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:10:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huinan/pg9/> (referer: https://sh.lianjia.com/ershoufang/huinan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:10:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huinan/pg7/> (referer: https://sh.lianjia.com/ershoufang/huinan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:10:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huinan/pg6/> (referer: https://sh.lianjia.com/ershoufang/huinan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:10:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhongyuanliangwancheng/> (referer: https://sh.lianjia.com/ershoufang/putuo/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spiders\crawl.py", line 78, in _parse_response
    for requests_or_item in iterate_spider_output(cb_res):
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 55, in parse_item
    page = self.get_page(response)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 80, in get_page
    page = json.loads(response.xpath('//div[@comp-module="page"]/@page-data')[0].extract())['totalPage']
  File "C:\Python 3.6\lib\site-packages\parsel\selector.py", line 61, in __getitem__
    o = super(SelectorList, self).__getitem__(pos)
IndexError: list index out of range
2018-11-28 23:10:58 [scrapy.extensions.logstats] INFO: Crawled 179 pages (at 26 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:11:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changzheng/pg1/> (referer: https://sh.lianjia.com/ershoufang/changzheng/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:11:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/ganquanyichuan/pg1/> (referer: https://sh.lianjia.com/ershoufang/ganquanyichuan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:11:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changzheng/pg8/> (referer: https://sh.lianjia.com/ershoufang/changzheng/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:11:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changzheng/pg9/> (referer: https://sh.lianjia.com/ershoufang/changzheng/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:11:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changzheng/pg7/> (referer: https://sh.lianjia.com/ershoufang/changzheng/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:07 [scrapy.extensions.logstats] INFO: Crawled 213 pages (at 34 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:12:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenru/pg9/> (referer: https://sh.lianjia.com/ershoufang/zhenru/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caoyang/pg7/> (referer: https://sh.lianjia.com/ershoufang/caoyang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caoyang/pg6/> (referer: https://sh.lianjia.com/ershoufang/caoyang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caoyang/pg3/> (referer: https://sh.lianjia.com/ershoufang/caoyang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caoyang/pg4/> (referer: https://sh.lianjia.com/ershoufang/caoyang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caoyang/pg5/> (referer: https://sh.lianjia.com/ershoufang/caoyang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caoyang/pg2/> (referer: https://sh.lianjia.com/ershoufang/caoyang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changfeng1/pg7/> (referer: https://sh.lianjia.com/ershoufang/changfeng1/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changfeng1/pg6/> (referer: https://sh.lianjia.com/ershoufang/changfeng1/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changfeng1/pg5/> (referer: https://sh.lianjia.com/ershoufang/changfeng1/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changfeng1/pg3/> (referer: https://sh.lianjia.com/ershoufang/changfeng1/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changfeng1/pg4/> (referer: https://sh.lianjia.com/ershoufang/changfeng1/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changfeng1/pg2/> (referer: https://sh.lianjia.com/ershoufang/changfeng1/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changzheng/pg3/> (referer: https://sh.lianjia.com/ershoufang/changzheng/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changzheng/pg2/> (referer: https://sh.lianjia.com/ershoufang/changzheng/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changzheng/pg5/> (referer: https://sh.lianjia.com/ershoufang/changzheng/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changzheng/pg6/> (referer: https://sh.lianjia.com/ershoufang/changzheng/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changzheng/pg4/> (referer: https://sh.lianjia.com/ershoufang/changzheng/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/ganquanyichuan/pg9/> (referer: https://sh.lianjia.com/ershoufang/ganquanyichuan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/ganquanyichuan/pg8/> (referer: https://sh.lianjia.com/ershoufang/ganquanyichuan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:57 [scrapy.extensions.logstats] INFO: Crawled 236 pages (at 23 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:12:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/ganquanyichuan/pg5/> (referer: https://sh.lianjia.com/ershoufang/ganquanyichuan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/ganquanyichuan/pg4/> (referer: https://sh.lianjia.com/ershoufang/ganquanyichuan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/ganquanyichuan/pg7/> (referer: https://sh.lianjia.com/ershoufang/ganquanyichuan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/ganquanyichuan/pg6/> (referer: https://sh.lianjia.com/ershoufang/ganquanyichuan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:12:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/ganquanyichuan/pg3/> (referer: https://sh.lianjia.com/ershoufang/ganquanyichuan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wanli/pg5/> (referer: https://sh.lianjia.com/ershoufang/wanli/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wanli/pg6/> (referer: https://sh.lianjia.com/ershoufang/wanli/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wanli/pg7/> (referer: https://sh.lianjia.com/ershoufang/wanli/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wanli/pg8/> (referer: https://sh.lianjia.com/ershoufang/wanli/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/ganquanyichuan/pg2/> (referer: https://sh.lianjia.com/ershoufang/ganquanyichuan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wanli/pg4/> (referer: https://sh.lianjia.com/ershoufang/wanli/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/taopu/pg7/> (referer: https://sh.lianjia.com/ershoufang/taopu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/taopu/pg8/> (referer: https://sh.lianjia.com/ershoufang/taopu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wanli/pg2/> (referer: https://sh.lianjia.com/ershoufang/wanli/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/taopu/pg9/> (referer: https://sh.lianjia.com/ershoufang/taopu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wanli/pg3/> (referer: https://sh.lianjia.com/ershoufang/wanli/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/taopu/pg6/> (referer: https://sh.lianjia.com/ershoufang/taopu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/guangxin/pg7/> (referer: https://sh.lianjia.com/ershoufang/guangxin/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/taopu/pg2/> (referer: https://sh.lianjia.com/ershoufang/taopu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/taopu/pg4/> (referer: https://sh.lianjia.com/ershoufang/taopu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/taopu/pg5/> (referer: https://sh.lianjia.com/ershoufang/taopu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/taopu/pg3/> (referer: https://sh.lianjia.com/ershoufang/taopu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/guangxin/pg6/> (referer: https://sh.lianjia.com/ershoufang/guangxin/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/guangxin/pg3/> (referer: https://sh.lianjia.com/ershoufang/guangxin/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/guangxin/pg4/> (referer: https://sh.lianjia.com/ershoufang/guangxin/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/guangxin/pg5/> (referer: https://sh.lianjia.com/ershoufang/guangxin/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/guangxin/pg2/> (referer: https://sh.lianjia.com/ershoufang/guangxin/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wuning/pg8/> (referer: https://sh.lianjia.com/ershoufang/wuning/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wuning/pg9/> (referer: https://sh.lianjia.com/ershoufang/wuning/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wuning/pg4/> (referer: https://sh.lianjia.com/ershoufang/wuning/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wuning/pg5/> (referer: https://sh.lianjia.com/ershoufang/wuning/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wuning/pg6/> (referer: https://sh.lianjia.com/ershoufang/wuning/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wuning/pg7/> (referer: https://sh.lianjia.com/ershoufang/wuning/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wuning/pg3/> (referer: https://sh.lianjia.com/ershoufang/wuning/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenguang/pg8/> (referer: https://sh.lianjia.com/ershoufang/zhenguang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wuning/pg2/> (referer: https://sh.lianjia.com/ershoufang/wuning/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenguang/pg7/> (referer: https://sh.lianjia.com/ershoufang/zhenguang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:13:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenguang/pg6/> (referer: https://sh.lianjia.com/ershoufang/zhenguang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:14:11 [scrapy.extensions.logstats] INFO: Crawled 273 pages (at 37 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:14:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenguang/pg3/> (referer: https://sh.lianjia.com/ershoufang/zhenguang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:14:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenguang/pg4/> (referer: https://sh.lianjia.com/ershoufang/zhenguang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:14:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenguang/pg5/> (referer: https://sh.lianjia.com/ershoufang/zhenguang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:14:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenguang/pg2/> (referer: https://sh.lianjia.com/ershoufang/zhenguang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:14:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenru/pg8/> (referer: https://sh.lianjia.com/ershoufang/zhenru/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:14:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenru/pg7/> (referer: https://sh.lianjia.com/ershoufang/zhenru/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:14:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenru/pg5/> (referer: https://sh.lianjia.com/ershoufang/zhenru/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:14:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenru/pg6/> (referer: https://sh.lianjia.com/ershoufang/zhenru/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:14:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenru/pg4/> (referer: https://sh.lianjia.com/ershoufang/zhenru/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:14:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenru/pg3/> (referer: https://sh.lianjia.com/ershoufang/zhenru/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:14:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changfeng1/pg1/> (referer: https://sh.lianjia.com/ershoufang/changfeng1/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:14:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caoyang/pg1/> (referer: https://sh.lianjia.com/ershoufang/caoyang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:14:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenru/pg2/> (referer: https://sh.lianjia.com/ershoufang/zhenru/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:14:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/guangxin/pg1/> (referer: https://sh.lianjia.com/ershoufang/guangxin/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:14:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wanli/pg1/> (referer: https://sh.lianjia.com/ershoufang/wanli/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:14:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/taopu/pg1/> (referer: https://sh.lianjia.com/ershoufang/taopu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:14:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wuning/pg1/> (referer: https://sh.lianjia.com/ershoufang/wuning/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:14:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenguang/pg1/> (referer: https://sh.lianjia.com/ershoufang/zhenguang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:14:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhenru/pg1/> (referer: https://sh.lianjia.com/ershoufang/zhenru/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:15:13 [scrapy.extensions.logstats] INFO: Crawled 302 pages (at 29 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:15:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/biyun/pg6/> (referer: https://sh.lianjia.com/ershoufang/biyun/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:15:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/biyun/pg5/> (referer: https://sh.lianjia.com/ershoufang/biyun/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:15:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/biyun/pg4/> (referer: https://sh.lianjia.com/ershoufang/biyun/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:15:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/biyun/pg3/> (referer: https://sh.lianjia.com/ershoufang/biyun/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:15:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/biyun/pg2/> (referer: https://sh.lianjia.com/ershoufang/biyun/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:15:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huamu/pg2/> (referer: https://sh.lianjia.com/ershoufang/huamu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:15:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaohang/pg8/> (referer: https://sh.lianjia.com/ershoufang/gaohang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:15:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaohang/pg7/> (referer: https://sh.lianjia.com/ershoufang/gaohang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:15:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaohang/pg6/> (referer: https://sh.lianjia.com/ershoufang/gaohang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:15:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaohang/pg5/> (referer: https://sh.lianjia.com/ershoufang/gaohang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:15:51 [scrapy.extensions.logstats] INFO: Crawled 323 pages (at 21 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:16:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tianlin/pg1/> (referer: https://sh.lianjia.com/ershoufang/tianlin/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:16:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tianlin/pg5/> (referer: https://sh.lianjia.com/ershoufang/tianlin/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:16:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tianlin/pg6/> (referer: https://sh.lianjia.com/ershoufang/tianlin/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:16:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tianlin/pg7/> (referer: https://sh.lianjia.com/ershoufang/tianlin/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:16:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tianlin/pg8/> (referer: https://sh.lianjia.com/ershoufang/tianlin/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:16:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tianlin/pg4/> (referer: https://sh.lianjia.com/ershoufang/tianlin/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:16:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xietulu/pg8/> (referer: https://sh.lianjia.com/ershoufang/xietulu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:16:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tianlin/pg9/> (referer: https://sh.lianjia.com/ershoufang/tianlin/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:12 [scrapy.extensions.logstats] INFO: Crawled 360 pages (at 37 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:17:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xujiahui/pg9/> (referer: https://sh.lianjia.com/ershoufang/xujiahui/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shanghainanzhan/pg8/> (referer: https://sh.lianjia.com/ershoufang/shanghainanzhan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shanghainanzhan/pg3/> (referer: https://sh.lianjia.com/ershoufang/shanghainanzhan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shanghainanzhan/pg4/> (referer: https://sh.lianjia.com/ershoufang/shanghainanzhan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shanghainanzhan/pg5/> (referer: https://sh.lianjia.com/ershoufang/shanghainanzhan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shanghainanzhan/pg6/> (referer: https://sh.lianjia.com/ershoufang/shanghainanzhan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shanghainanzhan/pg7/> (referer: https://sh.lianjia.com/ershoufang/shanghainanzhan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shanghainanzhan/pg2/> (referer: https://sh.lianjia.com/ershoufang/shanghainanzhan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tianlin/pg3/> (referer: https://sh.lianjia.com/ershoufang/tianlin/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tianlin/pg2/> (referer: https://sh.lianjia.com/ershoufang/tianlin/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wantiguan/pg7/> (referer: https://sh.lianjia.com/ershoufang/wantiguan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wantiguan/pg6/> (referer: https://sh.lianjia.com/ershoufang/wantiguan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wantiguan/pg5/> (referer: https://sh.lianjia.com/ershoufang/wantiguan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wantiguan/pg2/> (referer: https://sh.lianjia.com/ershoufang/wantiguan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wantiguan/pg4/> (referer: https://sh.lianjia.com/ershoufang/wantiguan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wantiguan/pg3/> (referer: https://sh.lianjia.com/ershoufang/wantiguan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhiwuyuan/pg5/> (referer: https://sh.lianjia.com/ershoufang/zhiwuyuan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:53 [scrapy.extensions.logstats] INFO: Crawled 382 pages (at 22 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xietulu/pg5/> (referer: https://sh.lianjia.com/ershoufang/xietulu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xietulu/pg7/> (referer: https://sh.lianjia.com/ershoufang/xietulu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhiwuyuan/pg4/> (referer: https://sh.lianjia.com/ershoufang/zhiwuyuan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhiwuyuan/pg3/> (referer: https://sh.lianjia.com/ershoufang/zhiwuyuan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xietulu/pg6/> (referer: https://sh.lianjia.com/ershoufang/xietulu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhiwuyuan/pg2/> (referer: https://sh.lianjia.com/ershoufang/zhiwuyuan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:17:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xietulu/pg4/> (referer: https://sh.lianjia.com/ershoufang/xietulu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xujiahui/pg6/> (referer: https://sh.lianjia.com/ershoufang/xujiahui/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xujiahui/pg7/> (referer: https://sh.lianjia.com/ershoufang/xujiahui/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xujiahui/pg8/> (referer: https://sh.lianjia.com/ershoufang/xujiahui/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xietulu/pg2/> (referer: https://sh.lianjia.com/ershoufang/xietulu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xietulu/pg3/> (referer: https://sh.lianjia.com/ershoufang/xietulu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xujiahui/pg5/> (referer: https://sh.lianjia.com/ershoufang/xujiahui/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xujiahui/pg4/> (referer: https://sh.lianjia.com/ershoufang/xujiahui/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xujiahui/pg3/> (referer: https://sh.lianjia.com/ershoufang/xujiahui/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xujiahui/pg2/> (referer: https://sh.lianjia.com/ershoufang/xujiahui/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xuhuibinjiang/pg4/> (referer: https://sh.lianjia.com/ershoufang/xuhuibinjiang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/wantiguan/pg1/> (referer: https://sh.lianjia.com/ershoufang/wantiguan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/shanghainanzhan/pg1/> (referer: https://sh.lianjia.com/ershoufang/shanghainanzhan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xuhuibinjiang/pg3/> (referer: https://sh.lianjia.com/ershoufang/xuhuibinjiang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xuhuibinjiang/pg2/> (referer: https://sh.lianjia.com/ershoufang/xuhuibinjiang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/zhiwuyuan/pg1/> (referer: https://sh.lianjia.com/ershoufang/zhiwuyuan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaohang/pg4/> (referer: https://sh.lianjia.com/ershoufang/gaohang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xujiahui/pg1/> (referer: https://sh.lianjia.com/ershoufang/xujiahui/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaohang/pg3/> (referer: https://sh.lianjia.com/ershoufang/gaohang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xuhuibinjiang/pg1/> (referer: https://sh.lianjia.com/ershoufang/xuhuibinjiang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xietulu/pg1/> (referer: https://sh.lianjia.com/ershoufang/xietulu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaohang/pg2/> (referer: https://sh.lianjia.com/ershoufang/gaohang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/datuanzhen/pg2/> (referer: https://sh.lianjia.com/ershoufang/datuanzhen/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/geqing/pg2/> (referer: https://sh.lianjia.com/ershoufang/geqing/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/pudong/pg9/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/pudong/pg8/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/pudong/pg7/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/pudong/pg6/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/pudong/pg5/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:18:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/pudong/pg4/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:19:10 [scrapy.extensions.logstats] INFO: Crawled 421 pages (at 39 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:19:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/pudong/pg3/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:19:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/pudong/pg2/> (referer: https://sh.lianjia.com/ershoufang/pudong/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:19:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caolu/pg9/> (referer: https://sh.lianjia.com/ershoufang/caolu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:19:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caolu/pg8/> (referer: https://sh.lianjia.com/ershoufang/caolu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:19:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caolu/pg7/> (referer: https://sh.lianjia.com/ershoufang/caolu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:19:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caolu/pg6/> (referer: https://sh.lianjia.com/ershoufang/caolu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:19:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caolu/pg5/> (referer: https://sh.lianjia.com/ershoufang/caolu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:19:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caolu/pg2/> (referer: https://sh.lianjia.com/ershoufang/caolu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:19:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caolu/pg4/> (referer: https://sh.lianjia.com/ershoufang/caolu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:19:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaodong/pg4/> (referer: https://sh.lianjia.com/ershoufang/gaodong/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:19:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/caolu/pg3/> (referer: https://sh.lianjia.com/ershoufang/caolu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:19:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaodong/pg3/> (referer: https://sh.lianjia.com/ershoufang/gaodong/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:19:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaodong/pg2/> (referer: https://sh.lianjia.com/ershoufang/gaodong/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:19:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huinan/pg5/> (referer: https://sh.lianjia.com/ershoufang/huinan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:19:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huinan/pg4/> (referer: https://sh.lianjia.com/ershoufang/huinan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:19:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hangtou/pg3/> (referer: https://sh.lianjia.com/ershoufang/hangtou/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:19:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huinan/pg2/> (referer: https://sh.lianjia.com/ershoufang/huinan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:19:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hangtou/pg4/> (referer: https://sh.lianjia.com/ershoufang/hangtou/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:19:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hangtou/pg5/> (referer: https://sh.lianjia.com/ershoufang/hangtou/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:19:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huinan/pg3/> (referer: https://sh.lianjia.com/ershoufang/huinan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:19:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/hangtou/pg2/> (referer: https://sh.lianjia.com/ershoufang/hangtou/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:19:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lingangxincheng/pg2/> (referer: https://sh.lianjia.com/ershoufang/lingangxincheng/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:19:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lingangxincheng/pg3/> (referer: https://sh.lianjia.com/ershoufang/lingangxincheng/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:05 [scrapy.extensions.logstats] INFO: Crawled 449 pages (at 28 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:20:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lujiazui/pg9/> (referer: https://sh.lianjia.com/ershoufang/lujiazui/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lujiazui/pg8/> (referer: https://sh.lianjia.com/ershoufang/lujiazui/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lujiazui/pg7/> (referer: https://sh.lianjia.com/ershoufang/lujiazui/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lujiazui/pg6/> (referer: https://sh.lianjia.com/ershoufang/lujiazui/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lujiazui/pg5/> (referer: https://sh.lianjia.com/ershoufang/lujiazui/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lujiazui/pg4/> (referer: https://sh.lianjia.com/ershoufang/lujiazui/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lujiazui/pg2/> (referer: https://sh.lianjia.com/ershoufang/lujiazui/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lujiazui/pg3/> (referer: https://sh.lianjia.com/ershoufang/lujiazui/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changshoulu/pg1/> (referer: https://sh.lianjia.com/ershoufang/changshoulu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changshoulu/pg7/> (referer: https://sh.lianjia.com/ershoufang/changshoulu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changshoulu/pg6/> (referer: https://sh.lianjia.com/ershoufang/changshoulu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changshoulu/pg5/> (referer: https://sh.lianjia.com/ershoufang/changshoulu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changshoulu/pg4/> (referer: https://sh.lianjia.com/ershoufang/changshoulu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changshoulu/pg3/> (referer: https://sh.lianjia.com/ershoufang/changshoulu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changshoulu/pg2/> (referer: https://sh.lianjia.com/ershoufang/changshoulu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kangqiao/pg9/> (referer: https://sh.lianjia.com/ershoufang/kangqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changshoulu/pg9/> (referer: https://sh.lianjia.com/ershoufang/changshoulu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/changshoulu/pg8/> (referer: https://sh.lianjia.com/ershoufang/changshoulu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:57 [scrapy.extensions.logstats] INFO: Crawled 476 pages (at 27 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:20:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kangqiao/pg6/> (referer: https://sh.lianjia.com/ershoufang/kangqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kangqiao/pg7/> (referer: https://sh.lianjia.com/ershoufang/kangqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kangqiao/pg8/> (referer: https://sh.lianjia.com/ershoufang/kangqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kangqiao/pg4/> (referer: https://sh.lianjia.com/ershoufang/kangqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kangqiao/pg5/> (referer: https://sh.lianjia.com/ershoufang/kangqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:20:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kangqiao/pg3/> (referer: https://sh.lianjia.com/ershoufang/kangqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:21:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kangqiao/pg2/> (referer: https://sh.lianjia.com/ershoufang/kangqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:21:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinqiao/pg9/> (referer: https://sh.lianjia.com/ershoufang/jinqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:21:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinqiao/pg6/> (referer: https://sh.lianjia.com/ershoufang/jinqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:21:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinqiao/pg7/> (referer: https://sh.lianjia.com/ershoufang/jinqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:21:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinqiao/pg8/> (referer: https://sh.lianjia.com/ershoufang/jinqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:21:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinqiao/pg5/> (referer: https://sh.lianjia.com/ershoufang/jinqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:21:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinqiao/pg2/> (referer: https://sh.lianjia.com/ershoufang/jinqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:21:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinqiao/pg3/> (referer: https://sh.lianjia.com/ershoufang/jinqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:21:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinqiao/pg4/> (referer: https://sh.lianjia.com/ershoufang/jinqiao/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:21:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinyang/pg9/> (referer: https://sh.lianjia.com/ershoufang/jinyang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:21:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinyang/pg8/> (referer: https://sh.lianjia.com/ershoufang/jinyang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:21:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinyang/pg7/> (referer: https://sh.lianjia.com/ershoufang/jinyang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:21:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinyang/pg4/> (referer: https://sh.lianjia.com/ershoufang/jinyang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:21:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinyang/pg5/> (referer: https://sh.lianjia.com/ershoufang/jinyang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:21:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinyang/pg6/> (referer: https://sh.lianjia.com/ershoufang/jinyang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:21:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinyang/pg3/> (referer: https://sh.lianjia.com/ershoufang/jinyang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:21:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/jinyang/pg2/> (referer: https://sh.lianjia.com/ershoufang/jinyang/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:22:08 [scrapy.extensions.logstats] INFO: Crawled 512 pages (at 36 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:22:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chunshen/pg8/> (referer: https://sh.lianjia.com/ershoufang/chunshen/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:22:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chunshen/pg7/> (referer: https://sh.lianjia.com/ershoufang/chunshen/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:22:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chunshen/pg9/> (referer: https://sh.lianjia.com/ershoufang/chunshen/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:22:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chunshen/pg6/> (referer: https://sh.lianjia.com/ershoufang/chunshen/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:22:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chunshen/pg4/> (referer: https://sh.lianjia.com/ershoufang/chunshen/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:22:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chunshen/pg5/> (referer: https://sh.lianjia.com/ershoufang/chunshen/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:22:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chunshen/pg2/> (referer: https://sh.lianjia.com/ershoufang/chunshen/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:22:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/chunshen/pg3/> (referer: https://sh.lianjia.com/ershoufang/chunshen/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:22:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/xuhui/pg1/> (referer: https://sh.lianjia.com/ershoufang/xuhui/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:22:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huadongligong/pg1/> (referer: https://sh.lianjia.com/ershoufang/huadongligong/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:22:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/kangjian/pg1/> (referer: https://sh.lianjia.com/ershoufang/kangjian/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:22:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huajing/pg1/> (referer: https://sh.lianjia.com/ershoufang/huajing/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:22:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/tonghe/pg1/> (referer: https://sh.lianjia.com/ershoufang/tonghe/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 58, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 92, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:22:54 [scrapy.extensions.logstats] INFO: Crawled 535 pages (at 23 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:23:56 [scrapy.extensions.logstats] INFO: Crawled 569 pages (at 34 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:25:12 [scrapy.extensions.logstats] INFO: Crawled 598 pages (at 29 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:26:10 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: lianjia)
2018-11-28 23:26:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-11-28 23:26:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'lianjia', 'LOG_FILE': 'lianjiaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'lianjia.spiders', 'SPIDER_MODULES': ['lianjia.spiders']}
2018-11-28 23:26:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-28 23:26:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'lianjia.middlewares.LianjiaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-28 23:26:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-28 23:26:11 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-28 23:26:11 [scrapy.core.engine] INFO: Spider opened
2018-11-28 23:26:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:26:11 [old_house] INFO: Spider opened: old_house
2018-11-28 23:27:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/beicai/pg9/> (referer: https://sh.lianjia.com/ershoufang/beicai/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 83, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:27:24 [scrapy.extensions.logstats] INFO: Crawled 39 pages (at 39 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:28:20 [scrapy.extensions.logstats] INFO: Crawled 66 pages (at 27 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:29:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huinan/pg9/> (referer: https://sh.lianjia.com/ershoufang/huinan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 83, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:29:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huinan/pg8/> (referer: https://sh.lianjia.com/ershoufang/huinan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 83, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:29:36 [scrapy.extensions.logstats] INFO: Crawled 104 pages (at 38 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:29:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huinan/pg7/> (referer: https://sh.lianjia.com/ershoufang/huinan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 83, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:29:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huamu/pg5/> (referer: https://sh.lianjia.com/ershoufang/huamu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 83, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:29:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huinan/pg6/> (referer: https://sh.lianjia.com/ershoufang/huinan/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 83, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:29:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huamu/pg6/> (referer: https://sh.lianjia.com/ershoufang/huamu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 83, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:29:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/huamu/pg4/> (referer: https://sh.lianjia.com/ershoufang/huamu/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 83, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:29:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lujiazui/pg9/> (referer: https://sh.lianjia.com/ershoufang/lujiazui/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 83, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:29:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lujiazui/pg8/> (referer: https://sh.lianjia.com/ershoufang/lujiazui/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 83, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:29:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/lujiazui/pg7/> (referer: https://sh.lianjia.com/ershoufang/lujiazui/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 83, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:30:29 [scrapy.extensions.logstats] INFO: Crawled 134 pages (at 30 pages/min), scraped 0 items (at 0 items/min)
2018-11-28 23:30:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaodong/pg4/> (referer: https://sh.lianjia.com/ershoufang/gaodong/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 83, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:30:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaodong/pg2/> (referer: https://sh.lianjia.com/ershoufang/gaodong/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 83, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
2018-11-28 23:30:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://sh.lianjia.com/ershoufang/gaodong/pg3/> (referer: https://sh.lianjia.com/ershoufang/gaodong/)
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Python 3.6\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 57, in parse_item
    response_or_resquest = self.send_requset(response, new_page)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\lianjia\lianjia\spiders\old_house.py", line 83, in send_requset
    page = int(url_list[5][3:])
ValueError: invalid literal for int() with base 10: ''
