2018-11-04 12:38:04 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-04 12:38:04 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-04 12:38:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-04 12:38:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-04 12:38:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weibo.middlewares.middleware.JavaScriptMiddleware',
 'weibo.middlewares.middleware.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-04 12:38:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-04 12:38:05 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-04 12:38:05 [scrapy.core.engine] INFO: Spider opened
2018-11-04 12:38:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 12:38:05 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 12:38:22 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 12:39:25 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 12:43:19 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 18 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 12:46:58 [scrapy.extensions.logstats] INFO: Crawled 39 pages (at 16 pages/min), scraped 9 items (at 9 items/min)
2018-11-04 12:46:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302408128803002>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 12:48:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302060827866355>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 12:48:49 [scrapy.extensions.logstats] INFO: Crawled 44 pages (at 5 pages/min), scraped 24 items (at 15 items/min)
2018-11-04 12:50:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302339145109693>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Python36\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "C:\Python36\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "C:\Python36\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Python36\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 51, in process_request
    driver.get(request.url)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 376, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 404, in _request
    resp = http.request(method, url, body=body, headers=headers)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\request.py", line 72, in request
    **urlopen_kw)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\request.py", line 150, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\poolmanager.py", line 322, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\util\retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\packages\six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Python36\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "C:\Python36\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "C:\Python36\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Python36\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
2018-11-04 12:50:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302343695947733>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 12:50:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302307725582361>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 12:50:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309351002454302341628121257>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 12:52:00 [scrapy.extensions.logstats] INFO: Crawled 59 pages (at 15 pages/min), scraped 31 items (at 7 items/min)
2018-11-04 12:52:12 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302271205761251>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 12:52:12 [scrapy.extensions.logstats] INFO: Crawled 60 pages (at 1 pages/min), scraped 43 items (at 12 items/min)
2018-11-04 12:54:42 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-04 12:54:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-04 12:54:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-04 12:54:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-04 12:54:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weibo.middlewares.middleware.JavaScriptMiddleware',
 'weibo.middlewares.middleware.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-04 12:54:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-04 12:54:44 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-04 12:54:44 [scrapy.core.engine] INFO: Spider opened
2018-11-04 12:54:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 12:54:44 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 12:54:59 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 12:55:58 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 12:59:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302408300782605>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 12:59:24 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 17 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 13:02:54 [scrapy.extensions.logstats] INFO: Crawled 38 pages (at 16 pages/min), scraped 8 items (at 8 items/min)
2018-11-04 13:04:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302332539068874>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 13:04:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302205925642132>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 13:05:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302350285178035>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 13:05:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302343695947733>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 13:05:23 [scrapy.extensions.logstats] INFO: Crawled 48 pages (at 10 pages/min), scraped 24 items (at 16 items/min)
2018-11-04 13:08:11 [scrapy.extensions.logstats] INFO: Crawled 60 pages (at 12 pages/min), scraped 36 items (at 12 items/min)
2018-11-04 13:08:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302295289481834>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 13:08:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302281481842138>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 13:10:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302219146050204>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Python36\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "C:\Python36\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "C:\Python36\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Python36\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 51, in process_request
    driver.get(request.url)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 333, in get
    self.execute(Command.GET, {'url': url})
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 319, in execute
    response = self.command_executor.execute(driver_command, params)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 376, in execute
    return self._request(command_info[0], url, body=data)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 404, in _request
    resp = http.request(method, url, body=body, headers=headers)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\request.py", line 72, in request
    **urlopen_kw)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\request.py", line 150, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\poolmanager.py", line 322, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\connectionpool.py", line 638, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\util\retry.py", line 367, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\packages\six.py", line 685, in reraise
    raise value.with_traceback(tb)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\connectionpool.py", line 600, in urlopen
    chunked=chunked)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\connectionpool.py", line 384, in _make_request
    six.raise_from(e, None)
  File "<string>", line 2, in raise_from
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\urllib3\connectionpool.py", line 380, in _make_request
    httplib_response = conn.getresponse()
  File "C:\Python36\lib\http\client.py", line 1331, in getresponse
    response.begin()
  File "C:\Python36\lib\http\client.py", line 297, in begin
    version, status, reason = self._read_status()
  File "C:\Python36\lib\http\client.py", line 258, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "C:\Python36\lib\socket.py", line 586, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
2018-11-04 13:12:15 [scrapy.extensions.logstats] INFO: Crawled 81 pages (at 21 pages/min), scraped 49 items (at 13 items/min)
2018-11-04 13:12:15 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-04 13:12:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/urllib3.exceptions.ProtocolError': 1,
 'downloader/response_bytes': 1794872,
 'downloader/response_count': 88,
 'downloader/response_status_count/200': 88,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 4, 5, 12, 15, 413211),
 'item_scraped_count': 71,
 'log_count/ERROR': 8,
 'log_count/INFO': 13,
 'log_count/WARNING': 2,
 'request_depth_max': 1,
 'response_received_count': 81,
 'scheduler/dequeued': 89,
 'scheduler/dequeued/memory': 89,
 'scheduler/enqueued': 89,
 'scheduler/enqueued/memory': 89,
 'start_time': datetime.datetime(2018, 11, 4, 4, 54, 44, 794144)}
2018-11-04 13:12:15 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-04 15:03:59 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-04 15:03:59 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-04 15:03:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-04 15:03:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-04 15:04:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weibo.middlewares.middleware.JavaScriptMiddleware',
 'weibo.middlewares.middleware.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-04 15:04:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-04 15:04:02 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-04 15:04:02 [scrapy.core.engine] INFO: Spider opened
2018-11-04 15:04:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 15:04:03 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 15:04:18 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 15:06:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302579042490972>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 15:06:50 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 13 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 15:10:28 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 14 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 15:10:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302485182393781>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 15:10:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302393494924236>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 15:12:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302415229812054>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 15:12:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309351002794302388902164700>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 15:14:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302358149467774>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 15:14:01 [scrapy.extensions.logstats] INFO: Crawled 42 pages (at 15 pages/min), scraped 14 items (at 14 items/min)
2018-11-04 15:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302323017989881>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 15:15:53 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302408128803002>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 15:15:53 [scrapy.extensions.logstats] INFO: Crawled 49 pages (at 7 pages/min), scraped 27 items (at 13 items/min)
2018-11-04 15:17:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302336766951612>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 15:17:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302347378516803>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 15:17:27 [scrapy.extensions.logstats] INFO: Crawled 55 pages (at 6 pages/min), scraped 33 items (at 6 items/min)
2018-11-04 15:17:49 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309351002454302341628121257>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 15:17:50 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302094671677958>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 15:21:55 [scrapy.extensions.logstats] INFO: Crawled 69 pages (at 14 pages/min), scraped 45 items (at 12 items/min)
2018-11-04 15:21:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302283272797884>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 15:21:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302220714764287>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 15:21:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302243154231325>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 15:21:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302013113495112>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 15:21:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302232010017808>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 15:21:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302210686159033>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 15:21:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302219146050204>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 15:21:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302245893132785>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 15:21:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/%5C/%5C/weibo.com%5C/ttarticle%5C/p%5C/show?id=2309404302260178958822>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 71, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 78, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 15:21:55 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-04 15:21:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 1654271,
 'downloader/response_count': 90,
 'downloader/response_status_count/200': 90,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 4, 7, 21, 55, 990536),
 'item_scraped_count': 59,
 'log_count/ERROR': 21,
 'log_count/INFO': 13,
 'log_count/WARNING': 2,
 'request_depth_max': 1,
 'response_received_count': 69,
 'scheduler/dequeued': 90,
 'scheduler/dequeued/memory': 90,
 'scheduler/enqueued': 90,
 'scheduler/enqueued/memory': 90,
 'start_time': datetime.datetime(2018, 11, 4, 7, 4, 2, 887189)}
2018-11-04 15:21:55 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-04 15:58:39 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-04 15:58:39 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-04 15:58:39 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-04 15:58:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-04 15:58:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weibo.middlewares.middleware.JavaScriptMiddleware',
 'weibo.middlewares.middleware.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-04 15:58:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-04 15:58:41 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-04 15:58:41 [scrapy.core.engine] INFO: Spider opened
2018-11-04 15:58:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 15:58:41 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 15:59:09 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 16:00:00 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 16:14:22 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-04 16:14:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-04 16:14:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-04 16:14:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-04 16:14:22 [twisted] CRITICAL: Unhandled error in Deferred:
2018-11-04 16:14:22 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Python36\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 674, in exec_module
  File "<frozen importlib._bootstrap_external>", line 781, in get_code
  File "<frozen importlib._bootstrap_external>", line 741, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 52
    b = r'\'
           ^
SyntaxError: EOL while scanning string literal
2018-11-04 16:14:56 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-04 16:14:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-04 16:14:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-04 16:14:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-04 16:14:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weibo.middlewares.middleware.JavaScriptMiddleware',
 'weibo.middlewares.middleware.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-04 16:14:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-04 16:14:57 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-04 16:14:57 [scrapy.core.engine] INFO: Spider opened
2018-11-04 16:14:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 16:14:57 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 16:15:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=3&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 56, in process_request
    request.url=''.join(url_list)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\common.py", line 5, in newsetter
    raise AttributeError(msg)
AttributeError: Request.url is not modifiable, use Request.replace() instead
2018-11-04 16:15:15 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=4&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 56, in process_request
    request.url=''.join(url_list)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\common.py", line 5, in newsetter
    raise AttributeError(msg)
AttributeError: Request.url is not modifiable, use Request.replace() instead
2018-11-04 16:15:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=5&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 56, in process_request
    request.url=''.join(url_list)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\common.py", line 5, in newsetter
    raise AttributeError(msg)
AttributeError: Request.url is not modifiable, use Request.replace() instead
2018-11-04 16:15:27 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=6&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 56, in process_request
    request.url=''.join(url_list)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\common.py", line 5, in newsetter
    raise AttributeError(msg)
AttributeError: Request.url is not modifiable, use Request.replace() instead
2018-11-04 16:15:33 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=7&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 56, in process_request
    request.url=''.join(url_list)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\common.py", line 5, in newsetter
    raise AttributeError(msg)
AttributeError: Request.url is not modifiable, use Request.replace() instead
2018-11-04 16:15:39 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 56, in process_request
    request.url=''.join(url_list)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\common.py", line 5, in newsetter
    raise AttributeError(msg)
AttributeError: Request.url is not modifiable, use Request.replace() instead
2018-11-04 16:15:45 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=9&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 56, in process_request
    request.url=''.join(url_list)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\common.py", line 5, in newsetter
    raise AttributeError(msg)
AttributeError: Request.url is not modifiable, use Request.replace() instead
2018-11-04 16:15:52 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=10&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 56, in process_request
    request.url=''.join(url_list)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\common.py", line 5, in newsetter
    raise AttributeError(msg)
AttributeError: Request.url is not modifiable, use Request.replace() instead
2018-11-04 16:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=11&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 56, in process_request
    request.url=''.join(url_list)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\common.py", line 5, in newsetter
    raise AttributeError(msg)
AttributeError: Request.url is not modifiable, use Request.replace() instead
2018-11-04 16:15:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 16:15:58 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=12&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 56, in process_request
    request.url=''.join(url_list)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\common.py", line 5, in newsetter
    raise AttributeError(msg)
AttributeError: Request.url is not modifiable, use Request.replace() instead
2018-11-04 16:15:58 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-04 16:15:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 10,
 'downloader/exception_type_count/builtins.AttributeError': 10,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 4, 8, 15, 58, 404872),
 'log_count/ERROR': 10,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 10,
 'scheduler/dequeued/memory': 10,
 'scheduler/enqueued': 10,
 'scheduler/enqueued/memory': 10,
 'start_time': datetime.datetime(2018, 11, 4, 8, 14, 57, 144129)}
2018-11-04 16:15:58 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-04 16:17:52 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-04 16:17:52 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-04 16:17:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-04 16:17:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-04 16:17:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weibo.middlewares.middleware.JavaScriptMiddleware',
 'weibo.middlewares.middleware.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-04 16:17:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-04 16:17:53 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-04 16:17:53 [scrapy.core.engine] INFO: Spider opened
2018-11-04 16:17:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 16:17:53 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 16:18:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=3&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 56, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:18:11 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=4&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 56, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:18:17 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=5&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 56, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:18:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=6&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 56, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:18:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=7&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 56, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:18:35 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 56, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:18:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=9&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 56, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:18:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=10&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 56, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:18:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=11&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 56, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:18:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 16:18:54 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=12&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 56, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:18:54 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-04 16:18:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 10,
 'downloader/exception_type_count/builtins.TypeError': 10,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 4, 8, 18, 54, 264161),
 'log_count/ERROR': 10,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 10,
 'scheduler/dequeued/memory': 10,
 'scheduler/enqueued': 10,
 'scheduler/enqueued/memory': 10,
 'start_time': datetime.datetime(2018, 11, 4, 8, 17, 53, 198730)}
2018-11-04 16:18:54 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-04 16:20:42 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-04 16:20:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-04 16:20:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-04 16:20:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-04 16:20:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weibo.middlewares.middleware.JavaScriptMiddleware',
 'weibo.middlewares.middleware.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-04 16:20:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-04 16:20:42 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-04 16:20:42 [scrapy.core.engine] INFO: Spider opened
2018-11-04 16:20:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 16:20:42 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 16:20:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=3&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 57, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:21:01 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=4&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 57, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:21:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=5&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 57, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:21:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=6&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 57, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:21:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=7&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 57, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:21:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 57, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:21:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=9&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 57, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:21:37 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=10&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 57, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:21:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=11&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 57, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:21:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 16:21:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=12&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 57, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:21:44 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-04 16:21:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 10,
 'downloader/exception_type_count/builtins.TypeError': 10,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 4, 8, 21, 44, 101892),
 'log_count/ERROR': 10,
 'log_count/INFO': 8,
 'log_count/WARNING': 1,
 'scheduler/dequeued': 10,
 'scheduler/dequeued/memory': 10,
 'scheduler/enqueued': 10,
 'scheduler/enqueued/memory': 10,
 'start_time': datetime.datetime(2018, 11, 4, 8, 20, 42, 860966)}
2018-11-04 16:21:44 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-04 16:23:28 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-04 16:23:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-04 16:23:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-04 16:23:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-04 16:23:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weibo.middlewares.middleware.JavaScriptMiddleware',
 'weibo.middlewares.middleware.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-04 16:23:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-04 16:23:29 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-04 16:23:29 [scrapy.core.engine] INFO: Spider opened
2018-11-04 16:23:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 16:23:29 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 16:23:45 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-04 16:23:45 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-04 16:23:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-04 16:23:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-04 16:23:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weibo.middlewares.middleware.JavaScriptMiddleware',
 'weibo.middlewares.middleware.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-04 16:23:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-04 16:23:45 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-04 16:23:45 [scrapy.core.engine] INFO: Spider opened
2018-11-04 16:23:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 16:23:45 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 16:23:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=3&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 58, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:24:04 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=4&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 58, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:24:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=5&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 58, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:24:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=6&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 58, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:24:22 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=7&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 58, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:24:28 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-04 16:24:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-04 16:24:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-04 16:24:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-04 16:24:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weibo.middlewares.middleware.JavaScriptMiddleware',
 'weibo.middlewares.middleware.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-04 16:24:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-04 16:24:29 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-04 16:24:29 [scrapy.core.engine] INFO: Spider opened
2018-11-04 16:24:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 16:24:29 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 16:24:46 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 16:25:42 [scrapy.extensions.logstats] INFO: Crawled 4 pages (at 4 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 16:27:11 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-04 16:27:11 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-04 16:27:11 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-04 16:27:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-04 16:27:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weibo.middlewares.middleware.JavaScriptMiddleware',
 'weibo.middlewares.middleware.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-04 16:27:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-04 16:27:12 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-04 16:27:12 [scrapy.core.engine] INFO: Spider opened
2018-11-04 16:27:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 16:27:12 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 16:27:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=3&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 58, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:27:30 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=4&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 58, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:27:46 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-04 16:27:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-04 16:27:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-04 16:27:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-04 16:27:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weibo.middlewares.middleware.JavaScriptMiddleware',
 'weibo.middlewares.middleware.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-04 16:27:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-04 16:27:46 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-04 16:27:46 [scrapy.core.engine] INFO: Spider opened
2018-11-04 16:27:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 16:27:46 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 16:28:03 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 16:28:29 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-04 16:28:29 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-04 16:28:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-04 16:28:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-04 16:28:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weibo.middlewares.middleware.JavaScriptMiddleware',
 'weibo.middlewares.middleware.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-04 16:28:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-04 16:28:30 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-04 16:28:30 [scrapy.core.engine] INFO: Spider opened
2018-11-04 16:28:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 16:28:30 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 16:28:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=3&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 58, in process_request
    request.replace(''.join(url_list))
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\http\request\__init__.py", line 98, in replace
    return cls(*args, **kwargs)
TypeError: __init__() got multiple values for argument 'url'
2018-11-04 16:28:52 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-04 16:28:52 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-04 16:28:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-04 16:28:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-04 16:28:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weibo.middlewares.middleware.JavaScriptMiddleware',
 'weibo.middlewares.middleware.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-04 16:28:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-04 16:28:53 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-04 16:28:53 [scrapy.core.engine] INFO: Spider opened
2018-11-04 16:28:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 16:28:53 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 16:29:10 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 16:31:06 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-04 16:31:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-04 16:31:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-04 16:31:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-04 16:31:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weibo.middlewares.middleware.JavaScriptMiddleware',
 'weibo.middlewares.middleware.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-04 16:31:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-04 16:31:07 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-04 16:31:07 [scrapy.core.engine] INFO: Spider opened
2018-11-04 16:31:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 16:31:07 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 16:31:21 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 16:33:54 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-04 16:33:54 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-04 16:33:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-04 16:33:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-04 16:33:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weibo.middlewares.middleware.JavaScriptMiddleware',
 'weibo.middlewares.middleware.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-04 16:33:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-04 16:33:55 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-04 16:33:55 [scrapy.core.engine] INFO: Spider opened
2018-11-04 16:33:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 16:33:55 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 16:34:07 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=3&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 54, in process_request
    print(re.findall(b, request.url))
  File "C:\Python36\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
  File "C:\Python36\lib\re.py", line 301, in _compile
    p = sre_compile.compile(pattern, flags)
  File "C:\Python36\lib\sre_compile.py", line 562, in compile
    p = sre_parse.parse(p, flags)
  File "C:\Python36\lib\sre_parse.py", line 847, in parse
    source = Tokenizer(str)
  File "C:\Python36\lib\sre_parse.py", line 231, in __init__
    self.__next()
  File "C:\Python36\lib\sre_parse.py", line 245, in __next
    self.string, len(self.string) - 1) from None
sre_constants.error: bad escape (end of pattern) at position 0
2018-11-04 16:34:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=4&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 54, in process_request
    print(re.findall(b, request.url))
  File "C:\Python36\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
  File "C:\Python36\lib\re.py", line 301, in _compile
    p = sre_compile.compile(pattern, flags)
  File "C:\Python36\lib\sre_compile.py", line 562, in compile
    p = sre_parse.parse(p, flags)
  File "C:\Python36\lib\sre_parse.py", line 847, in parse
    source = Tokenizer(str)
  File "C:\Python36\lib\sre_parse.py", line 231, in __init__
    self.__next()
  File "C:\Python36\lib\sre_parse.py", line 245, in __next
    self.string, len(self.string) - 1) from None
sre_constants.error: bad escape (end of pattern) at position 0
2018-11-04 16:34:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=5&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 54, in process_request
    print(re.findall(b, request.url))
  File "C:\Python36\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
  File "C:\Python36\lib\re.py", line 301, in _compile
    p = sre_compile.compile(pattern, flags)
  File "C:\Python36\lib\sre_compile.py", line 562, in compile
    p = sre_parse.parse(p, flags)
  File "C:\Python36\lib\sre_parse.py", line 847, in parse
    source = Tokenizer(str)
  File "C:\Python36\lib\sre_parse.py", line 231, in __init__
    self.__next()
  File "C:\Python36\lib\sre_parse.py", line 245, in __next
    self.string, len(self.string) - 1) from None
sre_constants.error: bad escape (end of pattern) at position 0
2018-11-04 16:34:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=6&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 54, in process_request
    print(re.findall(b, request.url))
  File "C:\Python36\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
  File "C:\Python36\lib\re.py", line 301, in _compile
    p = sre_compile.compile(pattern, flags)
  File "C:\Python36\lib\sre_compile.py", line 562, in compile
    p = sre_parse.parse(p, flags)
  File "C:\Python36\lib\sre_parse.py", line 847, in parse
    source = Tokenizer(str)
  File "C:\Python36\lib\sre_parse.py", line 231, in __init__
    self.__next()
  File "C:\Python36\lib\sre_parse.py", line 245, in __next
    self.string, len(self.string) - 1) from None
sre_constants.error: bad escape (end of pattern) at position 0
2018-11-04 16:34:32 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=7&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 54, in process_request
    print(re.findall(b, request.url))
  File "C:\Python36\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
  File "C:\Python36\lib\re.py", line 301, in _compile
    p = sre_compile.compile(pattern, flags)
  File "C:\Python36\lib\sre_compile.py", line 562, in compile
    p = sre_parse.parse(p, flags)
  File "C:\Python36\lib\sre_parse.py", line 847, in parse
    source = Tokenizer(str)
  File "C:\Python36\lib\sre_parse.py", line 231, in __init__
    self.__next()
  File "C:\Python36\lib\sre_parse.py", line 245, in __next
    self.string, len(self.string) - 1) from None
sre_constants.error: bad escape (end of pattern) at position 0
2018-11-04 16:34:38 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 54, in process_request
    print(re.findall(b, request.url))
  File "C:\Python36\lib\re.py", line 222, in findall
    return _compile(pattern, flags).findall(string)
  File "C:\Python36\lib\re.py", line 301, in _compile
    p = sre_compile.compile(pattern, flags)
  File "C:\Python36\lib\sre_compile.py", line 562, in compile
    p = sre_parse.parse(p, flags)
  File "C:\Python36\lib\sre_parse.py", line 847, in parse
    source = Tokenizer(str)
  File "C:\Python36\lib\sre_parse.py", line 231, in __init__
    self.__next()
  File "C:\Python36\lib\sre_parse.py", line 245, in __next
    self.string, len(self.string) - 1) from None
sre_constants.error: bad escape (end of pattern) at position 0
2018-11-04 16:34:47 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-04 16:34:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-04 16:34:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-04 16:34:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-04 16:34:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weibo.middlewares.middleware.JavaScriptMiddleware',
 'weibo.middlewares.middleware.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-04 16:34:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-04 16:34:47 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-04 16:34:47 [scrapy.core.engine] INFO: Spider opened
2018-11-04 16:34:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 16:34:48 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 16:40:41 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-04 16:40:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-04 16:40:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-04 16:40:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-04 16:40:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weibo.middlewares.middleware.JavaScriptMiddleware',
 'weibo.middlewares.middleware.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-04 16:40:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-04 16:40:41 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-04 16:40:41 [scrapy.core.engine] INFO: Spider opened
2018-11-04 16:40:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 16:40:41 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 16:42:27 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-04 16:42:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-04 16:42:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-04 16:42:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-04 16:42:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weibo.middlewares.middleware.JavaScriptMiddleware',
 'weibo.middlewares.middleware.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-04 16:42:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-04 16:42:27 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-04 16:42:27 [scrapy.core.engine] INFO: Spider opened
2018-11-04 16:42:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 16:42:28 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 16:42:46 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 16:43:43 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 5 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 16:47:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302402080649865>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 16:47:14 [scrapy.extensions.logstats] INFO: Crawled 18 pages (at 13 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 16:47:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302546977049022>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 16:50:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302476391107948>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 16:50:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302387861964248>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 16:50:16 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302531663681200>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 16:51:32 [scrapy.extensions.logstats] INFO: Crawled 40 pages (at 22 pages/min), scraped 7 items (at 7 items/min)
2018-11-04 16:54:13 [scrapy.extensions.logstats] INFO: Crawled 51 pages (at 11 pages/min), scraped 27 items (at 20 items/min)
2018-11-04 16:54:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302328072111295>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 16:55:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302323017989881>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 16:57:48 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302026749179865>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 16:57:48 [scrapy.extensions.logstats] INFO: Crawled 68 pages (at 17 pages/min), scraped 38 items (at 11 items/min)
2018-11-04 17:00:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302350285178035>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:00:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302013113495112>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:00:24 [scrapy.extensions.logstats] INFO: Crawled 78 pages (at 10 pages/min), scraped 48 items (at 10 items/min)
2018-11-04 17:00:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302260178958822>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:00:24 [scrapy.core.engine] INFO: Closing spider (finished)
2018-11-04 17:00:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/response_bytes': 2594124,
 'downloader/response_count': 89,
 'downloader/response_status_count/200': 89,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 11, 4, 9, 0, 24, 603899),
 'item_scraped_count': 68,
 'log_count/ERROR': 11,
 'log_count/INFO': 13,
 'log_count/WARNING': 2,
 'request_depth_max': 1,
 'response_received_count': 78,
 'scheduler/dequeued': 89,
 'scheduler/dequeued/memory': 89,
 'scheduler/enqueued': 89,
 'scheduler/enqueued/memory': 89,
 'start_time': datetime.datetime(2018, 11, 4, 8, 42, 28, 1089)}
2018-11-04 17:00:24 [scrapy.core.engine] INFO: Spider closed (finished)
2018-11-04 17:07:34 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-04 17:07:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-04 17:07:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-04 17:07:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-04 17:07:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weibo.middlewares.middleware.JavaScriptMiddleware',
 'weibo.middlewares.middleware.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-04 17:07:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-04 17:07:36 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-04 17:07:36 [scrapy.core.engine] INFO: Spider opened
2018-11-04 17:07:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 17:07:37 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 17:08:44 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 17:10:16 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 11 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 17:10:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2310474302648508555922>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:10:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302624273862059>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:10:42 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302669811431230>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:12:20 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 11 pages/min), scraped 1 items (at 1 items/min)
2018-11-04 17:14:19 [scrapy.extensions.logstats] INFO: Crawled 32 pages (at 10 pages/min), scraped 7 items (at 6 items/min)
2018-11-04 17:15:55 [scrapy.extensions.logstats] INFO: Crawled 40 pages (at 8 pages/min), scraped 23 items (at 16 items/min)
2018-11-04 17:18:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302393494924236>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:18:40 [scrapy.extensions.logstats] INFO: Crawled 50 pages (at 10 pages/min), scraped 23 items (at 0 items/min)
2018-11-04 17:18:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302387861964248>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:18:40 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309351000284302403590597963>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:21:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2310474302409429032563>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:21:41 [scrapy.extensions.logstats] INFO: Crawled 62 pages (at 12 pages/min), scraped 36 items (at 13 items/min)
2018-11-04 17:21:41 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302424587251194>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:23:25 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309351000774302301241209831>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:26:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302360624150401>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:26:28 [scrapy.extensions.logstats] INFO: Crawled 84 pages (at 22 pages/min), scraped 47 items (at 11 items/min)
2018-11-04 17:26:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404301866950367909>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:26:55 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302323017989881>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:26:55 [scrapy.extensions.logstats] INFO: Crawled 86 pages (at 2 pages/min), scraped 54 items (at 7 items/min)
2018-11-04 17:30:28 [scrapy.extensions.logstats] INFO: Crawled 101 pages (at 15 pages/min), scraped 67 items (at 13 items/min)
2018-11-04 17:30:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302196983349485>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:30:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302266352964441>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:30:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309351000404302342232125422>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:32:50 [scrapy.extensions.logstats] INFO: Crawled 111 pages (at 10 pages/min), scraped 80 items (at 13 items/min)
2018-11-04 17:34:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302263655997133>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:35:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404301865037731572>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:35:47 [scrapy.extensions.logstats] INFO: Crawled 125 pages (at 14 pages/min), scraped 81 items (at 1 items/min)
2018-11-04 17:39:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302016347266780>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:39:13 [scrapy.extensions.logstats] INFO: Crawled 141 pages (at 16 pages/min), scraped 95 items (at 14 items/min)
2018-11-04 17:42:39 [scrapy.extensions.logstats] INFO: Crawled 159 pages (at 18 pages/min), scraped 111 items (at 16 items/min)
2018-11-04 17:46:31 [scrapy.extensions.logstats] INFO: Crawled 174 pages (at 15 pages/min), scraped 124 items (at 13 items/min)
2018-11-04 17:46:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302008688458367>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:47:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404301484077498717>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:47:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302618292794251>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:47:05 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302619395920698>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:47:05 [scrapy.extensions.logstats] INFO: Crawled 177 pages (at 3 pages/min), scraped 139 items (at 15 items/min)
2018-11-04 17:49:08 [scrapy.extensions.logstats] INFO: Crawled 186 pages (at 9 pages/min), scraped 145 items (at 6 items/min)
2018-11-04 17:49:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302587401769407>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:49:52 [scrapy.extensions.logstats] INFO: Crawled 189 pages (at 3 pages/min), scraped 154 items (at 9 items/min)
2018-11-04 17:50:52 [scrapy.extensions.logstats] INFO: Crawled 193 pages (at 4 pages/min), scraped 154 items (at 0 items/min)
2018-11-04 17:51:41 [scrapy.extensions.logstats] INFO: Crawled 196 pages (at 3 pages/min), scraped 154 items (at 0 items/min)
2018-11-04 17:52:46 [scrapy.extensions.logstats] INFO: Crawled 200 pages (at 4 pages/min), scraped 154 items (at 0 items/min)
2018-11-04 17:53:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404301486757701050>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 74, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 81, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 17:53:57 [scrapy.extensions.logstats] INFO: Crawled 204 pages (at 4 pages/min), scraped 154 items (at 0 items/min)
2018-11-04 17:54:49 [scrapy.extensions.logstats] INFO: Crawled 207 pages (at 3 pages/min), scraped 155 items (at 1 items/min)
2018-11-04 17:55:47 [scrapy.extensions.logstats] INFO: Crawled 211 pages (at 4 pages/min), scraped 155 items (at 0 items/min)
2018-11-04 17:56:42 [scrapy.extensions.logstats] INFO: Crawled 215 pages (at 4 pages/min), scraped 155 items (at 0 items/min)
2018-11-04 17:57:45 [scrapy.extensions.logstats] INFO: Crawled 219 pages (at 4 pages/min), scraped 155 items (at 0 items/min)
2018-11-04 17:58:48 [scrapy.extensions.logstats] INFO: Crawled 223 pages (at 4 pages/min), scraped 155 items (at 0 items/min)
2018-11-04 17:59:50 [scrapy.extensions.logstats] INFO: Crawled 227 pages (at 4 pages/min), scraped 155 items (at 0 items/min)
2018-11-04 18:00:47 [scrapy.extensions.logstats] INFO: Crawled 231 pages (at 4 pages/min), scraped 155 items (at 0 items/min)
2018-11-04 18:01:43 [scrapy.extensions.logstats] INFO: Crawled 235 pages (at 4 pages/min), scraped 155 items (at 0 items/min)
2018-11-04 18:02:44 [scrapy.extensions.logstats] INFO: Crawled 239 pages (at 4 pages/min), scraped 155 items (at 0 items/min)
2018-11-04 18:03:56 [scrapy.extensions.logstats] INFO: Crawled 244 pages (at 5 pages/min), scraped 155 items (at 0 items/min)
2018-11-04 18:04:52 [scrapy.extensions.logstats] INFO: Crawled 248 pages (at 4 pages/min), scraped 157 items (at 2 items/min)
2018-11-04 18:05:42 [scrapy.extensions.logstats] INFO: Crawled 251 pages (at 3 pages/min), scraped 157 items (at 0 items/min)
2018-11-04 18:06:39 [scrapy.extensions.logstats] INFO: Crawled 255 pages (at 4 pages/min), scraped 157 items (at 0 items/min)
2018-11-04 18:07:40 [scrapy.extensions.logstats] INFO: Crawled 259 pages (at 4 pages/min), scraped 157 items (at 0 items/min)
2018-11-04 18:08:37 [scrapy.extensions.logstats] INFO: Crawled 263 pages (at 4 pages/min), scraped 157 items (at 0 items/min)
2018-11-04 18:09:43 [scrapy.extensions.logstats] INFO: Crawled 267 pages (at 4 pages/min), scraped 157 items (at 0 items/min)
2018-11-04 18:10:45 [scrapy.extensions.logstats] INFO: Crawled 271 pages (at 4 pages/min), scraped 157 items (at 0 items/min)
2018-11-04 18:11:49 [scrapy.extensions.logstats] INFO: Crawled 275 pages (at 4 pages/min), scraped 157 items (at 0 items/min)
2018-11-04 18:12:46 [scrapy.extensions.logstats] INFO: Crawled 279 pages (at 4 pages/min), scraped 157 items (at 0 items/min)
2018-11-04 18:13:37 [scrapy.extensions.logstats] INFO: Crawled 283 pages (at 4 pages/min), scraped 157 items (at 0 items/min)
2018-11-04 18:14:45 [scrapy.extensions.logstats] INFO: Crawled 288 pages (at 5 pages/min), scraped 157 items (at 0 items/min)
2018-11-04 18:15:45 [scrapy.extensions.logstats] INFO: Crawled 292 pages (at 4 pages/min), scraped 157 items (at 0 items/min)
2018-11-04 18:16:47 [scrapy.extensions.logstats] INFO: Crawled 296 pages (at 4 pages/min), scraped 157 items (at 0 items/min)
2018-11-04 18:17:47 [scrapy.extensions.logstats] INFO: Crawled 300 pages (at 4 pages/min), scraped 157 items (at 0 items/min)
2018-11-04 18:18:49 [scrapy.extensions.logstats] INFO: Crawled 304 pages (at 4 pages/min), scraped 157 items (at 0 items/min)
2018-11-04 18:20:01 [scrapy.extensions.logstats] INFO: Crawled 309 pages (at 5 pages/min), scraped 157 items (at 0 items/min)
2018-11-04 18:20:40 [scrapy.extensions.logstats] INFO: Crawled 312 pages (at 3 pages/min), scraped 159 items (at 2 items/min)
2018-11-04 18:21:37 [scrapy.extensions.logstats] INFO: Crawled 316 pages (at 4 pages/min), scraped 159 items (at 0 items/min)
2018-11-04 18:22:42 [scrapy.extensions.logstats] INFO: Crawled 320 pages (at 4 pages/min), scraped 159 items (at 0 items/min)
2018-11-04 18:23:45 [scrapy.extensions.logstats] INFO: Crawled 324 pages (at 4 pages/min), scraped 159 items (at 0 items/min)
2018-11-04 18:24:52 [scrapy.extensions.logstats] INFO: Crawled 328 pages (at 4 pages/min), scraped 159 items (at 0 items/min)
2018-11-04 18:25:44 [scrapy.extensions.logstats] INFO: Crawled 332 pages (at 4 pages/min), scraped 159 items (at 0 items/min)
2018-11-04 18:26:40 [scrapy.extensions.logstats] INFO: Crawled 336 pages (at 4 pages/min), scraped 159 items (at 0 items/min)
2018-11-04 18:28:18 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-04 18:28:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.5.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 18.7.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0i  14 Aug 2018), cryptography 2.3.1, Platform Windows-10-10.0.17134-SP0
2018-11-04 18:28:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-04 18:28:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-04 18:28:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weibo.middlewares.middleware.JavaScriptMiddleware',
 'weibo.middlewares.middleware.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-04 18:28:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-04 18:28:21 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-04 18:28:21 [scrapy.core.engine] INFO: Spider opened
2018-11-04 18:28:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 18:28:21 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 18:28:33 [py.warnings] WARNING: C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 18:28:47 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/?category=12>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 49, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 56, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 18:28:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/?category=7>
Traceback (most recent call last):
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\admin\PycharmProjects\text\venv\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 49, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\admin\PycharmProjects\spider-dome\weibo\weibo\middlewares\middleware.py", line 56, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 18:29:22 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 21:30:16 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-04 21:30:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-11-04 21:30:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-04 21:30:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-04 21:30:31 [fake_useragent] WARNING: Error occurred during loading data. Trying to use cache server https://fake-useragent.herokuapp.com/browsers/0.1.11
Traceback (most recent call last):
  File "C:\Python 3.6\lib\urllib\request.py", line 1318, in do_open
    encode_chunked=req.has_header('Transfer-encoding'))
  File "C:\Python 3.6\lib\http\client.py", line 1239, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Python 3.6\lib\http\client.py", line 1285, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Python 3.6\lib\http\client.py", line 1234, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Python 3.6\lib\http\client.py", line 1026, in _send_output
    self.send(msg)
  File "C:\Python 3.6\lib\http\client.py", line 964, in send
    self.connect()
  File "C:\Python 3.6\lib\http\client.py", line 1392, in connect
    super().connect()
  File "C:\Python 3.6\lib\http\client.py", line 936, in connect
    (self.host,self.port), self.timeout, self.source_address)
  File "C:\Python 3.6\lib\socket.py", line 724, in create_connection
    raise err
  File "C:\Python 3.6\lib\socket.py", line 713, in create_connection
    sock.connect(sa)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\fake_useragent\utils.py", line 67, in get
    context=context,
  File "C:\Python 3.6\lib\urllib\request.py", line 223, in urlopen
    return opener.open(url, data, timeout)
  File "C:\Python 3.6\lib\urllib\request.py", line 526, in open
    response = self._open(req, data)
  File "C:\Python 3.6\lib\urllib\request.py", line 544, in _open
    '_open', req)
  File "C:\Python 3.6\lib\urllib\request.py", line 504, in _call_chain
    result = func(*args)
  File "C:\Python 3.6\lib\urllib\request.py", line 1361, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "C:\Python 3.6\lib\urllib\request.py", line 1320, in do_open
    raise URLError(err)
urllib.error.URLError: <urlopen error timed out>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\fake_useragent\utils.py", line 154, in load
    for item in get_browsers(verify_ssl=verify_ssl):
  File "C:\Python 3.6\lib\site-packages\fake_useragent\utils.py", line 97, in get_browsers
    html = get(settings.BROWSERS_STATS_PAGE, verify_ssl=verify_ssl)
  File "C:\Python 3.6\lib\site-packages\fake_useragent\utils.py", line 84, in get
    raise FakeUserAgentError('Maximum amount of retries reached')
fake_useragent.errors.FakeUserAgentError: Maximum amount of retries reached
2018-11-04 21:30:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weibo.middlewares.middleware.JavaScriptMiddleware',
 'weibo.middlewares.middleware.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-04 21:30:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-04 21:30:35 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-04 21:30:35 [scrapy.core.engine] INFO: Spider opened
2018-11-04 21:30:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 21:30:36 [py.warnings] WARNING: C:\Python 3.6\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 21:31:06 [py.warnings] WARNING: C:\Python 3.6\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-04 21:31:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/?category=7>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:31:48 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 3 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 21:32:18 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/?category=1760>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:34:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404232016534098055>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 0
    
    ^
SyntaxError: unexpected EOF while parsing
2018-11-04 21:34:19 [scrapy.extensions.logstats] INFO: Crawled 11 pages (at 8 pages/min), scraped 0 items (at 0 items/min)
2018-11-04 21:34:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302732889597977>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:34:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302729773246245>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:34:19 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302739197824377>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:34:46 [scrapy.extensions.logstats] INFO: Crawled 13 pages (at 2 pages/min), scraped 5 items (at 5 items/min)
2018-11-04 21:37:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302640833022209>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:39:00 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 12 pages/min), scraped 5 items (at 0 items/min)
2018-11-04 21:39:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302618292794251>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:39:00 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302617063879912>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:40:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302636542250409>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:40:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302644331066703>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:40:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309351002454302639662771953>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:40:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302653222997366>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:40:46 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302654091173458>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 0
    
    ^
SyntaxError: unexpected EOF while parsing
2018-11-04 21:42:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309351002454302218701477883>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:42:29 [scrapy.extensions.logstats] INFO: Crawled 38 pages (at 13 pages/min), scraped 11 items (at 6 items/min)
2018-11-04 21:42:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404301922772320443>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 0
    
    ^
SyntaxError: unexpected EOF while parsing
2018-11-04 21:44:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302568451923111>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 0
    
    ^
SyntaxError: unexpected EOF while parsing
2018-11-04 21:44:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302579042490972>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:44:13 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302598504109402>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:44:13 [scrapy.extensions.logstats] INFO: Crawled 45 pages (at 7 pages/min), scraped 20 items (at 9 items/min)
2018-11-04 21:45:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302402080649865>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 0
    
    ^
SyntaxError: unexpected EOF while parsing
2018-11-04 21:45:57 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302393494924236>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:47:43 [scrapy.extensions.logstats] INFO: Crawled 55 pages (at 10 pages/min), scraped 25 items (at 5 items/min)
2018-11-04 21:47:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302387316718129>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    return response
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:47:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302485182393781>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    return response
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:47:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302446917764427>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    return response
  File "<string>", line 0
    
    ^
SyntaxError: unexpected EOF while parsing
2018-11-04 21:47:43 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309351002454302558834374424>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    return response
  File "<string>", line 0
    
    ^
SyntaxError: unexpected EOF while parsing
2018-11-04 21:49:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302246002187769>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    return response
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:49:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302408300782605>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    return response
  File "<string>", line 0
    
    ^
SyntaxError: unexpected EOF while parsing
2018-11-04 21:49:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309351002254302412130179108>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    return response
  File "<string>", line 0
    
    ^
SyntaxError: unexpected EOF while parsing
2018-11-04 21:49:03 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302389006965028>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    return response
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:51:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302360624150401>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    return response
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:51:10 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302418119664792>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    return response
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:51:10 [scrapy.extensions.logstats] INFO: Crawled 67 pages (at 12 pages/min), scraped 35 items (at 10 items/min)
2018-11-04 21:53:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302358149467774>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    return response
  File "<string>", line 0
    
    ^
SyntaxError: unexpected EOF while parsing
2018-11-04 21:53:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302323017989881>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    return response
  File "<string>", line 0
    
    ^
SyntaxError: unexpected EOF while parsing
2018-11-04 21:53:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302379800486752>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    return response
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:53:20 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302328072111295>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    return response
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:55:09 [scrapy.extensions.logstats] INFO: Crawled 77 pages (at 10 pages/min), scraped 43 items (at 8 items/min)
2018-11-04 21:55:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302349517630765>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    return response
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:55:09 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302347378516803>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    return response
  File "<string>", line 0
    
    ^
SyntaxError: unexpected EOF while parsing
2018-11-04 21:56:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309351002454302341628121257>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    return response
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:56:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302350285178035>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    return response
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:56:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309351000404302342232125422>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    return response
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:56:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302343695947733>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    return response
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-04 21:56:59 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404302303837436254>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 46, in process_response
    https://weibo.com/a/aj/transform/loadingmoreunlogin?ajwvr=6&category=1760&page=8&lefnav=0&cursor=
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 53, in response_new
    return response
  File "<string>", line 0
    
    ^
SyntaxError: unexpected EOF while parsing
2018-11-08 15:53:47 [scrapy.utils.log] INFO: Scrapy 1.5.1 started (bot: weibo)
2018-11-08 15:53:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.7, cssselect 1.0.3, parsel 1.5.1, w3lib 1.19.0, Twisted 18.9.0, Python 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-11-08 15:53:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo', 'LOG_FILE': 'weiboSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'weibo.spiders', 'SPIDER_MODULES': ['weibo.spiders']}
2018-11-08 15:53:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-11-08 15:53:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['weibo.middlewares.middleware.JavaScriptMiddleware',
 'weibo.middlewares.middleware.RandomUserAgent',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-11-08 15:53:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-11-08 15:53:51 [scrapy.middleware] INFO: Enabled item pipelines:
[]
2018-11-08 15:53:51 [scrapy.core.engine] INFO: Spider opened
2018-11-08 15:53:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-11-08 15:53:51 [py.warnings] WARNING: C:\Python 3.6\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-08 15:56:32 [scrapy.extensions.logstats] INFO: Crawled 14 pages (at 14 pages/min), scraped 0 items (at 0 items/min)
2018-11-08 15:58:42 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 11 pages/min), scraped 1 items (at 1 items/min)
2018-11-08 15:59:04 [scrapy.extensions.logstats] INFO: Crawled 27 pages (at 2 pages/min), scraped 10 items (at 9 items/min)
2018-11-08 15:59:04 [py.warnings] WARNING: C:\Python 3.6\lib\site-packages\selenium\webdriver\phantomjs\webdriver.py:49: UserWarning: Selenium support for PhantomJS has been deprecated, please use headless versions of Chrome or Firefox instead
  warnings.warn('Selenium support for PhantomJS has been deprecated, please use headless '

2018-11-08 16:00:52 [scrapy.extensions.logstats] INFO: Crawled 36 pages (at 9 pages/min), scraped 18 items (at 8 items/min)
2018-11-08 16:03:23 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404304027503440908>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 49, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 57, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-08 16:05:31 [scrapy.extensions.logstats] INFO: Crawled 55 pages (at 19 pages/min), scraped 26 items (at 8 items/min)
2018-11-08 16:09:31 [scrapy.extensions.logstats] INFO: Crawled 72 pages (at 17 pages/min), scraped 34 items (at 8 items/min)
2018-11-08 16:09:31 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404303747521100150>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 49, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 57, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-08 16:12:31 [scrapy.extensions.logstats] INFO: Crawled 86 pages (at 14 pages/min), scraped 49 items (at 15 items/min)
2018-11-08 16:16:36 [scrapy.extensions.logstats] INFO: Crawled 104 pages (at 18 pages/min), scraped 64 items (at 15 items/min)
2018-11-08 16:16:36 [scrapy.core.scraper] ERROR: Error downloading <GET https://weibo.com/ttarticle/p/show?id=2309404303770833032502>
Traceback (most recent call last):
  File "C:\Python 3.6\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "C:\Python 3.6\lib\site-packages\scrapy\core\downloader\middleware.py", line 53, in process_response
    spider=spider)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 49, in process_response
    response = self.response_new(response.url,request)
  File "C:\Users\Administrator\PycharmProjects\spider_weibo\weibo\weibo\middlewares\middleware.py", line 57, in response_new
    re_text = eval(re.text)['data']
  File "<string>", line 1
    <!DOCTYPE html>
    ^
SyntaxError: invalid syntax
2018-11-08 16:19:59 [scrapy.extensions.logstats] INFO: Crawled 122 pages (at 18 pages/min), scraped 77 items (at 13 items/min)
2018-11-08 16:23:20 [scrapy.extensions.logstats] INFO: Crawled 140 pages (at 18 pages/min), scraped 93 items (at 16 items/min)
